{
  "url": "https://api.github.com/repos/sigp/lighthouse/issues/800",
  "repository_url": "https://api.github.com/repos/sigp/lighthouse",
  "labels_url": "https://api.github.com/repos/sigp/lighthouse/issues/800/labels{/name}",
  "comments_url": "https://api.github.com/repos/sigp/lighthouse/issues/800/comments",
  "events_url": "https://api.github.com/repos/sigp/lighthouse/issues/800/events",
  "html_url": "https://github.com/sigp/lighthouse/issues/800",
  "id": 548664237,
  "node_id": "MDU6SXNzdWU1NDg2NjQyMzc=",
  "number": 800,
  "title": "Potential memory exhaustion vector",
  "user": {
    "login": "paulhauner",
    "id": 6660660,
    "node_id": "MDQ6VXNlcjY2NjA2NjA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/paulhauner",
    "html_url": "https://github.com/paulhauner",
    "followers_url": "https://api.github.com/users/paulhauner/followers",
    "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
    "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
    "organizations_url": "https://api.github.com/users/paulhauner/orgs",
    "repos_url": "https://api.github.com/users/paulhauner/repos",
    "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
    "received_events_url": "https://api.github.com/users/paulhauner/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1783740159,
      "node_id": "MDU6TGFiZWwxNzgzNzQwMTU5",
      "url": "https://api.github.com/repos/sigp/lighthouse/labels/security",
      "name": "security",
      "color": "d30ca8",
      "default": false,
      "description": ""
    },
    {
      "id": 2034355093,
      "node_id": "MDU6TGFiZWwyMDM0MzU1MDkz",
      "url": "https://api.github.com/repos/sigp/lighthouse/labels/consensus",
      "name": "consensus",
      "color": "5e59bf",
      "default": false,
      "description": "An issue/PR that touches consensus code, such as state_processing or block verification."
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": {
    "login": "michaelsproul",
    "id": 4452260,
    "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/michaelsproul",
    "html_url": "https://github.com/michaelsproul",
    "followers_url": "https://api.github.com/users/michaelsproul/followers",
    "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
    "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
    "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
    "repos_url": "https://api.github.com/users/michaelsproul/repos",
    "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
    "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
    "type": "User",
    "site_admin": false
  },
  "assignees": [
    {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    }
  ],
  "milestone": null,
  "comments": 8,
  "created_at": "2020-01-13T01:45:26Z",
  "updated_at": "2022-11-09T05:03:01Z",
  "closed_at": "2020-10-23T02:41:41Z",
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "body": "## Description\r\n\r\nIn `per_block_processing` we store a list of intermediate states when fast-fowarding a state through skip slots:\r\n\r\nhttps://github.com/sigp/lighthouse/blob/03443c3e5714ae5478173de4a87f92a1c9577549/beacon_node/beacon_chain/src/beacon_chain.rs#L1364-L1378\r\n\r\nGiven that each state is on the order of MB (they're ~5mb when SSZ encoded, not sure what they consumer when in RAM) there's an attack here to force us to skip forward more blocks than we can keep in RAM.\r\n\r\n## Suggestions\r\n\r\n1. Enforce a max-skip slots value. This was found to be annoying in testnets, so perhaps we allow it to be disabled at run-time.\r\n2. Store the blocks in the DB as we go, and unwind if we encounter an error.\r\n\r\nI'd probably lean towards a combination of the both. (2) still has a DoS vector that we can fill up a filesystem, but we can fit _many_ more states in the DB than in RAM because there's more memory and there is compression\\efficiency when storing in the DB that is not present in RAM.\r\n",
  "closed_by": {
    "login": "bors[bot]",
    "id": 26634292,
    "node_id": "MDM6Qm90MjY2MzQyOTI=",
    "avatar_url": "https://avatars.githubusercontent.com/in/1847?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/bors%5Bbot%5D",
    "html_url": "https://github.com/apps/bors",
    "followers_url": "https://api.github.com/users/bors%5Bbot%5D/followers",
    "following_url": "https://api.github.com/users/bors%5Bbot%5D/following{/other_user}",
    "gists_url": "https://api.github.com/users/bors%5Bbot%5D/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/bors%5Bbot%5D/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/bors%5Bbot%5D/subscriptions",
    "organizations_url": "https://api.github.com/users/bors%5Bbot%5D/orgs",
    "repos_url": "https://api.github.com/users/bors%5Bbot%5D/repos",
    "events_url": "https://api.github.com/users/bors%5Bbot%5D/events{/privacy}",
    "received_events_url": "https://api.github.com/users/bors%5Bbot%5D/received_events",
    "type": "Bot",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/800/reactions",
    "total_count": 2,
    "+1": 2,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/sigp/lighthouse/issues/800/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/573559838",
    "html_url": "https://github.com/sigp/lighthouse/issues/800#issuecomment-573559838",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/800",
    "id": 573559838,
    "node_id": "MDEyOklzc3VlQ29tbWVudDU3MzU1OTgzOA==",
    "user": {
      "login": "pscott",
      "id": 30843220,
      "node_id": "MDQ6VXNlcjMwODQzMjIw",
      "avatar_url": "https://avatars.githubusercontent.com/u/30843220?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/pscott",
      "html_url": "https://github.com/pscott",
      "followers_url": "https://api.github.com/users/pscott/followers",
      "following_url": "https://api.github.com/users/pscott/following{/other_user}",
      "gists_url": "https://api.github.com/users/pscott/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/pscott/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/pscott/subscriptions",
      "organizations_url": "https://api.github.com/users/pscott/orgs",
      "repos_url": "https://api.github.com/users/pscott/repos",
      "events_url": "https://api.github.com/users/pscott/events{/privacy}",
      "received_events_url": "https://api.github.com/users/pscott/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-01-13T08:42:45Z",
    "updated_at": "2020-01-13T08:44:05Z",
    "author_association": "CONTRIBUTOR",
    "body": "Should we also maybe provide a way for the user to set this `max-skip slots value`? (cli parameter?) \r\nOr should we just set this number to be very low? Thinking about the user who has a small droplet that has 1GB RAM and that might find it useful to provide set a smaller `max-skip slots value`.\r\n\r\nEnabling / disabling might be done with cli parameters too now that I think about it, with default being \"yes\" and the testnet command defaulting to \"no\"?",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/573559838/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/689865594",
    "html_url": "https://github.com/sigp/lighthouse/issues/800#issuecomment-689865594",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/800",
    "id": 689865594,
    "node_id": "MDEyOklzc3VlQ29tbWVudDY4OTg2NTU5NA==",
    "user": {
      "login": "paulhauner",
      "id": 6660660,
      "node_id": "MDQ6VXNlcjY2NjA2NjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/paulhauner",
      "html_url": "https://github.com/paulhauner",
      "followers_url": "https://api.github.com/users/paulhauner/followers",
      "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
      "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
      "organizations_url": "https://api.github.com/users/paulhauner/orgs",
      "repos_url": "https://api.github.com/users/paulhauner/repos",
      "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/paulhauner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-09-09T22:55:36Z",
    "updated_at": "2020-09-09T22:55:36Z",
    "author_association": "MEMBER",
    "body": "> Enforce a max-skip slots value. This was found to be annoying in testnets, so perhaps we allow it to be disabled at run-time.\r\n\r\nThis has already been implemented.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/689865594/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/708973822",
    "html_url": "https://github.com/sigp/lighthouse/issues/800#issuecomment-708973822",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/800",
    "id": 708973822,
    "node_id": "MDEyOklzc3VlQ29tbWVudDcwODk3MzgyMg==",
    "user": {
      "login": "paulhauner",
      "id": 6660660,
      "node_id": "MDQ6VXNlcjY2NjA2NjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/paulhauner",
      "html_url": "https://github.com/paulhauner",
      "followers_url": "https://api.github.com/users/paulhauner/followers",
      "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
      "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
      "organizations_url": "https://api.github.com/users/paulhauner/orgs",
      "repos_url": "https://api.github.com/users/paulhauner/repos",
      "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/paulhauner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-10-15T07:59:46Z",
    "updated_at": "2020-10-15T07:59:46Z",
    "author_association": "MEMBER",
    "body": "A potential solution is to create another column in the database for \"temporary states\".\r\n\r\nIf we get a block with more than `STATE_SKIP_THRESHOLD`, instead of keeping the state in memory we write them into the temporary states column. After we've verified the block, we move the temporary states in to the real database.\r\n\r\nThe purpose of the temp states column is to avoid writing unverified states into the \"real database\".\r\n\r\nNote: we would need to think about to make the moving from temp states to real states an atomic operation.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/708973822/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/709010385",
    "html_url": "https://github.com/sigp/lighthouse/issues/800#issuecomment-709010385",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/800",
    "id": 709010385,
    "node_id": "MDEyOklzc3VlQ29tbWVudDcwOTAxMDM4NQ==",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-10-15T08:57:32Z",
    "updated_at": "2020-10-15T08:57:32Z",
    "author_association": "MEMBER",
    "body": "That’s a good point... I wonder if we used a database with “real transactions” (like LMDB) whether this would even require any more work than just using a transaction... 🤔 As far as I understand LMDB uses memory-mapped pages which get auto flushed to disk when the OS sees fit. Whether or not it would flush them to disk before the transaction commits is something we’d have to check",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/709010385/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/709306174",
    "html_url": "https://github.com/sigp/lighthouse/issues/800#issuecomment-709306174",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/800",
    "id": 709306174,
    "node_id": "MDEyOklzc3VlQ29tbWVudDcwOTMwNjE3NA==",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-10-15T12:56:28Z",
    "updated_at": "2020-10-15T12:56:28Z",
    "author_association": "MEMBER",
    "body": "Ok, LMDB is not a silver bullet 😅 I ran a test writing 20GB in one transaction and it OOMed instantly, obliterating my whole session.\r\n\r\nManually implementing temp states, or having a flag on states like `confirmed: bool` seems like a workable solution. Even using LevelDB we would be able to atomically update a batch of states from `confirmed: false -> true`",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/709306174/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/709661689",
    "html_url": "https://github.com/sigp/lighthouse/issues/800#issuecomment-709661689",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/800",
    "id": 709661689,
    "node_id": "MDEyOklzc3VlQ29tbWVudDcwOTY2MTY4OQ==",
    "user": {
      "login": "paulhauner",
      "id": 6660660,
      "node_id": "MDQ6VXNlcjY2NjA2NjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/paulhauner",
      "html_url": "https://github.com/paulhauner",
      "followers_url": "https://api.github.com/users/paulhauner/followers",
      "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
      "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
      "organizations_url": "https://api.github.com/users/paulhauner/orgs",
      "repos_url": "https://api.github.com/users/paulhauner/repos",
      "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/paulhauner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-10-16T00:37:26Z",
    "updated_at": "2020-10-16T00:37:26Z",
    "author_association": "MEMBER",
    "body": "> having a flag on states like confirmed: bool seems like a workable solution. \r\n\r\nThis is elegant from an atomic perspective but it's a breaking schema change. We could probably write a migration script *fairly* easily.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/709661689/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/711079664",
    "html_url": "https://github.com/sigp/lighthouse/issues/800#issuecomment-711079664",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/800",
    "id": 711079664,
    "node_id": "MDEyOklzc3VlQ29tbWVudDcxMTA3OTY2NA==",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-10-17T20:59:12Z",
    "updated_at": "2020-10-17T20:59:12Z",
    "author_association": "MEMBER",
    "body": "I think the temp state flag would need to be in a completely separate column from the states in order to allow atomic updates, and this would also simplify migration.\r\n\r\nI thought about atomicity some more and realised that:\r\n\r\n1. If the temp states are stored as whole states in their own column, then we have the same memory-exhaustion problem as now when it comes to atomically moving them, i.e. you'd have to load all the temp states into memory, create a WriteBatch, and commit that.\r\n2. Using an object like `{state: BeaconState, confirmed: bool}` is no better, because LevelDB only allows writes and not mutations, so we'd have to load the whole object just to change `confirmed: false -> true`.\r\n\r\nThe separate column design meanwhile would look something like:\r\n\r\n* During intermediate state storage, atomically write:\r\n    1. The state into the regular states column (if it doesn't already exist*)\r\n    2. A marker value into a new \"temp states\" column. This value doesn't need any content, and is stored under the state root as a key (i.e. mapping `state_root => ()`).\r\n    3. When the block is processed, commit one of two transactions:\r\n        1. Success: atomically delete all stored state roots from the temp states column\r\n        2. Failure: atomically delete all (new) stored state roots from the temp states column, _and_ their corresponding states (on `drop`).\r\n* During _all_ state loads:\r\n    1. Check if the state root corresponds to a temp state: if it does, return `None`\r\n    2. Load the state as normal from the regular states table\r\n\r\n*There are some complications around what to do if a state already exists a) as a confirmed state or b) as an existing temp state. Need to think about it some more.\r\n\r\nWe may also need some sort of garbage-collection process to delete temp states (on startup?). Although that may not be necessary if the normal deletion process removes most of them.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/711079664/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/711603652",
    "html_url": "https://github.com/sigp/lighthouse/issues/800#issuecomment-711603652",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/800",
    "id": 711603652,
    "node_id": "MDEyOklzc3VlQ29tbWVudDcxMTYwMzY1Mg==",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-10-19T05:34:37Z",
    "updated_at": "2020-10-19T05:34:37Z",
    "author_association": "MEMBER",
    "body": "I'm coming round to the idea of the garbage collection of temp states as the _only_ way to delete states created as temporary. Otherwise two threads could race, and if one reverts, it might delete a state required by the other. A flow something like:\r\n\r\n1. Thread 1 atomically stores state `s` and flag `s_temp`.\r\n2. Thread 2 wants to store `s`, but seeing it there already just stages the deletion of `s_temp` later\r\n3. Thread 1 errors, and commits the \"on drop\" revert transaction -- deleting `s` and `s_temp`\r\n4. Thread 2 succeeds, re-deleting `s_temp`. However, the state that it wanted stored, `s`, is also gone :frowning: #rekt\r\n\r\nWith the garbage collection approach, we just leave the temp states there if the block import fails, and they either get cleaned up by future blocks which make them non-temporary, _or_ at startup by iterating through the temp states column and deleting all the entries and their corresponding states (_before_ allowing any block importer to start running in parallel).\r\n\r\nAll this concurrency has me like :exploding_head: ",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/711603652/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
