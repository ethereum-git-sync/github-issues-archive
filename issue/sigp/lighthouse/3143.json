{
  "url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
  "repository_url": "https://api.github.com/repos/sigp/lighthouse",
  "labels_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143/labels{/name}",
  "comments_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143/comments",
  "events_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143/events",
  "html_url": "https://github.com/sigp/lighthouse/issues/3143",
  "id": 1193536643,
  "node_id": "I_kwDOCFeAzc5HI-yD",
  "number": 3143,
  "title": "Add HTTP Endpoint to Capture `BeaconState` and `BeaconBlock` for Head and Historical Slots",
  "user": {
    "login": "abdulrabbani00",
    "id": 58230246,
    "node_id": "MDQ6VXNlcjU4MjMwMjQ2",
    "avatar_url": "https://avatars.githubusercontent.com/u/58230246?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/abdulrabbani00",
    "html_url": "https://github.com/abdulrabbani00",
    "followers_url": "https://api.github.com/users/abdulrabbani00/followers",
    "following_url": "https://api.github.com/users/abdulrabbani00/following{/other_user}",
    "gists_url": "https://api.github.com/users/abdulrabbani00/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/abdulrabbani00/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/abdulrabbani00/subscriptions",
    "organizations_url": "https://api.github.com/users/abdulrabbani00/orgs",
    "repos_url": "https://api.github.com/users/abdulrabbani00/repos",
    "events_url": "https://api.github.com/users/abdulrabbani00/events{/privacy}",
    "received_events_url": "https://api.github.com/users/abdulrabbani00/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 12,
  "created_at": "2022-04-05T18:00:58Z",
  "updated_at": "2022-04-18T14:57:09Z",
  "closed_at": "2022-04-18T14:57:09Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "- [Overview](#overview)\r\n  * [Use Case](#use-case)\r\n  * [Running the Nodes](#running-the-nodes)\r\n- [Endpoints](#endpoints)\r\n  * [`/proposed-latest-block`](#--proposed-latest-block-)\r\n    + [Result We Want](#result-we-want)\r\n    + [Potential Implementation](#potential-implementation)\r\n  * [`/proposed-latest-state`](#--proposed-latest-state-)\r\n    + [Result We Want](#result-we-want-1)\r\n    + [Potential Implementation](#potential-implementation-1)\r\n  * [`/finalized-beacon-slot/range`](#--finalized-beacon-slot-range-)\r\n    + [Result We Want](#result-we-want-2)\r\n    + [Potential Implementation](#potential-implementation-2)\r\n  * [`/finalized-beacon-slot/range`](#--finalized-beacon-slot-range--1)\r\n    + [Result We Want](#result-we-want-3)\r\n    + [Potential Implementation](#potential-implementation-3)\r\n  * [`/forked-beacon-block`](#--forked-beacon-block-)\r\n    + [Result We Want](#result-we-want-4)\r\n    + [Potential Implementation](#potential-implementation-4)\r\n  * [`/missed-beacon-slot` - Nice to have](#--missed-beacon-slot----nice-to-have)\r\n    + [Result We Want](#result-we-want-5)\r\n    + [Potential Implementation](#potential-implementation-5)\r\n  * [`/finalized-beacon-slot/latest` - Nice to have](#--finalized-beacon-slot-latest----nice-to-have)\r\n    + [Result We Want](#result-we-want-6)\r\n- [Questions](#questions)\r\n\r\n<small><i><a href='http://ecotrust-canada.github.io/markdown-toc/'>Table of contents generated with markdown-toc</a></i></small>\r\n\r\n# Overview\r\n\r\nI would like to add a few HTTP endpoints for my team's use case. I am more than happy and willing to write all the code needed to implement these feature. I only ask for guidance and help.\r\n\r\n## Use Case\r\n\r\nMy teams use case is as follows:\r\n1. We want to capture every `BeaconBlock` and `BeaconState` for every slot from `genesis` to `head` in a Postgres DB.\r\n2. We want to capture `missed` slots (slots that were skipped).\r\n3. We would like to capture all processed `BeaconBlocks`, even the ones that are `forked` when watching the head of chain.\r\n  a. We would like to label the blocks that are `forked` as `forked` in the Postgres DB. \r\n\r\n## Running the Nodes\r\n\r\nAt the first go, we plan on having two `lighthouse` nodes running.\r\n1. Sole purpose is to keep up with the head of the chain. This node will update the database with the latest information from the head.\r\n2. An archival node that has every block since genesis available. This node will be used to fill the database for historical events, as well as missed events.\r\n\r\n# Endpoints\r\n\r\nThe following capture all the endpoints that we are hoping to expose on the beacon node, as well as potential implementations for them. The actual names and \"endpoints\" themselves can be easily changed and modified. This example is simply using dummy placeholders.\r\n\r\n## `/proposed-latest-block`\r\n\r\n### Result We Want\r\nExpose an HTTP event stream endpoint that will stream the proposed head `BeaconBlock(s)` for the latest slot. Keeping in mind that we can have multiple proposed head `BeaconBlocks` for a given slot.\r\n\r\nIf someone is listening to this endpoint they might see:\r\n```\r\n{\r\n  \"Slot\": 10,\r\n  \"BeaconBlock\": dict_a\r\n}\r\n...\r\n{\r\n  \"Slot\": 10,\r\n  \"BeaconBlock\": dict_b\r\n}\r\n...\r\n{\r\n  \"Slot\": 11,\r\n  \"BeaconBlock\": dict_c\r\n}\r\n```\r\n\r\n### Potential Implementation\r\n\r\nHypothetically speaking, whenever a new block is written to the Hot DB, we should be able to construct an object utilizing the `BeaconBlock` and send it through the endpoint.\r\n\r\n## `/proposed-latest-state`\r\n\r\n### Result We Want\r\nVery similar to the `/proposed-latest-block` endpoint. \r\n\r\nExpose an HTTP event stream endpoint that will stream the proposed head `BeaconStates` for the latest slot. Keeping in mind that we can have multiple proposed head `BeaconStates` for a given slot.\r\n\r\nIf someone is listening to this endpoint they might see:\r\n```\r\n{\r\n  \"Slot\": 10,\r\n  \"BeaconState\": dict_a\r\n}\r\n...\r\n{\r\n  \"Slot\": 10,\r\n  \"BeaconState\": dict_b\r\n}\r\n...\r\n{\r\n  \"Slot\": 11,\r\n  \"BeaconState\": dict_c\r\n}\r\n```\r\n\r\n### Potential Implementation\r\n\r\nFrom my understanding, the lighthouse juggles all potential `BeaconStates` at its head. We should be able to simply send them through the HTTP endpoint.\r\n\r\n## `/finalized-beacon-slot/range`\r\n\r\n### Result We Want\r\nExpose an HTTP endpoint to return a list of `BeaconBlock` objects for each slot for a specified block range.\r\n\r\nIf someone queries this endpoint with the following parameters, they might see:\r\n\r\n```\r\nParameters: {start:10, end: 12}\r\n\r\n[\r\n  {\r\n     \"Slot: 10,\r\n     \"BeaconBody\": dict_a\r\n  },\r\n  {\r\n     \"Slot: 11,\r\n     \"BeaconBody\": None --> Because this was a skipped slot.\r\n  },\r\n  {\r\n     \"Slot: 12,\r\n     \"BeaconBody\": dict_c\r\n  }\r\n]\r\n\r\n```\r\n### Potential Implementation\r\nHypothetically speaking, this object \"should\" be within the Hot DB (as long as the node has constructed it).  We should be able to query the DB to return the specified object.\r\n\r\n## `/finalized-beacon-slot/range`\r\n\r\n### Result We Want\r\n\r\nSimilar to  `/finalized-beacon-slot/range`, but the implementation will vary drastically I believe.\r\n\r\nExpose an HTTP endpoint to return a list of `BeaconStates` objects for each slot for a specified block range. If someone queries this endpoint with the following parameters, they might see:\r\n\r\n```\r\nParameters: {start:10, end: 12}\r\n\r\n[\r\n  {\r\n     \"Slot: 10,\r\n     \"BeaconStates\": dict_a\r\n  },\r\n  {\r\n     \"Slot: 11,\r\n     \"BeaconStates\": dict_a --> Because this slot has no BeaconBlock.\r\n  },\r\n  {\r\n     \"Slot: 12,\r\n     \"BeaconStates\": dict_c\r\n  }\r\n]\r\n\r\n```\r\n\r\n### Potential Implementation\r\n\r\nThe implementation for this is a bit of a head-scratcher to me. I would imagine that the cold DB might have some of the states available, but from my understanding, not all of the states (the frequency of states available in the cold DB can be configured through the parameter called `--slots-per-restore-point` correct?)\r\n\r\nPerhaps this implementation would be two folds:\r\n1. Check to see if any of the slots specified are in the cold DB, if so add them to the return array.\r\n4. If not, then construct each `BeaconState` that is missing and add it to the return array.\r\n5. Return the final return array.\r\n\r\n## `/forked-beacon-block`\r\n\r\n### Result We Want\r\nExpose an HTTP event stream endpoint that will stream any `forked` block. Consider the following case.\r\n\r\n1. Latest slot is `10`.\r\n2. Latest proposed block is `a`, this gets streamed via the `/proposed-latest-block` endpoint.\r\n3. Latest proposed block is `b`, this gets streamed via the `/proposed-latest-block` endpoint.\r\n6. Following the fork rule, the chain decides that block `a` is going to be chosen for slot `10`. This means that block `b` is the `forked` block.\r\n\r\nIn this scenario, anyone listening to `/forked-beacon-block`, should see the following:\r\n```\r\n{\r\n  \"Slot\": 10,\r\n  \"status\": \"forked\",\r\n  \"BeaconBody\": b\r\n}\r\n```\r\n\r\n### Potential Implementation\r\n\r\nI am not entirely sure of the inner workings of Hot DB. But if hot DB keeps track of `forked` blocks, then we might be able to piggyback off of that functionality. When hot DB recognizes a block as `forked`, a function streams that block to the `/forked-beacon-block` endpoint.\r\n\r\n## `/missed-beacon-slot` - Nice to have\r\n\r\n### Result We Want\r\nExpose an HTTP event stream endpoint that will stream any `missed` slots (skipped slots).\r\n\r\nIn this scenario, anyone listening to `/missed-beacon-slot`, should see the following:\r\n```\r\n{\r\n  \"Slot\": 11,\r\n  \"status\": \"missed\",\r\n}\r\n```\r\n\r\n### Potential Implementation\r\n\r\nI understand that `missed` slots are not referenced at all in the hot or cold DB. Therefore I am not sure how this might be implemented, but it would be great if `lighthouse` could see that it jumped from slot `x` to `x+2`, and skipped `x+1`. In this scenario it would then send slot `x+1` to the `/missed-beacon-slot` endpoint.\r\n\r\n## `/finalized-beacon-slot/latest` - Nice to have\r\n\r\nThis implementation is not needed if we have `/forked-beacon-block`.\r\n\r\n### Result We Want\r\n\r\n Expose an HTTP event stream endpoint that will stream the single, finalized head `BeaconBlock` for the latest finalized slot. This way, if we have 2 proposed blocks for a single slot, we can determine which block the chain chose for the specified slot.\r\n\r\n\r\nIn this scenario, anyone listening to `/finalized-beacon-slot/latest`, should see the following:\r\n```\r\n{\r\n  \"Slot\": 10,\r\n  \"BlockNumber\": a,\r\n  \"status\": \"finalized\",\r\n}\r\n....\r\n{\r\n  \"Slot\": 11,\r\n  \"BlockNumber\": b,\r\n  \"status\": \"finalized\",\r\n}\r\n```\r\n\r\n### Potential Implementation\r\nI am not sure if the Hot DB marks blocks as `finalized`. But if it does, then we can stream the `finalized` block to this endpoint after it is finalized in Hot DB.\r\n\r\n# Questions\r\n\r\nThere are a few questions that we have:\r\n1. What is the \"best\" way to run the \"archival\" node. I am considering the best configuration flags to provide to this node, to contain all blocks from genesis to head, and be able to construct the `BeaconState` for each slot. I understand that this is a heavy lift. I would love to understand if you guys have some insights here regarding the flags to use as well as hardware specs for achieving this.\r\n2. What type of Merkle tree is the `BeaconState` a part of?",
  "closed_by": {
    "login": "abdulrabbani00",
    "id": 58230246,
    "node_id": "MDQ6VXNlcjU4MjMwMjQ2",
    "avatar_url": "https://avatars.githubusercontent.com/u/58230246?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/abdulrabbani00",
    "html_url": "https://github.com/abdulrabbani00",
    "followers_url": "https://api.github.com/users/abdulrabbani00/followers",
    "following_url": "https://api.github.com/users/abdulrabbani00/following{/other_user}",
    "gists_url": "https://api.github.com/users/abdulrabbani00/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/abdulrabbani00/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/abdulrabbani00/subscriptions",
    "organizations_url": "https://api.github.com/users/abdulrabbani00/orgs",
    "repos_url": "https://api.github.com/users/abdulrabbani00/repos",
    "events_url": "https://api.github.com/users/abdulrabbani00/events{/privacy}",
    "received_events_url": "https://api.github.com/users/abdulrabbani00/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/3143/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1089205833",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1089205833",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1089205833,
    "node_id": "IC_kwDOCFeAzc5A6_ZJ",
    "user": {
      "login": "realbigsean",
      "id": 5160426,
      "node_id": "MDQ6VXNlcjUxNjA0MjY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5160426?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/realbigsean",
      "html_url": "https://github.com/realbigsean",
      "followers_url": "https://api.github.com/users/realbigsean/followers",
      "following_url": "https://api.github.com/users/realbigsean/following{/other_user}",
      "gists_url": "https://api.github.com/users/realbigsean/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/realbigsean/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/realbigsean/subscriptions",
      "organizations_url": "https://api.github.com/users/realbigsean/orgs",
      "repos_url": "https://api.github.com/users/realbigsean/repos",
      "events_url": "https://api.github.com/users/realbigsean/events{/privacy}",
      "received_events_url": "https://api.github.com/users/realbigsean/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-05T19:07:02Z",
    "updated_at": "2022-04-05T19:07:02Z",
    "author_association": "COLLABORATOR",
    "body": "An important thing to note is  we *do* prune non-canonical blocks from a finalized portion of the chain. I wasn't sure about this in answering your questions yesterday but I verified. So I don't know that some of these will be possible with lighthouse (any endpoint that expects to produce multiple blocks or states at a single slot in a portion of the chain that has finalized). If you require these, then another client might be an better option if they don't prune these (not sure which client that might be), or maybe you could get this data from a service like beaconcha.in. \r\n\r\nOtherwise, it sounds like lot of the other information here can be derived from existing standard API endpoints (which all clients implement), the main one being the existing events stream:  https://ethereum.github.io/beacon-APIs/#/Events/eventstream\r\n\r\n- `proposed-latest-block` + `proposed-latest-state` -> these could map to the `head` topic (any block set as head, but also includes the state root associated with it) or the `block` topic (any valid block seen).  \r\n  -  If you are looking for any states resulting from any block seen that are *not* set as head, we don't expose that but we do store them in our `snapshot_cache` so it would be possible to expose them \r\n  - The `head` topic only includes block roots and state roots, but you can use both of these to query the standard API endpoints to get the [full state](https://ethereum.github.io/beacon-APIs/#/Debug/getStateV2) and [block](https://ethereum.github.io/beacon-APIs/#/Beacon/getBlockV2).  \r\n  - If this route isn't feasible, I think it'd be reasonable for us to add a non-standard events endpoint. Something like `lighthouse_events` that is structured like the `events` endpoint where we stream full blocks and beacon states.\r\n\r\n- `finalized-beacon-slot` -> `finalized_checkpoint` events topic\r\n- `forked-beacon-block` -> `chaing_reorg` events topic\r\n- `range` endpoints -> Because we prune orphaned blocks, these wouldn't be able to return multiple objects per slot, so I'm not sure there's a reason for new endpoints for these when you could query the standard [full state](https://ethereum.github.io/beacon-APIs/#/Debug/getStateV2) and [block](https://ethereum.github.io/beacon-APIs/#/Beacon/getBlockV2) endpoints one slot at a time.\r\n- An additional endpoint that you might find interesting: https://ethereum.github.io/beacon-APIs/#/Debug/getDebugChainHeads\r\n\r\n### Answers to Questions\r\n\r\n1. By default any node synced from genesis (not checkpoint synced) will be an `archival` node in the sense that it will have all blocks and all states. But, again, we *do* prune non-canonical blocks from a finalized portion of the chain. \r\n2. All consensus types are SSZ types who's merklization is spec'd out here: https://github.com/ethereum/consensus-specs/blob/dev/ssz/merkle-proofs.md",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1089205833/reactions",
      "total_count": 2,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1089323459",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1089323459",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1089323459,
    "node_id": "IC_kwDOCFeAzc5A7cHD",
    "user": {
      "login": "abdulrabbani00",
      "id": 58230246,
      "node_id": "MDQ6VXNlcjU4MjMwMjQ2",
      "avatar_url": "https://avatars.githubusercontent.com/u/58230246?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/abdulrabbani00",
      "html_url": "https://github.com/abdulrabbani00",
      "followers_url": "https://api.github.com/users/abdulrabbani00/followers",
      "following_url": "https://api.github.com/users/abdulrabbani00/following{/other_user}",
      "gists_url": "https://api.github.com/users/abdulrabbani00/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/abdulrabbani00/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/abdulrabbani00/subscriptions",
      "organizations_url": "https://api.github.com/users/abdulrabbani00/orgs",
      "repos_url": "https://api.github.com/users/abdulrabbani00/repos",
      "events_url": "https://api.github.com/users/abdulrabbani00/events{/privacy}",
      "received_events_url": "https://api.github.com/users/abdulrabbani00/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-05T20:44:27Z",
    "updated_at": "2022-04-05T20:44:27Z",
    "author_association": "NONE",
    "body": "@realbigsean - This was super helpful. A few notes:\r\n\r\n* We are only interested in the `forked` blocks for new blocks (as we are syncing from the head). We don't need this information for historical blocks.\r\n* You're absolutely correct, we don't need the `range` endpoints if we can just query each `block` and `state` from genesis by the slot number.\r\n* Using the standard API to get the full state and block might be feasible hypothetically. But from a performance perspective, it might be too slow. If possible, I think implementing the `lighthouse_events` with full blocks would be a great help.\r\n* What are your thoughts on the `missed-beacon-slot` endpoint? This would be useful in telling is which slots were skipped in real-time. \r\n\r\nI'm going to have to take a closer look at some of the events but ultimately, this has been incredibly insightful. I think we might be able to trim down a lot of the expected work.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1089323459/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1089553129",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1089553129",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1089553129,
    "node_id": "IC_kwDOCFeAzc5A8ULp",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-06T00:07:04Z",
    "updated_at": "2022-04-06T00:07:04Z",
    "author_association": "MEMBER",
    "body": "I'll add one thing about the range endpoints: fetching a range of states could be a lot faster than fetching states individually, because we reconstruct states by replaying blocks. For example if the DB has a full state at slot 2048, and the user wants states 2048-4096 then the DB will replay blocks `[2049], [2049, 2050], [2049, 2050, 2051], [2049, 2050, 2051, 2052], etc`. By replaying blocks one at a time and streaming the states we can avoid replaying some blocks multiple times, i.e. `O(n)` replays rather than `O(n^2)`.\r\n\r\nWe have quite succinct code for doing this in the [`BlockReplayer`](https://github.com/sigp/lighthouse/blob/stable/consensus/state_processing/src/block_replayer.rs), which is used to back the existing `/lighthouse/analysis/block_rewards` endpoint: https://lighthouse-book.sigmaprime.io/api-lighthouse.html#lighthouseanalysisblock_rewards",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1089553129/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1090495783",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1090495783",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1090495783,
    "node_id": "IC_kwDOCFeAzc5A_6Un",
    "user": {
      "login": "abdulrabbani00",
      "id": 58230246,
      "node_id": "MDQ6VXNlcjU4MjMwMjQ2",
      "avatar_url": "https://avatars.githubusercontent.com/u/58230246?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/abdulrabbani00",
      "html_url": "https://github.com/abdulrabbani00",
      "followers_url": "https://api.github.com/users/abdulrabbani00/followers",
      "following_url": "https://api.github.com/users/abdulrabbani00/following{/other_user}",
      "gists_url": "https://api.github.com/users/abdulrabbani00/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/abdulrabbani00/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/abdulrabbani00/subscriptions",
      "organizations_url": "https://api.github.com/users/abdulrabbani00/orgs",
      "repos_url": "https://api.github.com/users/abdulrabbani00/repos",
      "events_url": "https://api.github.com/users/abdulrabbani00/events{/privacy}",
      "received_events_url": "https://api.github.com/users/abdulrabbani00/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-06T17:00:15Z",
    "updated_at": "2022-04-13T21:39:32Z",
    "author_association": "NONE",
    "body": "# GitHub Issue: Lighthouse\r\n\r\n# Overview\r\n\r\nI would like to add a few HTTP endpoints for my team's use case. I am more than happy and willing to write all the code needed to implement these features. I only ask for guidance and help.\r\n\r\n_This is the second iteration of the proposal._\r\n\r\n## Use Case\r\n\r\nMy teams use case is as follows:\r\n\r\n1.  We want to capture every `BeaconBlock` and `BeaconState` for every slot from `genesis` to `head` in a Postgres DB.\r\n2.  We want to capture `missed` slots (slots that were skipped).\r\n3.  We would like to capture all processed `BeaconBlocks`, even the ones that are `forked` when watching the head of the chain.\r\n    1.  We would like to label the blocks that are `forked` as `forked` in the Postgres DB.\r\n\r\n## Running the Nodes\r\n\r\nOn the first go, we plan on having two `lighthouse` nodes running.\r\n\r\n1.  The sole purpose is to keep up with the head of the chain. This node will update the database with the latest information from the head.\r\n2.  An archival node that has every block since genesis available. This node will be used to fill the database for historical events, as well as missed events.\r\n\r\n# Endpoints\r\n\r\nThe following capture all the endpoints that we are hoping to expose on the beacon node, as well as potential implementations for them. The actual names and \"endpoints\" themselves can be easily changed and modified. This example is simply using dummy placeholders.\r\n\r\n## [`/lighthouse-events?topic=head`](https://github.com/ethereum/beacon-APIs/blob/master/apis/eventstream/index.yaml#L41) - Update\r\n\r\n### Result We Want\r\n\r\nUpdate the endpoint to accept a parameter, that will return the entire `block` and `state` object in either JSON or SSZ encoded format.\r\n\r\nKeep in mind that we can have multiple proposed head `BeaconBlocks` for a given slot.\r\n\r\nIf someone is listening to this endpoint they might see:\r\n\r\n```\r\n{\"slot\":\"10\", \"block\": \"SSZ_OBJECT_A\", \"state\":\"SSZ_OBJECT_X\", \"epoch_transition\":false, \"previous_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e91\", \"current_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e91\", \"execution_optimistic\": false}\r\n...\r\n{\"slot\":\"10\", \"block\": \"SSZ_OBJECT_B\", \"state\":\"SSZ_OBJECT_Y\", \"epoch_transition\":false, \"previous_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e92\", \"current_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e92\", \"execution_optimistic\": false}\r\n...\r\n{\"slot\":\"11\", \"block\": \"SSZ_OBJECT_C\", \"state\":\"SSZ_OBJECT_Z\", \"epoch_transition\":false, \"previous_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e93\", \"current_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e93\", \"execution_optimistic\": false}\r\n\r\n\r\n```\r\n\r\n### Potential Implementation\r\n\r\nUpdate the features and functionalities to the current head endpoint to capture the entire SSZ encoded objects and return them if the necessary parameter is specified.\r\n\r\n## `/eth/v1/events?topics=intermediary_slots&start_slot=x&end_slot=y`\r\n\r\n### Result We Want\r\n\r\nExpose an HTTP event stream endpoint that will stream the historical `BeaconState` from the start to the end slots provided.\r\n\r\n```\r\nParameters: {start:10, end: 12}\r\n\r\n[\r\n  {\r\n     \"Slot: 10,\r\n     \"BeaconStates\": dict_a\r\n  },\r\n  {\r\n     \"Slot: 11,\r\n     \"BeaconStates\": dict_a --> Because this slot has no BeaconBlock.\r\n  },\r\n  {\r\n     \"Slot: 12,\r\n     \"BeaconStates\": dict_c\r\n  }\r\n]\r\n\r\n\r\n```\r\n\r\n### Potential Implementaion\r\n\r\nUtilize the code for doing this in the [`BlockReplayer`](https://github.com/sigp/lighthouse/blob/stable/consensus/state_processing/src/block_replayer.rs), which is used to back the existing [`/lighthouse/analysis/block_rewards`](https://lighthouse-book.sigmaprime.io/api-lighthouse.html#lighthouseanalysisblock_rewards) endpoint.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1090495783/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1090496838",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1090496838",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1090496838,
    "node_id": "IC_kwDOCFeAzc5A_6lG",
    "user": {
      "login": "abdulrabbani00",
      "id": 58230246,
      "node_id": "MDQ6VXNlcjU4MjMwMjQ2",
      "avatar_url": "https://avatars.githubusercontent.com/u/58230246?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/abdulrabbani00",
      "html_url": "https://github.com/abdulrabbani00",
      "followers_url": "https://api.github.com/users/abdulrabbani00/followers",
      "following_url": "https://api.github.com/users/abdulrabbani00/following{/other_user}",
      "gists_url": "https://api.github.com/users/abdulrabbani00/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/abdulrabbani00/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/abdulrabbani00/subscriptions",
      "organizations_url": "https://api.github.com/users/abdulrabbani00/orgs",
      "repos_url": "https://api.github.com/users/abdulrabbani00/repos",
      "events_url": "https://api.github.com/users/abdulrabbani00/events{/privacy}",
      "received_events_url": "https://api.github.com/users/abdulrabbani00/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-06T17:01:25Z",
    "updated_at": "2022-04-06T17:01:25Z",
    "author_association": "NONE",
    "body": "@michaelsproul and @realbigsean - Thank you both for your wonderful insight. I have compiled a second iteration of the proposal. I think this is far shorter and simpler to implement. Let me know your thoughts and if there's anything else to change (if the changes are minor I will simply update the proposal above instead of creating a new proposal).",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1090496838/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1091891039",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1091891039",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1091891039,
    "node_id": "IC_kwDOCFeAzc5BFO9f",
    "user": {
      "login": "realbigsean",
      "id": 5160426,
      "node_id": "MDQ6VXNlcjUxNjA0MjY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5160426?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/realbigsean",
      "html_url": "https://github.com/realbigsean",
      "followers_url": "https://api.github.com/users/realbigsean/followers",
      "following_url": "https://api.github.com/users/realbigsean/following{/other_user}",
      "gists_url": "https://api.github.com/users/realbigsean/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/realbigsean/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/realbigsean/subscriptions",
      "organizations_url": "https://api.github.com/users/realbigsean/orgs",
      "repos_url": "https://api.github.com/users/realbigsean/repos",
      "events_url": "https://api.github.com/users/realbigsean/events{/privacy}",
      "received_events_url": "https://api.github.com/users/realbigsean/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-07T15:38:56Z",
    "updated_at": "2022-04-07T15:38:56Z",
    "author_association": "COLLABORATOR",
    "body": "@abdulrabbani00 Nice! I think the simplified spec with the additional event topics holding debug information, and the state range endpoint all seem like reasonable additions to lighthouse. \r\n\r\n> I'll add one thing about the range endpoints...\r\n\r\n@michaelsproul  This is sweet! I also noticed we have a `block_rewards` events topic gated behind a `lighthouse` feature -- that might be a good way to add full beacon block and beacon state events too. Then there'd be no need for a separate `lighthouse_events` endpoint.\r\n\r\n> What are your thoughts on the missed-beacon-slot endpoint? This would be useful in telling is which slots were skipped in real-time.\r\n\r\nIt's tough to tell in real time whether the current slot is missed because you can't know if you just haven't seen the block yet. If you'd like this type of information, the timing in Eth2 is universal so slot times can be calculated outside of lighthouse pretty easily, so you can just mark a slot as likely missed if it's its been 8 seconds (or whatever threshold you choose) since the start of the slot and you haven't received a head event.\r\n\r\n> When block a is replaced by block b as the head for slot 10. Is it safe to assume that block a can be labeled as forked?\r\n\r\n- Yes\r\n> When block a is replaced by block b as the head for slot 10. Will there be an event on the chain_reorg topic indicating the reorg?\r\n\r\n- Yes\r\n> `lighthouse bn --http --metrics --private --network prater --reconstruct-historic-states --slots-per-restore-point 32`\r\n\r\n- `--reconstruct-historic-states` is only necessary if you are checkpoint syncing \r\n> `--slots-per-restore-point`  questions\r\n- I think @michaelsproul will have a better idea about this than me",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1091891039/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1092006051",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1092006051",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1092006051,
    "node_id": "IC_kwDOCFeAzc5BFrCj",
    "user": {
      "login": "abdulrabbani00",
      "id": 58230246,
      "node_id": "MDQ6VXNlcjU4MjMwMjQ2",
      "avatar_url": "https://avatars.githubusercontent.com/u/58230246?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/abdulrabbani00",
      "html_url": "https://github.com/abdulrabbani00",
      "followers_url": "https://api.github.com/users/abdulrabbani00/followers",
      "following_url": "https://api.github.com/users/abdulrabbani00/following{/other_user}",
      "gists_url": "https://api.github.com/users/abdulrabbani00/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/abdulrabbani00/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/abdulrabbani00/subscriptions",
      "organizations_url": "https://api.github.com/users/abdulrabbani00/orgs",
      "repos_url": "https://api.github.com/users/abdulrabbani00/repos",
      "events_url": "https://api.github.com/users/abdulrabbani00/events{/privacy}",
      "received_events_url": "https://api.github.com/users/abdulrabbani00/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-07T17:24:43Z",
    "updated_at": "2022-04-07T17:24:43Z",
    "author_association": "NONE",
    "body": "@realbigsean - Thanks for the insight. I think there might be a way to simplify the spec even more and remove 2/3 endpoints.\r\n\r\nScenario:\r\n1. I query `events?topic=head`, and I get the `block` and `state` in ssz encoded format.\r\n2. I query a new endpoint: `/lighthouse-events?topic=proposed-latest-block`. This endpoint returns a json object of the `BeaconBlock`.\r\n3. I query a new endpoint: `/lighthouse-events?topic=proposed-latest-state`. This endpoint returns a json object of the `BeaconState`.\r\n\r\nThe question I have is this:\r\n1. If I query `events?topic=head` and get `block` and `state` ssz encoded. Can I simply decode these objects and get a JSON representation of them?\r\n2. Is it faster to get the smaller return object from `head` and decode `block-->BeaconBlock` and `state-->BeaconState`? Or is it faster to query the significantly larger `BeaconState` and `BeaconBody`?\r\n\r\nThe thought is, if I can listen to `head` and decode the `block` and `state` to get the `BeaconState` and `BeaconBlock` in a relatively performant manner, then it makes sense to simply do that, instead of receiving a large JSON object. Thoughts?",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1092006051/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1092012627",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1092012627",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1092012627,
    "node_id": "IC_kwDOCFeAzc5BFspT",
    "user": {
      "login": "abdulrabbani00",
      "id": 58230246,
      "node_id": "MDQ6VXNlcjU4MjMwMjQ2",
      "avatar_url": "https://avatars.githubusercontent.com/u/58230246?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/abdulrabbani00",
      "html_url": "https://github.com/abdulrabbani00",
      "followers_url": "https://api.github.com/users/abdulrabbani00/followers",
      "following_url": "https://api.github.com/users/abdulrabbani00/following{/other_user}",
      "gists_url": "https://api.github.com/users/abdulrabbani00/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/abdulrabbani00/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/abdulrabbani00/subscriptions",
      "organizations_url": "https://api.github.com/users/abdulrabbani00/orgs",
      "repos_url": "https://api.github.com/users/abdulrabbani00/repos",
      "events_url": "https://api.github.com/users/abdulrabbani00/events{/privacy}",
      "received_events_url": "https://api.github.com/users/abdulrabbani00/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-07T17:32:35Z",
    "updated_at": "2022-04-07T17:33:05Z",
    "author_association": "NONE",
    "body": "> I'll add one thing about the range endpoints: fetching a range of states could be a lot faster than fetching states individually, because we reconstruct states by replaying blocks. For example if the DB has a full state at slot 2048, and the user wants states 2048-4096 then the DB will replay blocks `[2049], [2049, 2050], [2049, 2050, 2051], [2049, 2050, 2051, 2052], etc`. By replaying blocks one at a time and streaming the states we can avoid replaying some blocks multiple times, i.e. `O(n)` replays rather than `O(n^2)`.\r\n> \r\n> We have quite succinct code for doing this in the [`BlockReplayer`](https://github.com/sigp/lighthouse/blob/stable/consensus/state_processing/src/block_replayer.rs), which is used to back the existing `/lighthouse/analysis/block_rewards` endpoint: https://lighthouse-book.sigmaprime.io/api-lighthouse.html#lighthouseanalysisblock_rewards\r\n\r\nAnother thought is, what if, instead of implementing a new endpoint that takes a `start` and `end` slot, we implement a cache? \r\n\r\nScenario:\r\n* I query: `​/eth​/v2​/debug​/beacon​/states​/10`\r\n  * Lighthouse runs block `1-10` on top of the state at block `1`.\r\n  * Lighthouse stores the state at slot `10` in a `debug_state_cache`.\r\n  * I get a JSON object.\r\n* I query: `​/eth​/v2​/debug​/beacon​/states​/11`\r\n  * Lighthouse checks a local cache, to see if there is a `state` at `debug_state_cache`. If there is, build on top of it, otherwise, run block `1-11` on top of state at slot `1`.\r\n\r\nHopefully, that makes sense. In this scenario, we would not need to add any new endpoints, we only need to implement a cache to make the historical state querying performant.  \r\n",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1092012627/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1092415202",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1092415202",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1092415202,
    "node_id": "IC_kwDOCFeAzc5BHO7i",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-08T03:53:19Z",
    "updated_at": "2022-04-08T03:53:19Z",
    "author_association": "MEMBER",
    "body": "I prefer the range approach to a cache for now, because cache logic similar to what you mention has already been implemented, but it's lurking in my `tree-states` branch (https://github.com/michaelsproul/lighthouse/tree/tree-states)  and won't be part of Lighthouse `unstable` for a while. The `tree-states` branch changes the in-memory representation of states from flat bytes to copy-on-write trees, which is what makes the state cache viable (otherwise states are like 50MB each in memory and you can't cache very many). I'm not opposed to adding an API-specific cache in the meantime though if that's the route you'd prefer to take.\r\n\r\n> If I query events?topic=head and get block and state ssz encoded. Can I simply decode these objects and get a JSON representation of them?\r\n\r\n_If_ we add a head topic that emits the full `BeaconState` and `SignedBeaconBlock`, then yeah you can convert from SSZ to JSON. It's a matter of doing an SSZ decode, and then serializing with `serde_json`.\r\n\r\n> For our use case, will --slots-per-restore-point 32 make a difference, or if we implement /lighthouse/v2/debug/beacon?states?start_slot=2048?end_slot=4096, do you think it would be just as performant to utilize --slots-per-restore-point 2048.\r\n\r\nYeah I think you'll be OK with a high SPRP if your design only requires the LH database to be accessed occasionally. If you're storing all the beacon states outside the LH DB though, then that's going to use more space than LH's DB and you may want to consider using SPRP=32 and accessing states from LH more frequently.\r\n\r\nI heard from Sean you were also considering state diffs, and we actually have something along those lines already implemented too, but on the `tree-states` branch: https://github.com/michaelsproul/lighthouse/blob/9ab7c24e5a6172a0d134ed9f4df5112c39865343/consensus/types/src/beacon_state/diff.rs#L29-L89. Again, it'll be a while before that lands. The diffs end up being 6-9MB per state (relative to the state at the previous epoch).\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1092415202/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1092782022",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1092782022",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1092782022,
    "node_id": "IC_kwDOCFeAzc5BIofG",
    "user": {
      "login": "abdulrabbani00",
      "id": 58230246,
      "node_id": "MDQ6VXNlcjU4MjMwMjQ2",
      "avatar_url": "https://avatars.githubusercontent.com/u/58230246?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/abdulrabbani00",
      "html_url": "https://github.com/abdulrabbani00",
      "followers_url": "https://api.github.com/users/abdulrabbani00/followers",
      "following_url": "https://api.github.com/users/abdulrabbani00/following{/other_user}",
      "gists_url": "https://api.github.com/users/abdulrabbani00/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/abdulrabbani00/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/abdulrabbani00/subscriptions",
      "organizations_url": "https://api.github.com/users/abdulrabbani00/orgs",
      "repos_url": "https://api.github.com/users/abdulrabbani00/repos",
      "events_url": "https://api.github.com/users/abdulrabbani00/events{/privacy}",
      "received_events_url": "https://api.github.com/users/abdulrabbani00/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-08T11:53:58Z",
    "updated_at": "2022-04-08T11:54:54Z",
    "author_association": "NONE",
    "body": "@michaelsproul \r\n\r\n> _If_ we add a head topic that emits the full `BeaconState` and `SignedBeaconBlock`, then yeah you can convert from SSZ to JSON. It's a matter of doing an SSZ decode, and then serializing with `serde_json`.\r\n\r\n* Does the current `head` topic not emit the full `BeaconState` and `SignedBeaconBlock` in an SSZ encoded format? \r\n* Also, from a performance perspective, do you think it would be better to get the SSZ encoded object and decode it or transmit the entire JSON object over the wire? If decoding SSZ --> JSON is fairly performant, it might be better to take this approach, especially if we think the `BeaconState` and `BeaconBlock` might increase in size.\r\n\r\n\r\n> I heard from Sean you were also considering state diffs, and we actually have something along those lines already implemented too, but on the `tree-states` branch: https://github.com/michaelsproul/lighthouse/blob/9ab7c24e5a6172a0d134ed9f4df5112c39865343/consensus/types/src/beacon_state/diff.rs#L29-L89. Again, it'll be a while before that lands. The diffs end up being 6-9MB per state (relative to the state at the previous epoch).\r\n\r\nThis is very very interesting work. I will have to take a closer look at this. If we can send these statediff objects over the wire then it might be worth it to consider them in our application design and architecture.\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1092782022/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1094984726",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1094984726",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1094984726,
    "node_id": "IC_kwDOCFeAzc5BRCQW",
    "user": {
      "login": "abdulrabbani00",
      "id": 58230246,
      "node_id": "MDQ6VXNlcjU4MjMwMjQ2",
      "avatar_url": "https://avatars.githubusercontent.com/u/58230246?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/abdulrabbani00",
      "html_url": "https://github.com/abdulrabbani00",
      "followers_url": "https://api.github.com/users/abdulrabbani00/followers",
      "following_url": "https://api.github.com/users/abdulrabbani00/following{/other_user}",
      "gists_url": "https://api.github.com/users/abdulrabbani00/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/abdulrabbani00/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/abdulrabbani00/subscriptions",
      "organizations_url": "https://api.github.com/users/abdulrabbani00/orgs",
      "repos_url": "https://api.github.com/users/abdulrabbani00/repos",
      "events_url": "https://api.github.com/users/abdulrabbani00/events{/privacy}",
      "received_events_url": "https://api.github.com/users/abdulrabbani00/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-11T12:23:40Z",
    "updated_at": "2022-04-11T14:17:14Z",
    "author_association": "NONE",
    "body": "> # GitHub Issue: Lighthouse\r\n> # Overview\r\n> I would like to add a few HTTP endpoints for my team's use case. I am more than happy and willing to write all the code needed to implement these features. I only ask for guidance and help.\r\n> \r\n> _This is the second iteration of the proposal._\r\n> \r\n> ## Use Case\r\n> My teams use case is as follows:\r\n> \r\n> 1. We want to capture every `BeaconBlock` and `BeaconState` for every slot from `genesis` to `head` in a Postgres DB.\r\n> 2. We want to capture `missed` slots (slots that were skipped).\r\n> 3. We would like to capture all processed `BeaconBlocks`, even the ones that are `forked` when watching the head of the chain.\r\n>    \r\n>    1. We would like to label the blocks that are `forked` as `forked` in the Postgres DB.\r\n> \r\n> ## Running the Nodes\r\n> On the first go, we plan on having two `lighthouse` nodes running.\r\n> \r\n> 1. The sole purpose is to keep up with the head of the chain. This node will update the database with the latest information from the head.\r\n> 2. An archival node that has every block since genesis available. This node will be used to fill the database for historical events, as well as missed events.\r\n> \r\n> # Endpoints\r\n> The following capture all the endpoints that we are hoping to expose on the beacon node, as well as potential implementations for them. The actual names and \"endpoints\" themselves can be easily changed and modified. This example is simply using dummy placeholders.\r\n> \r\n> ## [`/lighthouse-events?topic=head`](https://github.com/ethereum/beacon-APIs/blob/master/apis/eventstream/index.yaml#L41) - Update\r\n> ### Result We Want\r\n> Update the endpoint to accept a parameter, that will return the entire `block` and `state` object in either JSON or SSZ encoded format.\r\n> \r\n> Keep in mind that we can have multiple proposed head `BeaconBlocks` for a given slot.\r\n> \r\n> If someone is listening to this endpoint they might see:\r\n> \r\n> ```\r\n> {\"slot\":\"10\", \"block\": \"SSZ_OBJECT_A\", \"state\":\"SSZ_OBJECT_X\", \"epoch_transition\":false, \"previous_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e91\", \"current_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e91\", \"execution_optimistic\": false}\r\n> ...\r\n> {\"slot\":\"10\", \"block\": \"SSZ_OBJECT_B\", \"state\":\"SSZ_OBJECT_Y\", \"epoch_transition\":false, \"previous_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e92\", \"current_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e92\", \"execution_optimistic\": false}\r\n> ...\r\n> {\"slot\":\"11\", \"block\": \"SSZ_OBJECT_C\", \"state\":\"SSZ_OBJECT_Z\", \"epoch_transition\":false, \"previous_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e93\", \"current_duty_dependent_root\":\"0x5e0043f107cb57913498fbf2f99ff55e730bf1e151f02f221e977c91a90a0e93\", \"execution_optimistic\": false}\r\n> ```\r\n> \r\n> ### Potential Implementation\r\n> Update the features and functionalities to the current head endpoint to capture the entire SSZ encoded objects and return them if the necessary parameter is specified.\r\n> \r\n> ## `/lighthouse/v2/debug/beacon?states?start_slot=x?end_slot=y`\r\n> ### Result We Want\r\n> Expose an HTTP event stream endpoint that will stream the historical `BeaconState` from the start to the end slots provided.\r\n> \r\n> ```\r\n> Parameters: {start:10, end: 12}\r\n> \r\n> [\r\n>   {\r\n>      \"Slot: 10,\r\n>      \"BeaconStates\": dict_a\r\n>   },\r\n>   {\r\n>      \"Slot: 11,\r\n>      \"BeaconStates\": dict_a --> Because this slot has no BeaconBlock.\r\n>   },\r\n>   {\r\n>      \"Slot: 12,\r\n>      \"BeaconStates\": dict_c\r\n>   }\r\n> ]\r\n> ```\r\n> \r\n> ### Potential Implementaion\r\n> Utilize the code for doing this in the [`BlockReplayer`](https://github.com/sigp/lighthouse/blob/stable/consensus/state_processing/src/block_replayer.rs), which is used to back the existing [`/lighthouse/analysis/block_rewards`](https://lighthouse-book.sigmaprime.io/api-lighthouse.html#lighthouseanalysisblock_rewards) endpoint.\r\n\r\n@michaelsproul and @realbigsean - I believe this should be the last proposal here.\r\n\r\nI update the `head?topics` endpoint to accept a new parameter which would provide the entire SSZ encoded object or JSON  for the `state` and the `block`. Let me know if this is feasible, or if we will have to move this functionality to a non-standard endpoint. If I can get your teams sign off and blessing, I can start working on the implementation.\r\n\r\nAlso: \r\n> * Also, from a performance perspective, do you think it would be better to get the SSZ encoded object and decode it or transmit the entire JSON object over the wire? If decoding SSZ --> JSON is fairly performant, it might be better to take this approach, especially if we think the `BeaconState` and `BeaconBlock` might increase in size.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1094984726/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1101472858",
    "html_url": "https://github.com/sigp/lighthouse/issues/3143#issuecomment-1101472858",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/3143",
    "id": 1101472858,
    "node_id": "IC_kwDOCFeAzc5BpyRa",
    "user": {
      "login": "abdulrabbani00",
      "id": 58230246,
      "node_id": "MDQ6VXNlcjU4MjMwMjQ2",
      "avatar_url": "https://avatars.githubusercontent.com/u/58230246?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/abdulrabbani00",
      "html_url": "https://github.com/abdulrabbani00",
      "followers_url": "https://api.github.com/users/abdulrabbani00/followers",
      "following_url": "https://api.github.com/users/abdulrabbani00/following{/other_user}",
      "gists_url": "https://api.github.com/users/abdulrabbani00/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/abdulrabbani00/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/abdulrabbani00/subscriptions",
      "organizations_url": "https://api.github.com/users/abdulrabbani00/orgs",
      "repos_url": "https://api.github.com/users/abdulrabbani00/repos",
      "events_url": "https://api.github.com/users/abdulrabbani00/events{/privacy}",
      "received_events_url": "https://api.github.com/users/abdulrabbani00/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-04-18T14:57:09Z",
    "updated_at": "2022-04-18T14:57:09Z",
    "author_association": "NONE",
    "body": "Hello Guys,\r\n\r\nWe have decided we are going to stick with the currently existing features within the lighthouse for our use case. The current performance we are seeing is perfectly fine for what we are trying to achieve. I appreciate all your help, and if we need anything else I will be sure to raise another issue.\r\n\r\nPlease let me know if there is anything I can ever do for your team.\r\n\r\nThank you,\r\nAbdul Rabbani",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1101472858/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 1,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
