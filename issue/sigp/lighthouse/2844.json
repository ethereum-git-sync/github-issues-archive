{
  "url": "https://api.github.com/repos/sigp/lighthouse/issues/2844",
  "repository_url": "https://api.github.com/repos/sigp/lighthouse",
  "labels_url": "https://api.github.com/repos/sigp/lighthouse/issues/2844/labels{/name}",
  "comments_url": "https://api.github.com/repos/sigp/lighthouse/issues/2844/comments",
  "events_url": "https://api.github.com/repos/sigp/lighthouse/issues/2844/events",
  "html_url": "https://github.com/sigp/lighthouse/issues/2844",
  "id": 1067850715,
  "node_id": "I_kwDOCFeAzc4_phvb",
  "number": 2844,
  "title": "Idea: I/O queue to accelerate block processing",
  "user": {
    "login": "michaelsproul",
    "id": 4452260,
    "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/michaelsproul",
    "html_url": "https://github.com/michaelsproul",
    "followers_url": "https://api.github.com/users/michaelsproul/followers",
    "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
    "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
    "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
    "repos_url": "https://api.github.com/users/michaelsproul/repos",
    "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
    "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1232620456,
      "node_id": "MDU6TGFiZWwxMjMyNjIwNDU2",
      "url": "https://api.github.com/repos/sigp/lighthouse/labels/RFC",
      "name": "RFC",
      "color": "4aaa19",
      "default": false,
      "description": "Request for comment"
    },
    {
      "id": 1999784343,
      "node_id": "MDU6TGFiZWwxOTk5Nzg0MzQz",
      "url": "https://api.github.com/repos/sigp/lighthouse/labels/optimization",
      "name": "optimization",
      "color": "f9de40",
      "default": false,
      "description": "Something to make Lighthouse run more efficiently."
    },
    {
      "id": 2336798682,
      "node_id": "MDU6TGFiZWwyMzM2Nzk4Njgy",
      "url": "https://api.github.com/repos/sigp/lighthouse/labels/database",
      "name": "database",
      "color": "C01C9D",
      "default": false,
      "description": ""
    }
  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 3,
  "created_at": "2021-12-01T01:31:51Z",
  "updated_at": "2022-09-16T01:32:55Z",
  "closed_at": null,
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "body": "## Description\r\n\r\nIn https://github.com/sigp/lighthouse/pull/2833 we reduce the frequency with which full states are stored in the hot database. However, this just works around the underlying issue that database writes take substantial time for full states.\r\n\r\nIn lieu of more drastic database restructuring I think we might be able to take the database write time off the critical path by serializing all our I/O and completing it on a dedicated background thread. We want to avoid a situation where out of order writes violate an invariant of the database like `block in db --> block's state in db` or `block in fork choice --> block in db`. I think we're in a good position to guarantee this by hooking [`HotColdDB::do_atomically`](https://github.com/sigp/lighthouse/blob/fff01b24ddedcd54486e374460855ca20d3dd232/beacon_node/store/src/hot_cold_store.rs#L556-L584) to run in the background. For example during block processing we would push the storage ops for the state and block in a single batch to the background thread. Later we may push fork choice to the background thread in a separate batch. Because `do_atomically` serializes requests (completes them in order), there's no way for the fork choice write to commit before the block/state write. In case of a crash (or shutdown) any incomplete I/O ops will just get dropped and the on-disk database will revert to whatever was most recently written successfully.\r\n\r\nThe key part of this scheme is a background thread within the store which keeps a queue of `Vec<StoreOp<E>>` for completion. We should bound the size of this queue to keep memory usage under control in case of I/O saturation (at which point we block and performance returns to what it is currently). The other important thing to keep in mind is that writes need to be _observable_ by other threads as soon as `do_atomically` returns. In order to achieve this I think we can cache the to-be-written blocks and states in memory, and return them from `get_block`, `get_state`. Other writes are trickier to make observable, because we just see generic key -> value mappings. We could limit the background writing to just apply to batches of blocks and states, and continue blocking for every other write (clearing the pending block/state queue before doing so). _Or_ we could push the I/O queuing down a level into the key-value store, so that it caches the raw `key -> value` mappings in memory (Ã  la `MemoryStore`) and the higher-level DB code doesn't need to change... This may actually be cleanest + most generic :thinking: Potential downsides of the KV-queuing approach are:\r\n\r\n- We pay a serialization/deserialization cost for writes/reads because the KV-store caches the bytes in memory rather than the objects.\r\n- We can't take advantage of in-memory de-duplication of `BeaconState`s (if #2806 is implemented).\r\n- We duplicate what fast KV-stores try to do anyway: write to memory (mem-mapped file) first and flush to disk later (on eviction from OS page cache). This isn't so much of a downside, as actually switching the BN's KV-store to MDBX would be a lot of work and require a breaking schema change (_unlike_ a queue on top of LevelDB).\r\n\r\nThere are also potentially other issues with synchronising the cold DB and hot DB during migrations. We may need to block in such cases.\r\n\r\n\r\n",
  "closed_by": {
    "login": "michaelsproul",
    "id": 4452260,
    "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/michaelsproul",
    "html_url": "https://github.com/michaelsproul",
    "followers_url": "https://api.github.com/users/michaelsproul/followers",
    "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
    "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
    "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
    "repos_url": "https://api.github.com/users/michaelsproul/repos",
    "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
    "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/2844/reactions",
    "total_count": 2,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 2
  },
  "timeline_url": "https://api.github.com/repos/sigp/lighthouse/issues/2844/timeline",
  "performed_via_github_app": null,
  "state_reason": "reopened"
}
[
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/999200396",
    "html_url": "https://github.com/sigp/lighthouse/issues/2844#issuecomment-999200396",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2844",
    "id": 999200396,
    "node_id": "IC_kwDOCFeAzc47jpaM",
    "user": {
      "login": "paulhauner",
      "id": 6660660,
      "node_id": "MDQ6VXNlcjY2NjA2NjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/paulhauner",
      "html_url": "https://github.com/paulhauner",
      "followers_url": "https://api.github.com/users/paulhauner/followers",
      "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
      "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
      "organizations_url": "https://api.github.com/users/paulhauner/orgs",
      "repos_url": "https://api.github.com/users/paulhauner/repos",
      "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/paulhauner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-12-22T01:01:15Z",
    "updated_at": "2021-12-22T01:01:15Z",
    "author_association": "MEMBER",
    "body": "The \"early attester cache\" over in #2872 is similar to this (as pointed out by @michaelsproul).",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/999200396/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1019595350",
    "html_url": "https://github.com/sigp/lighthouse/issues/2844#issuecomment-1019595350",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2844",
    "id": 1019595350,
    "node_id": "IC_kwDOCFeAzc48xcpW",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-01-23T23:53:11Z",
    "updated_at": "2022-01-23T23:53:11Z",
    "author_association": "MEMBER",
    "body": "Closing in favour of #2872",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1019595350/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1248814240",
    "html_url": "https://github.com/sigp/lighthouse/issues/2844#issuecomment-1248814240",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2844",
    "id": 1248814240,
    "node_id": "IC_kwDOCFeAzc5Kb2Sg",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-09-16T01:32:55Z",
    "updated_at": "2022-09-16T01:32:55Z",
    "author_association": "MEMBER",
    "body": "I'm going to revisit this in the context of `tree-states`. Although the early attester cache takes writes off the hot path of attesting, they still happen and consume resources at some point. I think we could instead store more of the unfinalized state in memory, and write it to disk in batches periodically. This way we can hopefully put data in its final position when writing it, rather than writing it to the hot DB and then deleting it 6 minutes later.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1248814240/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
