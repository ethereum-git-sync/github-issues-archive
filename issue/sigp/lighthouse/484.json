{
  "url": "https://api.github.com/repos/sigp/lighthouse/issues/484",
  "repository_url": "https://api.github.com/repos/sigp/lighthouse",
  "labels_url": "https://api.github.com/repos/sigp/lighthouse/issues/484/labels{/name}",
  "comments_url": "https://api.github.com/repos/sigp/lighthouse/issues/484/comments",
  "events_url": "https://api.github.com/repos/sigp/lighthouse/issues/484/events",
  "html_url": "https://github.com/sigp/lighthouse/issues/484",
  "id": 476016869,
  "node_id": "MDU6SXNzdWU0NzYwMTY4Njk=",
  "number": 484,
  "title": "Optimise state storage with Chunked Rangesâ„¢",
  "user": {
    "login": "michaelsproul",
    "id": 4452260,
    "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/michaelsproul",
    "html_url": "https://github.com/michaelsproul",
    "followers_url": "https://api.github.com/users/michaelsproul/followers",
    "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
    "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
    "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
    "repos_url": "https://api.github.com/users/michaelsproul/repos",
    "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
    "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 985647284,
      "node_id": "MDU6TGFiZWw5ODU2NDcyODQ=",
      "url": "https://api.github.com/repos/sigp/lighthouse/labels/enhancement",
      "name": "enhancement",
      "color": "a2eeef",
      "default": true,
      "description": "New feature or request"
    },
    {
      "id": 985647289,
      "node_id": "MDU6TGFiZWw5ODU2NDcyODk=",
      "url": "https://api.github.com/repos/sigp/lighthouse/labels/wontfix",
      "name": "wontfix",
      "color": "ffffff",
      "default": true,
      "description": "This will not be worked on"
    },
    {
      "id": 1157252215,
      "node_id": "MDU6TGFiZWwxMTU3MjUyMjE1",
      "url": "https://api.github.com/repos/sigp/lighthouse/labels/major-task",
      "name": "major-task",
      "color": "c18d3f",
      "default": false,
      "description": "A significant amount of work or conceptual task."
    },
    {
      "id": 1232620456,
      "node_id": "MDU6TGFiZWwxMjMyNjIwNDU2",
      "url": "https://api.github.com/repos/sigp/lighthouse/labels/RFC",
      "name": "RFC",
      "color": "4aaa19",
      "default": false,
      "description": "Request for comment"
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": {
    "login": "michaelsproul",
    "id": 4452260,
    "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/michaelsproul",
    "html_url": "https://github.com/michaelsproul",
    "followers_url": "https://api.github.com/users/michaelsproul/followers",
    "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
    "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
    "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
    "repos_url": "https://api.github.com/users/michaelsproul/repos",
    "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
    "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
    "type": "User",
    "site_admin": false
  },
  "assignees": [
    {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    }
  ],
  "milestone": null,
  "comments": 4,
  "created_at": "2019-08-02T06:23:42Z",
  "updated_at": "2019-08-12T00:18:45Z",
  "closed_at": "2019-08-12T00:18:16Z",
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "body": "## Motivation\r\n\r\nAt the moment we duplicate _a lot_ of data when we store `BeaconState`s in the database. For example, the `active_index_roots` vector is `2**16 elements * 32 bytes = 2MiB` in size, is updated only once per epoch, and is stored in every single state! Over the course of the time it takes to change every element in that vector (`2**16` epochs), this field alone accounts for `2**16 epochs * 64 slots per epoch * 2MiB per state = 8 TiB`!!! All that for only two vectors worth of unique values, i.e. `4MiB` of data!\r\n\r\n## Basic Idea\r\n\r\nRather than duplicating data in every `BeaconState`, we should store the contents of each vector in the database separately, and reconstruct `BeaconState`s on-demand. This works for vectors which are updated one element at a time in a predictable way (once-per-slot, once-per-epoch, etc), but doesn't help when it comes to fields like the validator registry (further work).\r\n\r\nWhichever key-value database we use (cf. https://github.com/sigp/lighthouse/issues/483), I think it's safe to say that it will satisfy these two properties:\r\n\r\n1. Reading some number of bytes using a small number of queries (keys) will be faster than reading the same number of bytes using a large number of queries. In other words: storing a vector of length N in _chunks_ will be more read-efficient than storing the elements individually and performing N reads every time we want to construct the vector.\r\n2. Looking up multiple keys in a contiguous range is faster than looking up disparate keys from different parts of the DB.\r\n\r\nI did a few rough benchmarks on LevelDB using our wrappers, and both these assumptions seem to hold true (see [db_bench](https://github.com/michaelsproul/lighthouse/tree/db_bench)). The crux of this RFC is exploit both of these properties when storing vectors.\r\n\r\nLet `v: FixedVector<T, N>` be a vector, and let `k` be a \"chunk size\". To store `v` in the database, we use a table (sequential range of keys), where each entry contains _multiple_ chunks (to account for forks).\r\n\r\n```rust\r\nstruct ChunkedEntry<T> {\r\n    /// Value used to identify the fork we're on (more on this later)\r\n    id: Hash256,\r\n    /// Dynamic vector of length at least 1, and at most k\r\n    values: Vec<T>,\r\n}\r\n```\r\n\r\nThe table is conceptually a map from `u64 => Vec<ChunkedEntry>`, implemented by the KV store. The `u64` index `i` is mapped to a 32-byte key under a prefix determined by the field name, like `hash(\"active_index_roots\")[..24] + i.to_bytes()`. The _values_ stored in the DB are serialised forms of `ChunkedEntry`, which are `32 + 1 + k * s(T)` bytes in the worst-case, where `s(T)` is the size of `T` in bytes, and 1 byte is used to represent the length (which is fine for `k < 256`).\r\n\r\nMore on those indexes: the way the table is indexed depends on the update pattern of the field. For a once-per-epoch field like `active_index_roots`, the index to use is `i = epoch / k`, with `j = epoch % k` acting as the index into `ChunkedEntry::values`.\r\n\r\n## Handling Forks\r\n\r\nThe `ChunkedEntry::id` field is intended to allow us to distinguish between chunks stored for different forks. If we have a chain beginning from a state `A` and forking at `C`, like `A <- B <- C <- {D or E}`, then we store _two_ chunked entries at the same index, one with the values for each fork.\r\n\r\nFor now assume we have a vector that is updated every slot, let `k = 4`, and let `v(S)` denote the value of the new vector element introduced at state `S`. The table looks like:\r\n\r\n```\r\nindex: u64 | chunked entries: Vec<ChunkedEntry>\r\n---------------------------------------------------------------------\r\n        0  | [[id1: v(A) v(B) v(C) v(D)], [id2: v(A) v(B) v(C) v(E)]]\r\n```\r\n\r\nNow let's consider what happens when we've stored \"light\" versions of the states `A..E` on disk, and want to reconstruct the vector for some states. If we want to look-up `D` or `E`, it'd be good if we could match some property of `D` or `E` against the IDs of the entries. What about the state root? To be clear:\r\n\r\n**Let the ID field of a ChunkedEntry be equal to the _state root_ of the state from which the _last_ value in the chunk was taken.**\r\n\r\nIn the example above we'd have `id1 = state_root(D)` and `id2 = state_root(E)`. When constructing the states `D` or `E` we then simply pick the entry with the matching state root (presumably we know the state roots of any states we're attempting to construct -- this seems like a reasonable assumption). Before the fork, the entry would be `[state_root(C): v(A) v(B) v(C)]`, and we'd mutate/update it when storing the values for `D`/`E`.\r\n\r\nBut what if we've got the values for `D` and `E` stored already and we want to reconstruct state `C`? The state root for `C` doesn't match either of the IDs. In this case, we should look up the successor state roots of `C` (namely `D` _and_ `E`) and use those to match against the IDs in the table. It should be sufficient to choose one of the possible successors, and we should be able to know we're in this case based on the state's slot modulo `k`. In the worst case, maybe we'll need to grab a bunch of state roots that succeed `C` and look for them in the bucket.\r\n\r\nHow do we know the successor states? And what IDs do we use for the vector of state roots themselves? Read on!\r\n\r\n## State Roots & Block Roots\r\n\r\nIn this scheme, state roots and block roots are handled differently to other vectors (recall that the `BeaconState` contains `state_roots` and `block_roots` fixed-len vectors).\r\n\r\n**For `state_roots` let the ID be equal to the state root of the state previous to the state who's state root is stored in the first entry of the chunk.**\r\n\r\nThis creates a thread of continuity between indices in the table, allowing us to traverse backwards from any `(state_root, slot)` pair. For example, the linear chain `A -> B -> .. -> H` would have its state roots (abbreviated `r(S)`) stored as follows:\r\n\r\n```\r\nindex: u64 | chunked entries: Vec<ChunkedEntry>\r\n---------------------------------------------------------------------\r\n        0  | [[0x00: r(A) r(B) r(C) r(D)]\r\n        1  | [[r(D): r(E) r(F) r(G) r(H)]\r\n```\r\n\r\nFor block roots we do something similar (use the previous block root as the ID).\r\n\r\nThen, constructing a full state from a state root looks something like:\r\n\r\n1. Look up the light state in the database, this yields the slot if it is not already known, but none of the vector fields which are stored separately.\r\n2. Construct the `state_roots` field with a range query over the on-disk state roots table (based on the slot). Choose from multiple chunks by matching the _entries_ of the ChunkedEntry against the state root of interest. Backtrack using the IDs of the chunked entries.\r\n3. Construct the `block_roots` field similarly.\r\n4. Construct all the other vector fields with reference to the already constructed `state_roots`. Use a range query on the field's table, then choose between forks based on the relevant entries of `state_roots` (some kind of `zip`).\r\n\r\n## Relevant BeaconState Fields\r\n\r\n* `block_roots`: once-per-slot, 8192 entries, 32 bytes each\r\n* `state_roots`: once-per-slot, 8192 entries, 32 bytes each\r\n* `randao_mixes`: once-per-slot, 65536 entries, 32 bytes each\r\n* `active_index_roots`: once-per-epoch, 65536 entries, 32 bytes each\r\n* `compact_committees_roots`: once-per-epoch, 65536 entries, 32 bytes each\r\n\r\nThe potential savings are, frankly, enormous. Don't pass up on this fantastic deal!! [humour]\r\n\r\n## Nice Properties\r\n\r\n* Linear space usage. Storing a `Vector<T, N>` requires `N/k` buckets of size `33 + k s(T)` bytes, i.e. `33N/k + N s(T)` bytes, which is a tad more than the theoretical minimum `N s(T)`. For our active roots example from earlier, this is an overhead of only `2 * 33 * 65536 / 8 = 528KiB`, which is a lot better than ~8TiB.\r\n* Easy garbage collection. Once blocks are finalised, one can scan the database and hose out any chunked entries for forks that didn't eventuate to anything.\r\n\r\n## Next Steps\r\n\r\n* How bad is it to be increasing the size of values in the NoSQL database so frequently? Should we pre-allocate every chunk to contain a full `k` elements initialised to 0?\r\n* What is the optimal value for `k`? High values mean more duplication in the case of forks, but also more efficient use of space when there is no forking. Higher values also mean bigger writes when updating a single bucket. Lots of factors to trade-off against each other.\r\n* Implement a prototype?\r\n\r\n## Future Work\r\n\r\nThese are all out of scope for this issue:\r\n\r\n* Optimising storage of fields with more complex update patterns, like `validators`, `balances`, `slashings`, etc (hard).\r\n* Optimising storage of fields with similar-ish update patterns, like `current_crosslinks` which is updated as-a-whole, once per epoch (easy-ish).\r\n* Optimising all the variable-length lists that are append-only, like `current_epoch_attestations`. We could probably store just new entries in the states themselves, and reconstruct the full vectors from the concatenation of entries in previous states (easy-ish).\r\n\r\n## Addendum\r\n\r\n1. The efficacy of range queries seems to be common knowledge in the NoSQL community, but is implied by [this](https://github.com/facebook/rocksdb/wiki/RocksDB-Tuning-Guide#prefix-databases)\r\n2. I don't think we need to store a length on-disk when storing a `Vec<ChunkedEntry>`, as each `ChunkedEntry` knows its size. Proof-of-concept impl [here](https://github.com/michaelsproul/lighthouse/blob/0e978c5c9c64019c5522b72d67ad6396007a2557/db_bench/src/lib.rs#L85-L96).",
  "closed_by": {
    "login": "michaelsproul",
    "id": 4452260,
    "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/michaelsproul",
    "html_url": "https://github.com/michaelsproul",
    "followers_url": "https://api.github.com/users/michaelsproul/followers",
    "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
    "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
    "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
    "repos_url": "https://api.github.com/users/michaelsproul/repos",
    "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
    "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/484/reactions",
    "total_count": 1,
    "+1": 1,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/sigp/lighthouse/issues/484/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/518110255",
    "html_url": "https://github.com/sigp/lighthouse/issues/484#issuecomment-518110255",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/484",
    "id": 518110255,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUxODExMDI1NQ==",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-08-05T06:56:05Z",
    "updated_at": "2019-08-05T06:56:05Z",
    "author_association": "MEMBER",
    "body": "@paulhauner and I had a meeting offline where we discussed this issue and our conclusions were:\r\n\r\n* We'll tackle tree hash caching (#440) separately for now, because the requirements are different: we want tree hash caching only for recent states, whereas we want the DB store to be long-term. There's also an issue with the tree hashes of chunks not being relevant to the tree hash of the whole vector. Even though each chunk will sit at an (even) index `j * k`, the chunk containing the current/slot epoch will usually be composed of two chunks from the database, meaning that any cached hashes for those chunks are irrelevant, and likewise for the path from that chunk to the root. The issue isn't insurmountable but we'll keep it separate for now.\r\n* There's an alternative formulation of the original scheme that might be useful to have up our sleeve if the write performance is poor. Rather than storing a `Vec<ChunkedEntry>` at each key, we could instead store one `ChunkedEntry` per key, where each key is `i * F + j`, with `i` being the original index (`slot / k`, etc), `F` being the maximum number of forks and `j` being a fork index. The upside is that we can still do range queries, and with compaction/GC the values will end up being stored contiguously (with the values from irrelevant forks deleted). The downside is that it requires us to fix a maximum number of forks.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/518110255/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/518454011",
    "html_url": "https://github.com/sigp/lighthouse/issues/484#issuecomment-518454011",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/484",
    "id": 518454011,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUxODQ1NDAxMQ==",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-08-06T00:55:47Z",
    "updated_at": "2019-08-06T00:55:47Z",
    "author_association": "MEMBER",
    "body": "I'm going to start prototyping this",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/518454011/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/519730502",
    "html_url": "https://github.com/sigp/lighthouse/issues/484#issuecomment-519730502",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/484",
    "id": 519730502,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUxOTczMDUwMg==",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-08-09T00:10:16Z",
    "updated_at": "2019-08-09T00:10:16Z",
    "author_association": "MEMBER",
    "body": "Whilst prototyping I've noticed an issue with this idea:\r\n\r\n* The `state_roots` of a given `state` do not contain enough history to successfully reconstruct the `randao_mixes`, `active_index_roots` or `compact_committees_roots`. This is obvious in hindsight, as these vectors are long-term archives (~0.8 years of history), rather than short-term archives (~13 hours of state roots). While it would be possible to work around this by loading _more_ state roots from the database, it would somewhat defeat the point. To load enough state roots to cover the `2**16` epochs of history would require looking up `2**16 * 64 / k` keys, which unless `k` is very large, is about as bad as looking up `2**16` keys individually, thus defeating the point (we want to read all the values of the vector with substantially less than `2**16` key lookups).\r\n\r\n@paulhauner came up with an alternative plan which is much simpler and doesn't suffer from this short-coming, namely:\r\n\r\n* Store full `BeaconState`s replete with duplicated entries from the present slot back to the last finalised state. For states before the last finalised state, store their vector values, list values and other duplicated information in tables like the ones above, but without any IDs to discriminate forks, because we've finalised and only have a single chain. These tables can even be stored in a separate \"cold DB\", possibly on a separate disk (like an HDD), similar to Geth's freezer.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/519730502/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 1,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/520273003",
    "html_url": "https://github.com/sigp/lighthouse/issues/484#issuecomment-520273003",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/484",
    "id": 520273003,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUyMDI3MzAwMw==",
    "user": {
      "login": "michaelsproul",
      "id": 4452260,
      "node_id": "MDQ6VXNlcjQ0NTIyNjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4452260?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/michaelsproul",
      "html_url": "https://github.com/michaelsproul",
      "followers_url": "https://api.github.com/users/michaelsproul/followers",
      "following_url": "https://api.github.com/users/michaelsproul/following{/other_user}",
      "gists_url": "https://api.github.com/users/michaelsproul/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/michaelsproul/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/michaelsproul/subscriptions",
      "organizations_url": "https://api.github.com/users/michaelsproul/orgs",
      "repos_url": "https://api.github.com/users/michaelsproul/repos",
      "events_url": "https://api.github.com/users/michaelsproul/events{/privacy}",
      "received_events_url": "https://api.github.com/users/michaelsproul/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-08-12T00:18:14Z",
    "updated_at": "2019-08-12T00:18:14Z",
    "author_association": "MEMBER",
    "body": "Closing, the prototype code is preserved [here](https://github.com/michaelsproul/lighthouse/tree/chunked-vec).",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/520273003/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
