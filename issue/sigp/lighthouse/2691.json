{
  "url": "https://api.github.com/repos/sigp/lighthouse/issues/2691",
  "repository_url": "https://api.github.com/repos/sigp/lighthouse",
  "labels_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691/labels{/name}",
  "comments_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691/comments",
  "events_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691/events",
  "html_url": "https://github.com/sigp/lighthouse/issues/2691",
  "id": 1020705074,
  "node_id": "I_kwDOCFeAzc481rky",
  "number": 2691,
  "title": "Optimistic post-merge sync",
  "user": {
    "login": "paulhauner",
    "id": 6660660,
    "node_id": "MDQ6VXNlcjY2NjA2NjA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/paulhauner",
    "html_url": "https://github.com/paulhauner",
    "followers_url": "https://api.github.com/users/paulhauner/followers",
    "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
    "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
    "organizations_url": "https://api.github.com/users/paulhauner/orgs",
    "repos_url": "https://api.github.com/users/paulhauner/repos",
    "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
    "received_events_url": "https://api.github.com/users/paulhauner/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1232620456,
      "node_id": "MDU6TGFiZWwxMjMyNjIwNDU2",
      "url": "https://api.github.com/repos/sigp/lighthouse/labels/RFC",
      "name": "RFC",
      "color": "4aaa19",
      "default": false,
      "description": "Request for comment"
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 9,
  "created_at": "2021-10-08T05:13:11Z",
  "updated_at": "2022-10-21T02:43:05Z",
  "closed_at": "2022-10-21T02:43:04Z",
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "body": "## Description\r\n\r\nThis is a tracking and discussion issue for implementing \"optimistic\" Beacon Chain (BC) sync once the merge-fork-epoch has passed. It aims to collate the lessons learned and information shared in the following two Lighthouse PRs:\r\n\r\n- https://github.com/sigp/lighthouse/pull/2683\r\n- https://github.com/sigp/lighthouse/pull/2686\r\n\r\n*This is a work-in-progress effort to maintain my notes in an organised fashion.*\r\n\r\n## Terminology\r\n\r\n- *Merge Fork*: I use this to refer to the point at which the BC passes the [`MERGE_FORK_EPOCH`](https://github.com/ethereum/consensus-specs/blob/ceb17a74e6f7e18d5c9303173536ec5d4fdf866c/configs/mainnet.yaml#L37). PoW Ethereum can (theoretically) exist indefinitely beyond this point.\r\n- *Terminal Block (TB) Inclusion:* I use this to refer to the point in the BC where `get_terminal_pow_block`\r\n first returns `Some(pow_block)` and it is included by reference as the parent of an `ExecutionPayload` in the BC. \r\nThis must happen either at or after the Merge Fork. PoW Ethereum ends here.\r\n- *Execution Layer (EL) Clients*: existing \"eth1\" clients modified to work with the merge. Think EthereumJS, Nethermind, Besu, Erigon, Geth, etc.\r\n- *Consensus Layer (CL) Clients*: existing \"eth2\" clients modified to work with the merge. Think Lodestar, Nimbus, Teku, Lighthouse, Prysm.\r\n\r\n## Optimistic Sync\r\n\r\nAfter TB inclusion on the BC, if we follow the [specs](https://github.com/ethereum/consensus-specs/tree/v1.1.1/specs/merge) exactly then we are simply unable to import beacon blocks without a connection to an EL client that is synced to our head (or later).\r\n\r\nWhilst this is nice from a specification point of view, it's not great in practice. EL clients have developed very advanced ways of syncing the Ethereum state across long block-spans. Being spoon-fed block-by-block from a CL client is a major step backwards.\r\n\r\nIn order for EL clients to be able to use their fancy sync mechanisms, the CL clients need to zoom ahead and obtain all the valid beacon blocks they can and send the execution payloads to the EL clients. Ideally, the CL clients zoom to the head of the BC and are able to start sharing the latest, tip-of-the-chain `execution_payload`s with the EL. This gives the EL a nice big, juicy chain segment to sync.\r\n\r\nSince the CL needs to reach the head of the BC before the EL can sync to an equivalent head, the CL must import beacon blocks without verifying the execution payloads. This is, technically, a violation of the BC specification. Some might call it \"unsafe\", but we call it \"optimistic\".\r\n\r\nIn summary, *optimistic sync* is where a CL syncs the BC without verifying all the execution payload values with an EL.\r\n\r\n## From Optimism to Realism\r\n\r\nSyncing a CL client without verifying the execution payload values at all is simply unsafe (at least as far as I'm concerned). So, once we mange to get our EL synced, we should go back and verify all of the execution payloads we imported along the way.\r\n\r\nThankfully, this is not as tedious as it sounds. If one execution payload is valid, then all the ancestors must be valid. So, as long as we've ensured that the execution payloads we've imported all form a chain, if all the chain-heads (chain-tips) are valid, then all of our beacon blocks become fully verified and we're no longer an optimistic client (a realistic client?).\r\n\r\nBut what if one of those execution payloads is invalid? Well, we just need to invalidate that block and its descendants. That *sounds* easy, but there are two scenarios to consider:\r\n\r\n1. A finalized execution payload is invalid.\r\n2. A non-finalized execution payload is invalid.\r\n\r\nIn the case of (1), we're in serious trouble. As I understand it, there aren't any CL clients prepared to handle a reversion in the finalized chain (Lighthouse wont). So, in this case I think we simply need to shutdown, log critical errors and request the user to re-sync on a trusted internet connection.\r\n\r\nIn the case of (2), this is going to be much simpler. All the CL clients are prepared for re-orgs in the non-finalized chain. What they would do is go and remove the invalid block (and descendants) from their fork-choice tree and then run the fork-choice algorithm to find a new head that does not include any invalid execution payloads.\r\n\r\n## Dealing with Uncertainty\r\n\r\nThere are various different things a CL client needs to do with the blocks in their database:\r\n\r\n- Build new blocks atop them\r\n- Attest to them\r\n- Reference them in a sync committee\r\n- Serve them to API consumers\r\n- Serve them to P2P peers\r\n\r\nWhen it comes to blocks with a valid payload, it's clear that we're free to do any of those tasks. However, when it comes to invalid blocks, I'd say it's clear that we shouldn't do *any* of those things. \r\n\r\nBut what about when we have blocks with an *unknown* execution payload status? I.e., the blocks we imported optimistically and haven't yet had verified? At this point, I think I'm also of the opinion that we should do any of those things either. Notably, it would be impossible to produce a block atop a block with an \"unknown\" status, since our EL can't build a new block atop one it doesn't know!\r\n\r\nSo, if we know that our head has an unknown status we can't build atop it. But should we try to fork around it and build atop the best verified head (our \"safe head\")? I'm not convinced the correct behaviour here, but I think that we *should not* try to build around it, since we would be forking the chain when we *know* that we have an incomplete picture. I really need to think deeply about this and if it will cause liveness failures.\r\n\r\n## Additional Resources\r\n\r\n- A doc by Danny Ryan on this topic: https://notes.ethereum.org/@djrtwo/BJxKBaqNF\r\n    - This includes the addition of a `most_recent_correct_ancestor` to `engine_processPayload` which would make it very easy for us to find all the invalid ancestors of a block in our fork-choice tree.",
  "closed_by": {
    "login": "paulhauner",
    "id": 6660660,
    "node_id": "MDQ6VXNlcjY2NjA2NjA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/paulhauner",
    "html_url": "https://github.com/paulhauner",
    "followers_url": "https://api.github.com/users/paulhauner/followers",
    "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
    "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
    "organizations_url": "https://api.github.com/users/paulhauner/orgs",
    "repos_url": "https://api.github.com/users/paulhauner/repos",
    "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
    "received_events_url": "https://api.github.com/users/paulhauner/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/2691/reactions",
    "total_count": 9,
    "+1": 5,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 4,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/938403492",
    "html_url": "https://github.com/sigp/lighthouse/issues/2691#issuecomment-938403492",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691",
    "id": 938403492,
    "node_id": "IC_kwDOCFeAzc437uak",
    "user": {
      "login": "ralexstokes",
      "id": 3113781,
      "node_id": "MDQ6VXNlcjMxMTM3ODE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/3113781?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ralexstokes",
      "html_url": "https://github.com/ralexstokes",
      "followers_url": "https://api.github.com/users/ralexstokes/followers",
      "following_url": "https://api.github.com/users/ralexstokes/following{/other_user}",
      "gists_url": "https://api.github.com/users/ralexstokes/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ralexstokes/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ralexstokes/subscriptions",
      "organizations_url": "https://api.github.com/users/ralexstokes/orgs",
      "repos_url": "https://api.github.com/users/ralexstokes/repos",
      "events_url": "https://api.github.com/users/ralexstokes/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ralexstokes/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-08T07:15:14Z",
    "updated_at": "2021-10-08T07:15:14Z",
    "author_association": "CONTRIBUTOR",
    "body": "> Terminal Block (TB) Inclusion: I use this to refer to the point in the BC where get_terminal_pow_block first returns Some(pow_block) and it is included as an ExecutionPayload in the BC. This must happen either at or after the Merge Fork. PoW Ethereum ends here.\r\n\r\n\r\nDo you mean here that the `parent_hash` of the `ExecutionPayload` in the BC is a reference to the `pow_block` (wrapped in `Some`)? The way this reads to me is that the `pow_block` is copied as a (duplicate) `ExecutionPayload` into the first post-merge beacon block. Unless I'm confused on this, I'd suggest updating this description so it is clearer:\r\n\r\n```\r\nTerminal Block (TB) Inclusion: I use this to refer to the point in the BC where `get_terminal_pow_block`\r\n first returns Some(pow_block) and it is included by reference as the parent of an ExecutionPayload in the BC. \r\nThis must happen either at or after the Merge Fork. PoW Ethereum ends here.\r\n```",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/938403492/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/938439181",
    "html_url": "https://github.com/sigp/lighthouse/issues/2691#issuecomment-938439181",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691",
    "id": 938439181,
    "node_id": "IC_kwDOCFeAzc4373IN",
    "user": {
      "login": "djrtwo",
      "id": 1433595,
      "node_id": "MDQ6VXNlcjE0MzM1OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1433595?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/djrtwo",
      "html_url": "https://github.com/djrtwo",
      "followers_url": "https://api.github.com/users/djrtwo/followers",
      "following_url": "https://api.github.com/users/djrtwo/following{/other_user}",
      "gists_url": "https://api.github.com/users/djrtwo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/djrtwo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/djrtwo/subscriptions",
      "organizations_url": "https://api.github.com/users/djrtwo/orgs",
      "repos_url": "https://api.github.com/users/djrtwo/repos",
      "events_url": "https://api.github.com/users/djrtwo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/djrtwo/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-08T08:13:44Z",
    "updated_at": "2021-10-08T08:13:44Z",
    "author_association": "NONE",
    "body": "I concur that item's 1 through 5 should not be performed on optimistic BC heads. *CERTAINLY* items 1 through 3 should not be performed on an unsafe/optimistic head. These are simply dangerous for attesters.\r\n\r\nAn attestation for an incorrect chain could result in the attester stuck on such a chain (in the even that two chains had 2/3 and conflicting ffg info) and building on incorrect beacon blocks is (a) currently just a bad behavior for the network and (b) when we have an execution proof of custody (which we expect sooner rather than later), it could result in slashing in some cases.\r\n\r\nAs for APIs, I don't think it makes sense to serve an optimistic head. The user would not be able to then go look at the EL contents of a such a head and thus would have a broken view of what maybe is the head. If EL isn't resolved for some stretch, that is essentially the aggregate EL+CL client still \"syncing\" that segment, and thus it is natural to treat it as such (even though one half of layers is resolved).\r\n\r\nAs for P2P, it's a bit less straight forward. I don't think you should serve optimistic beacon blocks in `blocks by range` or `status`. Your sync status and local head is still behind the optimistic head in a sense.\r\n\r\nFor gossip, though, it's a bit less clear. In many SYNCING situations, EL might be near the head so you want to still get new CL blocks so you can quickly resolve segments when EL finishes SYNCING. If you look at the [Merge p2p `beacon_block` validations](https://github.com/ethereum/consensus-specs/blob/dev/specs/merge/p2p-interface.md#beacon_block), you can do all of the `execution_payload` validations without issue. It seems like the worst case is that *all* CL clients (not just SYNCING ones) could be tricked to gossip a block that has a good signature and structure but bad EL execution. The non-SYNCING nodes would quickly drop the block because it fails full EL validations and the SYNCING nodes would also drop the block when eventually sync'd.\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/938439181/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/938480481",
    "html_url": "https://github.com/sigp/lighthouse/issues/2691#issuecomment-938480481",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691",
    "id": 938480481,
    "node_id": "IC_kwDOCFeAzc438BNh",
    "user": {
      "login": "vbuterin",
      "id": 2230894,
      "node_id": "MDQ6VXNlcjIyMzA4OTQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/2230894?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vbuterin",
      "html_url": "https://github.com/vbuterin",
      "followers_url": "https://api.github.com/users/vbuterin/followers",
      "following_url": "https://api.github.com/users/vbuterin/following{/other_user}",
      "gists_url": "https://api.github.com/users/vbuterin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vbuterin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vbuterin/subscriptions",
      "organizations_url": "https://api.github.com/users/vbuterin/orgs",
      "repos_url": "https://api.github.com/users/vbuterin/repos",
      "events_url": "https://api.github.com/users/vbuterin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vbuterin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-08T09:11:08Z",
    "updated_at": "2021-10-08T09:12:13Z",
    "author_association": "NONE",
    "body": "> CERTAINLY items 1 through 3 should not be performed on an unsafe/optimistic head.\r\n\r\nThis seems risky. If attesters do not attest to unsafe heads, then how would an unsafe head ever become safe?\r\n\r\n(I'm sure in _some_ situations it would, because attestations later show up, but not all)",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/938480481/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/938482116",
    "html_url": "https://github.com/sigp/lighthouse/issues/2691#issuecomment-938482116",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691",
    "id": 938482116,
    "node_id": "IC_kwDOCFeAzc438BnE",
    "user": {
      "login": "djrtwo",
      "id": 1433595,
      "node_id": "MDQ6VXNlcjE0MzM1OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1433595?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/djrtwo",
      "html_url": "https://github.com/djrtwo",
      "followers_url": "https://api.github.com/users/djrtwo/followers",
      "following_url": "https://api.github.com/users/djrtwo/following{/other_user}",
      "gists_url": "https://api.github.com/users/djrtwo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/djrtwo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/djrtwo/subscriptions",
      "organizations_url": "https://api.github.com/users/djrtwo/orgs",
      "repos_url": "https://api.github.com/users/djrtwo/repos",
      "events_url": "https://api.github.com/users/djrtwo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/djrtwo/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-08T09:13:26Z",
    "updated_at": "2021-10-08T09:14:58Z",
    "author_association": "NONE",
    "body": "This only happens if your EL is syncing.\r\n\r\n***THIS IS NOT** safe/unsafe wrt making decisions about beacon blocks and chance of re-org. This is unsafe because the CL has been validated but not the EL.\r\n\r\nWe conflated \"unsafe\" in two different Merge convos and conventions. \"Optimistic\" CL is probably a better term here",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/938482116/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/939040128",
    "html_url": "https://github.com/sigp/lighthouse/issues/2691#issuecomment-939040128",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691",
    "id": 939040128,
    "node_id": "IC_kwDOCFeAzc43-J2A",
    "user": {
      "login": "sauliusgrigaitis",
      "id": 6917,
      "node_id": "MDQ6VXNlcjY5MTc=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6917?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sauliusgrigaitis",
      "html_url": "https://github.com/sauliusgrigaitis",
      "followers_url": "https://api.github.com/users/sauliusgrigaitis/followers",
      "following_url": "https://api.github.com/users/sauliusgrigaitis/following{/other_user}",
      "gists_url": "https://api.github.com/users/sauliusgrigaitis/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sauliusgrigaitis/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sauliusgrigaitis/subscriptions",
      "organizations_url": "https://api.github.com/users/sauliusgrigaitis/orgs",
      "repos_url": "https://api.github.com/users/sauliusgrigaitis/repos",
      "events_url": "https://api.github.com/users/sauliusgrigaitis/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sauliusgrigaitis/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-08T18:34:23Z",
    "updated_at": "2021-10-08T18:34:23Z",
    "author_association": "NONE",
    "body": "We experimented with a similar concept in Grandine for a different purpose - _unlimited_ parallelization of blocks signatures verification. Kinda similar situation as the latest chunk of the chain had semi-verified (everything checked except signatures) blocks too. In our case fork choice built the chain with blocks skipping signature verification in order to advance the state enough so it made possible to spin a high amount (at least hundreds) of block signatures verification tasks.\r\n\r\nAfter we implemented it the whole thing looked so terrible and unsafe that we dropped this idea. Quadratic complexity of already complex optimized fork choice. Looking forward to your solution as it will solve the _unlimited_ block signatures verification parallelization too.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/939040128/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/940524520",
    "html_url": "https://github.com/sigp/lighthouse/issues/2691#issuecomment-940524520",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691",
    "id": 940524520,
    "node_id": "IC_kwDOCFeAzc44D0Po",
    "user": {
      "login": "paulhauner",
      "id": 6660660,
      "node_id": "MDQ6VXNlcjY2NjA2NjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/paulhauner",
      "html_url": "https://github.com/paulhauner",
      "followers_url": "https://api.github.com/users/paulhauner/followers",
      "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
      "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
      "organizations_url": "https://api.github.com/users/paulhauner/orgs",
      "repos_url": "https://api.github.com/users/paulhauner/repos",
      "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/paulhauner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-11T23:53:53Z",
    "updated_at": "2021-10-11T23:55:41Z",
    "author_association": "MEMBER",
    "body": "> Do you mean here that the parent_hash of the ExecutionPayload in the BC is a reference to the pow_block (wrapped in Some)?\r\n\r\nGood point @ralexstokes, thanks. I've added your suggestion :)\r\n\r\n> For gossip, though, it's a bit less clear. In many SYNCING situations, EL might be near the head so you want to still get new CL blocks so you can quickly resolve segments when EL finishes SYNCING\r\n\r\nIndeed, gossip is a good point. I also tend to think that we should continue to gossip blocks on an optimistic head.\r\n\r\n> Looking forward to your solution as it will solve the unlimited block signatures verification parallelization too.\r\n\r\nIt's important to note that my scheme fails hard (i.e. client shutdown, delete the database) if an invalid block is finalized. The primary reason I would be comfortable implementing such a scheme is because we verify signatures along the way. In order to get a failure in this optimistic execution-payload scheme you need to get 2/3rds (of a random distribution) of active validators signing across invalid blocks.\r\n\r\nIf we were to delay signature verification across a unlimited number of blocks, some batches would contain blocks that finalize blocks earlier in the batch (mainnet usually finalizes every 64 blocks). Since there is no signature verification, it would be trivial for anyone to construct a chain of blocks that looks like it finalizes.\r\n\r\nSo, to do unlimited parallelization of block signatures, you need a client design that makes it possible to revert finality. That is not something I plan to implement here unfortunately.\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/940524520/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/942618439",
    "html_url": "https://github.com/sigp/lighthouse/issues/2691#issuecomment-942618439",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691",
    "id": 942618439,
    "node_id": "IC_kwDOCFeAzc44LzdH",
    "user": {
      "login": "sauliusgrigaitis",
      "id": 6917,
      "node_id": "MDQ6VXNlcjY5MTc=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6917?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/sauliusgrigaitis",
      "html_url": "https://github.com/sauliusgrigaitis",
      "followers_url": "https://api.github.com/users/sauliusgrigaitis/followers",
      "following_url": "https://api.github.com/users/sauliusgrigaitis/following{/other_user}",
      "gists_url": "https://api.github.com/users/sauliusgrigaitis/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/sauliusgrigaitis/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/sauliusgrigaitis/subscriptions",
      "organizations_url": "https://api.github.com/users/sauliusgrigaitis/orgs",
      "repos_url": "https://api.github.com/users/sauliusgrigaitis/repos",
      "events_url": "https://api.github.com/users/sauliusgrigaitis/events{/privacy}",
      "received_events_url": "https://api.github.com/users/sauliusgrigaitis/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-13T18:53:59Z",
    "updated_at": "2021-10-13T18:53:59Z",
    "author_association": "NONE",
    "body": "> If we were to delay signature verification across a unlimited number of blocks, some batches would contain blocks that finalize blocks earlier in the batch (mainnet usually finalizes every 64 blocks). Since there is no signature verification, it would be trivial for anyone to construct a chain of blocks that looks like it finalizes.\r\n\r\nThis can be solved optimistically by doing a quick check of proposer signature. So that's not too big problem, especially if reverting is implemented.\r\n\r\n> So, to do unlimited parallelization of block signatures, you need a client design that makes it possible to revert finality. That is not something I plan to implement here unfortunately.\r\n\r\nGrandine doesn't have persistence and finalization coupling. It can run in memory for very long and we dump the state only to avoid full resync after a restart. However, as I mentioned before, the implementation we did back then felt too hacky.\r\n\r\nAnyway, as signatures are checked, then the only problem is to not get into a situation where 2/3rds finalizes invalid payload. This means that unsafe head should be an isolated optimization and should not be exponsed elsewhere, otherwise we may learn how users use it in creative ways that make 2/3rds finalizing invalid payload.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/942618439/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/962878140",
    "html_url": "https://github.com/sigp/lighthouse/issues/2691#issuecomment-962878140",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691",
    "id": 962878140,
    "node_id": "IC_kwDOCFeAzc45ZFq8",
    "user": {
      "login": "paulhauner",
      "id": 6660660,
      "node_id": "MDQ6VXNlcjY2NjA2NjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/paulhauner",
      "html_url": "https://github.com/paulhauner",
      "followers_url": "https://api.github.com/users/paulhauner/followers",
      "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
      "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
      "organizations_url": "https://api.github.com/users/paulhauner/orgs",
      "repos_url": "https://api.github.com/users/paulhauner/repos",
      "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/paulhauner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-11-08T07:24:42Z",
    "updated_at": "2021-11-08T07:24:42Z",
    "author_association": "MEMBER",
    "body": "I've done some more thinking on this and my latest collection of information lives here:\r\n\r\nhttps://hackmd.io/Ic7VpkY3SkKGgYLg2p9pMg",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/962878140/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1286384803",
    "html_url": "https://github.com/sigp/lighthouse/issues/2691#issuecomment-1286384803",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2691",
    "id": 1286384803,
    "node_id": "IC_kwDOCFeAzc5MrKyj",
    "user": {
      "login": "paulhauner",
      "id": 6660660,
      "node_id": "MDQ6VXNlcjY2NjA2NjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/paulhauner",
      "html_url": "https://github.com/paulhauner",
      "followers_url": "https://api.github.com/users/paulhauner/followers",
      "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
      "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
      "organizations_url": "https://api.github.com/users/paulhauner/orgs",
      "repos_url": "https://api.github.com/users/paulhauner/repos",
      "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/paulhauner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-10-21T02:43:04Z",
    "updated_at": "2022-10-21T02:43:04Z",
    "author_association": "MEMBER",
    "body": "I'll close this since we've already implemented optimistic sync (and done the merge :tada:)",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1286384803/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
