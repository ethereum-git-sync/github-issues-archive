{
  "url": "https://api.github.com/repos/sigp/lighthouse/issues/2926",
  "repository_url": "https://api.github.com/repos/sigp/lighthouse",
  "labels_url": "https://api.github.com/repos/sigp/lighthouse/issues/2926/labels{/name}",
  "comments_url": "https://api.github.com/repos/sigp/lighthouse/issues/2926/comments",
  "events_url": "https://api.github.com/repos/sigp/lighthouse/issues/2926/events",
  "html_url": "https://github.com/sigp/lighthouse/issues/2926",
  "id": 1107159765,
  "node_id": "I_kwDOCFeAzc5B_erV",
  "number": 2926,
  "title": "High inclusion lag and missed attestations when using fallback beacon node",
  "user": {
    "login": "poupas",
    "id": 265706,
    "node_id": "MDQ6VXNlcjI2NTcwNg==",
    "avatar_url": "https://avatars.githubusercontent.com/u/265706?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/poupas",
    "html_url": "https://github.com/poupas",
    "followers_url": "https://api.github.com/users/poupas/followers",
    "following_url": "https://api.github.com/users/poupas/following{/other_user}",
    "gists_url": "https://api.github.com/users/poupas/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/poupas/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/poupas/subscriptions",
    "organizations_url": "https://api.github.com/users/poupas/orgs",
    "repos_url": "https://api.github.com/users/poupas/repos",
    "events_url": "https://api.github.com/users/poupas/events{/privacy}",
    "received_events_url": "https://api.github.com/users/poupas/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 4,
  "created_at": "2022-01-18T17:10:13Z",
  "updated_at": "2022-03-25T00:20:38Z",
  "closed_at": "2022-03-25T00:20:38Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "## Description\r\n\r\nHi all. I think I've ran into a potential issue with the beacon node redundancy feature. Even if the primary node is unavailable, the validator client still tries to contact it **on every attestation**. This will result in attestation delays and missed attestations.\r\n\r\n## Version\r\n\r\nLighthouse/v2.0.1-fff01b2\r\n\r\n## Present Behaviour\r\n\r\nI'm using the following setup for my tests:\r\n\r\n  * primary beacon node (`192.168.0.1`)\r\n  * secondary beacon node (`192.168.0.2`)\r\n  * lighthouse validator client is configured with `--beacon-nodes http://192.168.0.1:5052,http://192.168.0.2:5052`\r\n\r\nIf the primary beacon node becomes unresponsive, and is correctly detected as being offline, the validator still tries to contact it every time during its attestation duties. This is causing significant delay (around 8 seconds, as it can be seen in the following logs), resulting in high inclusion lag and missed attestations.\r\n\r\nThis behavior is simple to reproduce, just make sure that the primary node does not reply to any traffic, since we need to trigger a timeout.\r\n\r\n**OK scenario (primary beacon node is up):**\r\n```\r\nJan DD HH:MM:03.001 TRCE Spawned attestation tasks               service: attestation\r\nJan DD HH:MM:03.055 TRCE Blocking task completed                 task: local_keystore_signer\r\nJan DD HH:MM:03.106 INFO Successfully published attestations     type: unaggregated, slot: [removed], committee_index: [removed], head_block: [removed], count: 1, service: attestation\r\n```\r\n\r\n**Failing scenario (primary beacon node is down, secondary is up):**\r\n```\r\nJan DD HH:MM:15.001 TRCE Spawned attestation tasks               service: attestation\r\n\r\n--- ~ 8 second gap ---\r\n\r\nJan DD HH:MM:23.005 WARN Offline beacon node                     endpoint: http://192.168.0.1:5052/, error: Reqwest(reqwest::Error { kind: Request, url: Url { scheme: \"http\", cannot_be_a_base: false, username: \"\", password: None, host: Some(Ipv4(192.168.0.1)), port: Some(5052),\r\n path: \"/eth/v1/node/version\", query: None, fragment: None }, source: TimedOut })\r\nJan DD HH:MM:23.005 INFO Connected to beacon node(s)             synced: 1, available: 1, total: 2, service: notifier\r\nJan DD HH:MM:23.026 TRCE Blocking task completed                 task: local_keystore_signer\r\nJan DD HH:MM:23.044 INFO Successfully published attestations     type: unaggregated, slot: [removed], committee_index: [removed], head_block: [removed], count: 1, service: attestation\r\n```\r\n\r\n## Expected Behaviour\r\n\r\nThe validator client should use the \"healthy\" beacon nodes first.",
  "closed_by": {
    "login": "poupas",
    "id": 265706,
    "node_id": "MDQ6VXNlcjI2NTcwNg==",
    "avatar_url": "https://avatars.githubusercontent.com/u/265706?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/poupas",
    "html_url": "https://github.com/poupas",
    "followers_url": "https://api.github.com/users/poupas/followers",
    "following_url": "https://api.github.com/users/poupas/following{/other_user}",
    "gists_url": "https://api.github.com/users/poupas/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/poupas/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/poupas/subscriptions",
    "organizations_url": "https://api.github.com/users/poupas/orgs",
    "repos_url": "https://api.github.com/users/poupas/repos",
    "events_url": "https://api.github.com/users/poupas/events{/privacy}",
    "received_events_url": "https://api.github.com/users/poupas/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/2926/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/sigp/lighthouse/issues/2926/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1017773554",
    "html_url": "https://github.com/sigp/lighthouse/issues/2926#issuecomment-1017773554",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2926",
    "id": 1017773554,
    "node_id": "IC_kwDOCFeAzc48qf3y",
    "user": {
      "login": "realbigsean",
      "id": 5160426,
      "node_id": "MDQ6VXNlcjUxNjA0MjY=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5160426?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/realbigsean",
      "html_url": "https://github.com/realbigsean",
      "followers_url": "https://api.github.com/users/realbigsean/followers",
      "following_url": "https://api.github.com/users/realbigsean/following{/other_user}",
      "gists_url": "https://api.github.com/users/realbigsean/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/realbigsean/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/realbigsean/subscriptions",
      "organizations_url": "https://api.github.com/users/realbigsean/orgs",
      "repos_url": "https://api.github.com/users/realbigsean/repos",
      "events_url": "https://api.github.com/users/realbigsean/events{/privacy}",
      "received_events_url": "https://api.github.com/users/realbigsean/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-01-20T18:01:22Z",
    "updated_at": "2022-01-20T18:01:22Z",
    "author_association": "COLLABORATOR",
    "body": "Thanks a lot for looking into this and bringing it up!  \r\n\r\n> The validator client should use the \"healthy\" beacon nodes first.\r\n\r\nThe fallback functionality is intended to give users the ability to set an order of precedence for which nodes should be used. A very common setup is to have a local beacon node node running and using Infura as a backup. And the hope for this type of setup is to only use Infura when necessary, and recover to the beacon node as soon as it's available.\r\n\r\nWe could instead try to address this by reducing this timeout to something that would allow a fallback requests to still be made.\r\nIt's possible this could induce some missed attestations when requests that would have completed just after the timeout are cancelled and the backup doesn't have time to complete the request. So maybe we can reduce this timeout only when a node was last seen as unhealthy.  ",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1017773554/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1030959338",
    "html_url": "https://github.com/sigp/lighthouse/issues/2926#issuecomment-1030959338",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2926",
    "id": 1030959338,
    "node_id": "IC_kwDOCFeAzc49czDq",
    "user": {
      "login": "paulhauner",
      "id": 6660660,
      "node_id": "MDQ6VXNlcjY2NjA2NjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/paulhauner",
      "html_url": "https://github.com/paulhauner",
      "followers_url": "https://api.github.com/users/paulhauner/followers",
      "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
      "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
      "organizations_url": "https://api.github.com/users/paulhauner/orgs",
      "repos_url": "https://api.github.com/users/paulhauner/repos",
      "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/paulhauner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-02-07T00:42:42Z",
    "updated_at": "2022-02-07T00:42:42Z",
    "author_association": "MEMBER",
    "body": "Reducing the timeout can be tricky for hard-working endpoints like `GET validator/blocks`. Block production can take a while and we don't want to abandon it with a short timeout.\r\n\r\nAnother solution might be to add a new `Timedout` variant to [`CandidateError`](https://github.com/sigp/lighthouse/blob/0177b9286edfdeb2782f74fc7fb1392b6459bfaa/validator_client/src/beacon_node_fallback.rs#L117) so we will always skip nodes that recently timed-out during the [first pass in the `first_success` function](https://github.com/sigp/lighthouse/blob/0177b9286edfdeb2782f74fc7fb1392b6459bfaa/validator_client/src/beacon_node_fallback.rs#L432-L449). Nodes that timeout will then need to be recovered via the [`update_unready_candidates`](https://github.com/sigp/lighthouse/blob/0177b9286edfdeb2782f74fc7fb1392b6459bfaa/validator_client/src/beacon_node_fallback.rs#L357-L385) routine. ",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1030959338/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1038884723",
    "html_url": "https://github.com/sigp/lighthouse/issues/2926#issuecomment-1038884723",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2926",
    "id": 1038884723,
    "node_id": "IC_kwDOCFeAzc497B9z",
    "user": {
      "login": "holiman",
      "id": 142290,
      "node_id": "MDQ6VXNlcjE0MjI5MA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/142290?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/holiman",
      "html_url": "https://github.com/holiman",
      "followers_url": "https://api.github.com/users/holiman/followers",
      "following_url": "https://api.github.com/users/holiman/following{/other_user}",
      "gists_url": "https://api.github.com/users/holiman/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/holiman/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/holiman/subscriptions",
      "organizations_url": "https://api.github.com/users/holiman/orgs",
      "repos_url": "https://api.github.com/users/holiman/repos",
      "events_url": "https://api.github.com/users/holiman/events{/privacy}",
      "received_events_url": "https://api.github.com/users/holiman/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-02-14T10:00:02Z",
    "updated_at": "2022-02-14T10:00:02Z",
    "author_association": "NONE",
    "body": "How about: \r\n- If node `x` is found to be \"down\" (wrongly configured, actually down, responding with error, whatever), then remove it from the list of nodes to query. \r\n- Start a `poller` which checks health every 5 seconds. \r\n- Once the `poller` finds that it's \"up\" again (according to some criteria), it get put back in the list according to the desired priority. \r\n\r\nMaybe that's the same as what you mean, but in other words, @paulhauner (?)\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1038884723/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1039676768",
    "html_url": "https://github.com/sigp/lighthouse/issues/2926#issuecomment-1039676768",
    "issue_url": "https://api.github.com/repos/sigp/lighthouse/issues/2926",
    "id": 1039676768,
    "node_id": "IC_kwDOCFeAzc49-DVg",
    "user": {
      "login": "paulhauner",
      "id": 6660660,
      "node_id": "MDQ6VXNlcjY2NjA2NjA=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6660660?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/paulhauner",
      "html_url": "https://github.com/paulhauner",
      "followers_url": "https://api.github.com/users/paulhauner/followers",
      "following_url": "https://api.github.com/users/paulhauner/following{/other_user}",
      "gists_url": "https://api.github.com/users/paulhauner/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/paulhauner/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/paulhauner/subscriptions",
      "organizations_url": "https://api.github.com/users/paulhauner/orgs",
      "repos_url": "https://api.github.com/users/paulhauner/repos",
      "events_url": "https://api.github.com/users/paulhauner/events{/privacy}",
      "received_events_url": "https://api.github.com/users/paulhauner/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-02-14T23:25:17Z",
    "updated_at": "2022-02-14T23:34:13Z",
    "author_association": "MEMBER",
    "body": "> Maybe that's the same as what you mean, but in other words, @paulhauner (?)\r\n\r\nIndeed, that's a clearer way to express what I was alluding to.\r\n\r\nI looked into this a bit further and we do already implement the desired behaviour *(excluding a bug I'll describe shortly)*. When a node returns *any* error we call [`CandidateBeaconNode::set_offline`](https://github.com/sigp/lighthouse/blob/c3a793fd73a3b11b130b82032904d39c952869e4/validator_client/src/beacon_node_fallback.rs#L424) which sets it's `status` to `CandidateError::Offline`. That node will then be ignored until the routine [`fallback_updater_service`](https://github.com/sigp/lighthouse/blob/c3a793fd73a3b11b130b82032904d39c952869e4/validator_client/src/beacon_node_fallback.rs#L44) manages to reconnect to it.\r\n\r\nHowever, I believe there was an issue in the [`CanidateBeaconNode::refesh_status`](https://github.com/sigp/lighthouse/blob/c3a793fd73a3b11b130b82032904d39c952869e4/validator_client/src/beacon_node_fallback.rs#L157-L178) method, which is used by the updater service to see if the node has come good again. It was holding a [write lock on the `status` field](https://github.com/sigp/lighthouse/blob/c3a793fd73a3b11b130b82032904d39c952869e4/validator_client/src/beacon_node_fallback.rs#L165) whilst it polled the node status. This means a long timeout would hog the write lock and starve other processes.\r\n\r\nWhen a VC is trying to access a beacon node for whatever purpose (getting duties, posting blocks, etc), it performs [three passes](https://github.com/sigp/lighthouse/blob/c3a793fd73a3b11b130b82032904d39c952869e4/validator_client/src/beacon_node_fallback.rs#L432-L482) through the lists of nodes, trying to run some generic `function` (closure/lambda) on each node:\r\n\r\n- 1st pass: only try running `function` on all nodes which are both synced and online.\r\n- 2nd pass: try running `function` on all nodes that are online, but not necessarily synced.\r\n- 3rd pass: for each offline node, try refreshing its status and then running `function` on it.\r\n\r\nSo, it turns out that if the `CanidateBeaconNode::refesh_status` function from the routine update service is hogging the write-lock, the 1st pass gets blocked whilst trying to read the status of the first node. So, nodes that should be left until the 3rd pass are blocking the process of the 1st and 2nd passes, hence the behaviour described by @poupas.",
    "reactions": {
      "url": "https://api.github.com/repos/sigp/lighthouse/issues/comments/1039676768/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 1
    },
    "performed_via_github_app": null
  }
]
