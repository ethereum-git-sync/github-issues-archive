{
  "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/311",
  "repository_url": "https://api.github.com/repos/ledgerwatch/erigon",
  "labels_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/311/labels{/name}",
  "comments_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/311/comments",
  "events_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/311/events",
  "html_url": "https://github.com/ledgerwatch/erigon/issues/311",
  "id": 548046956,
  "node_id": "MDU6SXNzdWU1NDgwNDY5NTY=",
  "number": 311,
  "title": "Introduce INTERMEDIATE_HASHES bucket - Phase 1",
  "user": {
    "login": "AlexeyAkhunov",
    "id": 13686139,
    "node_id": "MDQ6VXNlcjEzNjg2MTM5",
    "avatar_url": "https://avatars.githubusercontent.com/u/13686139?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/AlexeyAkhunov",
    "html_url": "https://github.com/AlexeyAkhunov",
    "followers_url": "https://api.github.com/users/AlexeyAkhunov/followers",
    "following_url": "https://api.github.com/users/AlexeyAkhunov/following{/other_user}",
    "gists_url": "https://api.github.com/users/AlexeyAkhunov/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/AlexeyAkhunov/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/AlexeyAkhunov/subscriptions",
    "organizations_url": "https://api.github.com/users/AlexeyAkhunov/orgs",
    "repos_url": "https://api.github.com/users/AlexeyAkhunov/repos",
    "events_url": "https://api.github.com/users/AlexeyAkhunov/events{/privacy}",
    "received_events_url": "https://api.github.com/users/AlexeyAkhunov/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": false,
  "assignee": {
    "login": "AskAlexSharov",
    "id": 46885206,
    "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
    "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/AskAlexSharov",
    "html_url": "https://github.com/AskAlexSharov",
    "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
    "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
    "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
    "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
    "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
    "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
    "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
    "type": "User",
    "site_admin": false
  },
  "assignees": [
    {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    }
  ],
  "milestone": null,
  "comments": 3,
  "created_at": "2020-01-10T12:13:39Z",
  "updated_at": "2020-02-14T04:01:28Z",
  "closed_at": "2020-02-14T04:01:28Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "body": "Create a new bucket in the database. Its purpose it is going to be to complement the current state buckets (`dbutils.AccountsBucket` and `dbutils.StorageBucket`). These current state buckets contain the mappings:\r\n`hash_of_address_of_account => serialised_account`\r\n`hash_of_address_of_account|incarnation|hash_of_storage_position => storage_value`\r\n\r\nthis is the main difference between turbo-geth and geth . This representation makes a lot of things faster and more straightforward, but it makes other things much harder.\r\nThe state on the Ethereum mainnet is very large, and we cannot assume that we can hold it entirely in memory. That is why there will be part of the state we hold in memory (cache), in the form of the patricia merkle tree, and the part of the state, which is not in that cache. Important property of such cache is that it is always possible to recompute the state root from the information in the cache.\r\n\r\nIf we are to satisfy state modification that goes beyond what it is in the cache, we first need to bring the required part of the state into the cache, and also some extra information that will allow us to preserve the property of being able to compute the state root. We currently call the process of loading this required part of the state (+extra information to be able to compute the state root) from the database to the cache - Resolution. It is implemented in `trie/resolver.go` and `trie/hashbuilder.go`. The main problem with the resolution is that often it needs to load a lot of records from the database, only to compute the hash of the subtree, and discard the read records. This is especially visible when the turbo-geth is restarted, and it needs to compute the state root of the Entire state, which means it needs to read the entire `AccountsBucket`.\r\n\r\nTo address this problem, we would like to experiment with adding an extra bucket to the database. In this bucket, we will store the mappings:\r\n`some_prefix_of(hash_of_address_of_account) => hash_of_subtrie`\r\n`hash_of_address_of_account|incarnation|some_prefix_of(hash_of_storage_position) => hash_of_subtrie`\r\n\r\nWe do not want to store this information for all possible subtries in the state trie. There are two restrictions:\r\n1. We only store the hashes of subtries starting on the branch nodes (`fullNode` and `duoNode` in `trie/node.go`)\r\n2. We only store the hashes that are not currently in the memory cache.\r\n\r\nThe reason for the second restriction is to prevent a high level of \"churn\" in the database. The hashes on the top of the state trie change very often, so we want it to happen only in our memory cache, and not in the database. But things we do not have in the memory cache, might become useful when we reach to the \"cold\" (as in not in the cache) parts of the state.\r\n\r\nIn the first stage, we only want to populate this bucket, but not use it yet for speeding up the \"Resolution\". Here are the suggested insertion points:\r\n\r\n1. Function `ResolveStateTrie` in the `core/state/database.go` performs the \"Resolution\" process. It is split up into 2 parts - one for the accounts (`buildAccountsTouches` and `resolveAccountsTouches`), another - for storage (`buildStorageTouches` and `resolveStorageTouches`). In the functions `resolveAccountsTouches` and `resolveStorageTouches` you can see the use of `Resolver` type from `trie/resolver.go`. Function `ResolveWithDb` is what performs the actual resolution (access to the database, if necessary). At this point, we would like to detect which branch nodes (`fullNode` and `branchNode`) we have brought into the memory cache, and **delete** them from our Intermediate Hash bucket (because they will now possibly change in memory).\r\n2. Function `PruneTries` in the `core/state/database.go` unloads parts of the memory cache, those parts that have not been touched for longest. It is done by the function `PruneTo` defined in `trie/trie_pruning.go`. We would like to detect those branch nodes (`fullNode` and `branchNode`) that have been unloaded and **insert** them into our Intermediate Hash bucket (because they will not change for a while, and will help us to recover parts of the state quicker later).\r\n",
  "closed_by": {
    "login": "AskAlexSharov",
    "id": 46885206,
    "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
    "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/AskAlexSharov",
    "html_url": "https://github.com/AskAlexSharov",
    "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
    "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
    "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
    "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
    "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
    "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
    "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/311/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/311/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/573172185",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/311#issuecomment-573172185",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/311",
    "id": 573172185,
    "node_id": "MDEyOklzc3VlQ29tbWVudDU3MzE3MjE4NQ==",
    "user": {
      "login": "AlexeyAkhunov",
      "id": 13686139,
      "node_id": "MDQ6VXNlcjEzNjg2MTM5",
      "avatar_url": "https://avatars.githubusercontent.com/u/13686139?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AlexeyAkhunov",
      "html_url": "https://github.com/AlexeyAkhunov",
      "followers_url": "https://api.github.com/users/AlexeyAkhunov/followers",
      "following_url": "https://api.github.com/users/AlexeyAkhunov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AlexeyAkhunov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AlexeyAkhunov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AlexeyAkhunov/subscriptions",
      "organizations_url": "https://api.github.com/users/AlexeyAkhunov/orgs",
      "repos_url": "https://api.github.com/users/AlexeyAkhunov/repos",
      "events_url": "https://api.github.com/users/AlexeyAkhunov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AlexeyAkhunov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-01-10T19:25:03Z",
    "updated_at": "2020-01-10T19:25:03Z",
    "author_association": "CONTRIBUTOR",
    "body": "Initial suggestion for the key to be used in the new bucket. First byte is the number of \"digits\" in the prefix (since we use hexary tree, one digit is 4 bits). Other bytes are the digits of the prefix, possibly padded by one empty hex digit.\r\nWe might discover other key formats that work better",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/573172185/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/576230966",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/311#issuecomment-576230966",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/311",
    "id": 576230966,
    "node_id": "MDEyOklzc3VlQ29tbWVudDU3NjIzMDk2Ng==",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-01-20T11:23:49Z",
    "updated_at": "2020-01-21T10:01:41Z",
    "author_association": "COLLABORATOR",
    "body": "## Preface: \r\n“Nibbles sequences of various limited length” form totally different Set compare to “Bytes of fixed length”. Take a look: \r\n\r\n![1](https://user-images.githubusercontent.com/46885206/72720740-32730080-3bad-11ea-8702-4d16d36752c9.jpg)\r\n\r\nfmt.Sprintf(“%x”) - does follow same Hex logic - after x00 goes x01, but not x0000. fmt.Sprintf(“%x”) works on Set of “Bytes sequences of fixed length” (just very big length).\r\n\r\n#### Definitions:\r\nNibbles - Set of “Nibbles sequences of **various limited** length”\r\nBytes - Set of “Bytes sequences of **various limited** length”\r\nN - Max length of Nibbles (dimension)\r\nL - length of given nibbles sequence\r\nOrdering - property of mapping which preserve lexicographical order of elements\r\nSpace Compactness - property of mapping, where result bytes must take as less space as possible\r\n0 Compactness - property of mapping, where result bytes must be as close to 0 as possible (no skips)\r\nMapping - mapping from Set 1 to Set 2 which preserve ordering\r\n\r\n\r\n## Problem statement\r\n\r\nTo construct Mapping from Nibbles to Bytes with **Ordering** and **Space Compactness** props.  All work will happen in limited sets - because our original task is about hashes prefixes (trie prefixes have nibbles format). \r\n\r\n## Step 1: Construction of mapping with **Ordering** and **0 Compactness** props\r\n\r\nConstruct such mapping is easy and will help on Step 2 (sacrifice **0 Compactness** to gain **Space Compactness**). Let's illustrate in N=3 mapping from Nibbles to Natural numbers:\r\n\r\n![2](https://user-images.githubusercontent.com/46885206/72720807-50d8fc00-3bad-11ea-8f4e-cf837dfd228d.jpg)\r\n\r\nFor example nibble n1 has number: 16^2 + 16 + 1. Common formula:\r\n\r\n![3](https://user-images.githubusercontent.com/46885206/72721582-f80a6300-3bae-11ea-9e4c-d9e538374a08.jpg)\r\n\r\nTo derive right part from Formula (1) - open bracers and sum similar powers. Mapping from Bytes to Natural numbers looks same - just change 16 to 256. (Don't worry about huge powers performance. Sum of powers of 16 - doesn't have any variables -> can pre-calculate and cache with big.Int)\r\n\r\nConstructed mapping of Bytes and Nibbles to Natural numbers preserving Ordering but not Compact. But it's enough to show that we can map Nibbles to Bytes and preserve Ordering (just choose 2 elements from 2 sets which relate to same Natural number). \r\n\r\n## Step 2: Exchange \"0 Compaction\" to \"Space Compaction\" property\r\n\r\n#### Definitions:\r\nSparse Decimal - mapping to Natural numbers \"0 Compactness\" property.\r\nSparse Bytes - mapping to Bytes \"0 Compactness\" property.\r\n\r\nTo achieve it - make sure that all shortest target bytes are used and we still have enough space between elements to map any source nibbles without breaking ordering. \r\n\r\nHow much bytes we need to encode nibbles of max length L? `16^n+16^(n-1)+...+1 = 256^(n/2)+256^([n-1]/2)+... < 256^(n/2 + 1)` - then required `Nb = N/2 + 1` of Bytes.\r\n\r\nLet's illustrate Sparse Bytes mapping for `N=3 (then Nb = 3/2 + 1 = 2)`. \r\n\r\n![4](https://user-images.githubusercontent.com/46885206/72772539-bd4c0d80-3c36-11ea-84c2-e92c0b57c4f3.jpg)\r\n\r\nMapping construction:\r\n\r\n- Nibbles of len=1 will map to shortest Bytes (len=1), but 16 times more sparse (rarefied). For example: n1 -> x10=16*x01. Nibbles of len=2 will fill gaps (left bytes of len=1): n0,n1 -> x01, n2,n1 -> x21. \r\n\r\n- But nibbles of len=2 ending with 0 have no available byte of len=1, then such elements we will map to  bytes of len2. \r\n\r\n- Then nibbles of len3 will fill gaps (available bytes of len=2) also 16 times sparse. For example: n0,n0,n1 -> x0010, n0,n0,n2 -> x0020, etc...\r\n\r\n- But nibbles of len=3 ending with 0 have no available byte of len=2, then just map it to next available bytes of len=2. For examp n0,n0,n0 -> x0001, n0,n0,n0 -> x0001\r\n\r\n- End. \r\n\r\nIllustration for N=4,5,6 is below:\r\n\r\n![5](https://user-images.githubusercontent.com/46885206/72774020-c1c6f500-3c3b-11ea-90bd-893247333341.jpg)\r\n\r\nOnly Nibbles which looks like \"(X)(0) - non-zero amount of leading digit + non-zero amount of zeroes\" have no space for mapping, then we map them to element: `image(nX) + amount_of_zeroes`. \r\n\r\nCommon formula for mapping Non-Zero-Ending-Nibbles to Sparse Decimal (Formula has powers of 256, not 16 - because we need to get Sparse result in Bytes set. And 16 it's Sparse factor):\r\n\r\n![6](https://user-images.githubusercontent.com/46885206/72780333-2d678d00-3c51-11ea-88c2-1d57066a7091.jpg)\r\n\r\nZero-Ending-Nibbles: Non-Zero-Ending prefix handle by Formula(5), Zero suffix handle by Formula(1) with N=amount_of_zeroes. \r\n\r\n## Step 3: Optimization\r\n\r\nFormula (5) actually is straightforward compression of \"Nibbles of **limited** length\" to \"Bytes of **limited** length\" - just write nibbles one after another as string and think about result string as about Bytes: `n1,n0,n2,n5->x1025`; `n1->x10`; `n0,n1,n2->x012`. So, we don't need all that math all the time.\r\n\r\nBut, I don't see (yet) - how to avoid math for exceptions of Formula (5). No special tricks for Formula (1) - to map Zero-Nibbles to Bytes (but amount of Zero-Nibbles is limited -> pre-calculate/cache).\r\n\r\nCode: V0 implementation (Status: fixing bugs, adding tests) is in https://github.com/ledgerwatch/turbo-geth/blob/intermediate_trie_hashes/trie/witness_marshalling_test.go#L71\r\n\r\nToDo: to provide digits of compression results\r\n\r\n\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/576230966/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/586087150",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/311#issuecomment-586087150",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/311",
    "id": 586087150,
    "node_id": "MDEyOklzc3VlQ29tbWVudDU4NjA4NzE1MA==",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-02-14T04:01:27Z",
    "updated_at": "2020-02-14T04:01:27Z",
    "author_association": "COLLABORATOR",
    "body": "Agreed to store only nibbles of even length. Done. ",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/586087150/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
