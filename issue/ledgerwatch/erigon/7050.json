{
  "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
  "repository_url": "https://api.github.com/repos/ledgerwatch/erigon",
  "labels_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050/labels{/name}",
  "comments_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050/comments",
  "events_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050/events",
  "html_url": "https://github.com/ledgerwatch/erigon/issues/7050",
  "id": 1614206692,
  "node_id": "I_kwDOC0FsAM5gNtbk",
  "number": 7050,
  "title": "Analysis of chaindata/mdbx.dat - best backup strategies for such a huge file",
  "user": {
    "login": "J-A-M-E-5",
    "id": 26421539,
    "node_id": "MDQ6VXNlcjI2NDIxNTM5",
    "avatar_url": "https://avatars.githubusercontent.com/u/26421539?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/J-A-M-E-5",
    "html_url": "https://github.com/J-A-M-E-5",
    "followers_url": "https://api.github.com/users/J-A-M-E-5/followers",
    "following_url": "https://api.github.com/users/J-A-M-E-5/following{/other_user}",
    "gists_url": "https://api.github.com/users/J-A-M-E-5/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/J-A-M-E-5/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/J-A-M-E-5/subscriptions",
    "organizations_url": "https://api.github.com/users/J-A-M-E-5/orgs",
    "repos_url": "https://api.github.com/users/J-A-M-E-5/repos",
    "events_url": "https://api.github.com/users/J-A-M-E-5/events{/privacy}",
    "received_events_url": "https://api.github.com/users/J-A-M-E-5/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 4566396003,
      "node_id": "LA_kwDOC0FsAM8AAAABEC2sYw",
      "url": "https://api.github.com/repos/ledgerwatch/erigon/labels/Stale",
      "name": "Stale",
      "color": "ededed",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 11,
  "created_at": "2023-03-07T21:03:52Z",
  "updated_at": "2023-05-27T02:20:51Z",
  "closed_at": "2023-05-27T02:20:51Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "I thought I'd open up a ticket (this is not a bug) to encourage feedback and input from others. Idea is devising the best strategy for regular backups of erigon to \"the cloud\". The principle problem is tackling the 1.7TB mdbx.dat file, the main database. Unless you have super-fast bandwidth you are not going to send 1.7TB of data in 24 hours! If you are already running your erigon in the cloud (VPS/dedicated server) then you don't have this problem, but many users would be running locally simply because it's expensive having a node in the cloud principally due to disk-space required. However for $5/month you can store 2TB of backups with a backup service.\r\n\r\n### Following assumptions have been made.\r\n\r\n- MDBX database has a default pagesize of 4KB (this is the standard unless you tweak options when performing initial sync of erigon).\r\n- User has 2TB of \"scratch storage\" on the local system - perhaps a hard disk. A place to quickly copy their mdbx.dat file to, for minimum erigon downtime possible. I personally run erigon and geth purged node so always have new block announcement/TXs etc.. unless geth happened to crash whilst I was backing up erigon, but redundancy is a whole subject unto itself, so let's try and keep the problem as simple as possible...\r\n\r\n### Basic steps (we won't go into how-to backup other erigon files as that's quite simple): \r\n\r\n1. Shutdown erigon.\r\n2. Copy mdbx.dat to scratch storage + other erigon files.\r\n3. Restart erigon. (step 2 could have taken ~3 hours, so that's 3 hours downtime).\r\n4. Copy scratch storage to cloud.\r\n5. Goto step 1\r\n\r\n### Slightly more advanced (minimise erigon downtime):\r\n\r\n1. Shutdown erigon.\r\n2. If on LVM turn on snapshotting, otherwise with btrfs/ZFS etc.. make a snapshotted (frozen) version of the mdbx.dat file\r\n3. Copy other files (this is quick as it is mostly appended data)\r\n4. Restart erigon (steps 2 to 3 for sure took less than 5 minutes, you had less than 5 minutes downtime).\r\n5. Copy snapshot to scratch storage\r\n6. Delete snapshot - it should be noted until you delete the snapshot your disk I/O will be reduced.\r\n7. Copy scratch storage to cloud\r\n8. Goto step 1\r\n\r\nSo whilst your \"backup\" is now on the scratch disk it's not really a backup as its sitting inside the same server and an electrical problem could destroy everything. You might do a rsync over a LAN to another server which removes that issue, but a building fire destroys your backup. Until that backup is miles away you have no real backup. Which brings us to the cloud...\r\n\r\nOK so first backup to cloud there's no other way of doing it except for sending the 1.7TB. This took over 10 days for me. After that your backup is 10 days out of date, which means any attempts to differential copy (e.g. rsync with delta) will have a high load of 10 days worth of changes to process. Say this takes 8 days. You then have for the next backup just 8 days worth of changes which is going to be less to transfer and probably takes 6  days, and so on... As long as whatever strategy you use keeps reducing the time between backups, eventually this _should_ come down to around the desired 24 hours.\r\n\r\nRsync has a standard block_size \"window\" which is automatically calculated but can be manually specified. According to [this post](https://unix.stackexchange.com/a/587783) as we are dealing with a massive file our default rsync block size is going to be ~131KB which is for sure not optimal unless you have very few changes (minutes/hours) to the database since last backup. If you have lots of memory you can specify a block size of just 4KB and use the [--max-alloc=SIZE](https://download.samba.org/pub/rsync/rsync.1#opt--max-alloc) parameter. Whilst this 4KB matches erigon's default database pagesize this is probably not optimal either as for every block there is not only a memory overhead (--max-alloc will need to be around 32GiB for 4KB block size) but there will also be an overhead in internet traffic per block to ensure each block is delta-synced.\r\n\r\nAlso you have to bare in mind if your last backup was 12 hours ago your optimal block size will be different than if your last backup was 30 days ago.\r\n\r\nThis is where I am now, on the second sync running with a 8KB rsync blocksize. It seems around 3x quicker than the initial sync. Why 8KB? I dunno. 4KB seemed too silly. 1MB seemed too high. I'd like to know if this was optimal.\r\n\r\n### Other ideas I've thought of:-\r\n\r\nUse a tool such as [dcfldd](https://manpages.ubuntu.com/manpages/jammy/man1/dcfldd.1.html) to read the database but split it into files of N-bytes size, with the advantage that the entire file (as it was read from input) is md5summed for integrity, and also each part is. This makes one big problem into potentially thousands of little ones, which could all be rsynced. The only real downside to this is if you need to restore you might need extra diskspace to eventually \"cat\" the split files back into one big file. This means you can use 4KB rsync blocksize for these files on a system with less than 32GB of free memory. You could also be smarter  and compare the hashes of each split file (dcfldd already hashed them) to the previous backup, if it is the same as last time you can set the timestamp for that file to be the same as last time and rsync will ignore it as that particular chunk was unchanged.\r\n\r\nThis is where I am. I aim to revise this ticket as I make new discoveries and technical findings, perhaps upload some bash script or code examples etc... Relying on the collective brain-power and experience of all erigon users who for sure if they are interested in backups have seen these issues.\r\n\r\nI guess the best thing that could be achieved is to take a local backup of database at 00:00 UTC on day 1, and the same backup at 00:00 UTC day 2. And then create (or find) a tool to analyse differences between both files and calculate an optimal block size. Then repeat for an interlude of 2 days, 3 days, perhaps up to 20 days or until we got a good feel for how much 24 hours of blockchain activity impacts the database in terms of where changes are happening. Of course this is not exact as every 24 hours on the blockchain is different, but it has to be better than plucking numbers out of the air! Knowing a good blocksize to use depending on how many days your last-backup is stale, would help users get to the (for now) mythical status of sub-24 hour cloud backups as quickly as possible. There's also other variables to consider, what happens if you compact/reindex your erigon database - I'd presume you'd be back to waiting 10 days to back it up as practically every block would change.\r\n\r\nTo be continued... I appreciate all input & feedback.",
  "closed_by": {
    "login": "github-actions[bot]",
    "id": 41898282,
    "node_id": "MDM6Qm90NDE4OTgyODI=",
    "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/github-actions%5Bbot%5D",
    "html_url": "https://github.com/apps/github-actions",
    "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers",
    "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}",
    "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions",
    "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs",
    "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos",
    "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}",
    "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events",
    "type": "Bot",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050/timeline",
  "performed_via_github_app": null,
  "state_reason": "not_planned"
}
[
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1459114836",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1459114836",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1459114836,
    "node_id": "IC_kwDOC0FsAM5W-FNU",
    "user": {
      "login": "J-A-M-E-5",
      "id": 26421539,
      "node_id": "MDQ6VXNlcjI2NDIxNTM5",
      "avatar_url": "https://avatars.githubusercontent.com/u/26421539?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/J-A-M-E-5",
      "html_url": "https://github.com/J-A-M-E-5",
      "followers_url": "https://api.github.com/users/J-A-M-E-5/followers",
      "following_url": "https://api.github.com/users/J-A-M-E-5/following{/other_user}",
      "gists_url": "https://api.github.com/users/J-A-M-E-5/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/J-A-M-E-5/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/J-A-M-E-5/subscriptions",
      "organizations_url": "https://api.github.com/users/J-A-M-E-5/orgs",
      "repos_url": "https://api.github.com/users/J-A-M-E-5/repos",
      "events_url": "https://api.github.com/users/J-A-M-E-5/events{/privacy}",
      "received_events_url": "https://api.github.com/users/J-A-M-E-5/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-03-08T01:15:31Z",
    "updated_at": "2023-03-08T16:23:44Z",
    "author_association": "NONE",
    "body": "Some other ideas. Sync erigon with page size of 512K rather than standard 4K. I will be doing a resync from zero of Erigon as soon as I get my secondary server setup (redundancy) as I am not sure due to crashing a few times if my database is tainted or not, so may as well try this 512K page size.\r\n\r\nApparently according to the lead dev with a bigger page size it makes the filesize of mdbx.dat smaller but there is no performance difference or perhaps a slight decrease when running erigon - or at least he didn't see one. At this stage I'd be happy to sacrifice a little bit of erigon performance for a faster backup and less disk-space so I think these variables all need to be investigated. Also of course whilst my aim is to speed up rsync, the principle of block-sizes and finding \"the best\" applies to RAID stripe sizes, filesystem block/cluster sizes, which effects thing such as snapshots too. It for sure makes a big difference specifying block size instead of accepting default when creating LVM partitions and how each snapshot is a series of block-level changes.\r\n\r\nI am not sure if after a full sync of erigon if the best thing to do first would be a full compact of the database, and then initial backup or if it is better to leave the database with this \"slack space\". My upload speed is limited to around 3MiB/s, however recently with ~10% of today's backup rsynced using delta against backup from ~14 days ago I have seen rsync processing speeds of 120MiB/s. For the first 5% of the file rsync speed seemed to be max upload speed which suggests lots of changes at the start of the file. I almost gave up the idea of trying to rsync/delta before I saw this 120MiB/s, so patience is indeed a virtue. Obviously running at 40x my connection speed suggests that around 10% into the file not a lot has changed in the past 2 weeks. Now a slow speed is around 8MiB/s which is still double my wire speed so the delta algo is performing well at 8k block size. Would it perform better at 16k? At 4k? I dunno!!!\r\n\r\nSo my latest rsync estimates are around 60 hours for this backup to be complete, which is a huge increase from the ~340 hours initial backup took. Of course if I then immediately do another backup I'll only have 60 hours of changes for rsync to diff. I think I'm going to keep this 8k rsync blocksize even though right now it's consuming a lot of RAM, at least until I get under 24 hours backup time, and then bring it up and keep rsyncing and see what happens as I cannot dedicate this much RAM permanently for backups.\r\n\r\nUPDATE: I got confused with page_size, not sure why I thought max limit was 512KiB. It's actually 64KiB max. The actual rules can be seen using `erigon --help | grep \"pagesize\"`\r\n\r\n`--db.pagesize value                                      set mdbx pagesize on db creation: must be power of 2 and '256b <= pagesize <= 64kb'. default: equal to OperationSystem's pageSize (default: \"4KB\")`\r\n\r\nTherefor allowable pagesizes are 256b, 512b, 1KiB, 2KiB, 4KiB (default), 8KiB, 16KiB, 32KiB and 64KiB.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1459114836/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1500725337",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1500725337",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1500725337,
    "node_id": "IC_kwDOC0FsAM5Zc0BZ",
    "user": {
      "login": "dreadedhamish",
      "id": 5133413,
      "node_id": "MDQ6VXNlcjUxMzM0MTM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5133413?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dreadedhamish",
      "html_url": "https://github.com/dreadedhamish",
      "followers_url": "https://api.github.com/users/dreadedhamish/followers",
      "following_url": "https://api.github.com/users/dreadedhamish/following{/other_user}",
      "gists_url": "https://api.github.com/users/dreadedhamish/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dreadedhamish/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dreadedhamish/subscriptions",
      "organizations_url": "https://api.github.com/users/dreadedhamish/orgs",
      "repos_url": "https://api.github.com/users/dreadedhamish/repos",
      "events_url": "https://api.github.com/users/dreadedhamish/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dreadedhamish/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-04-07T23:43:46Z",
    "updated_at": "2023-04-07T23:43:46Z",
    "author_association": "NONE",
    "body": "Have you considered using ZFS snapshots and ZFS send/recv? I'm still researching it, but it looks fairly basic to take regular snapshots (incremental) and send them to a remote repository.  You wouldn't need to stop Erigon, and snapshots only take up space when there are changes.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1500725337/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1500850136",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1500850136",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1500850136,
    "node_id": "IC_kwDOC0FsAM5ZdSfY",
    "user": {
      "login": "keithchew",
      "id": 5557929,
      "node_id": "MDQ6VXNlcjU1NTc5Mjk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5557929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/keithchew",
      "html_url": "https://github.com/keithchew",
      "followers_url": "https://api.github.com/users/keithchew/followers",
      "following_url": "https://api.github.com/users/keithchew/following{/other_user}",
      "gists_url": "https://api.github.com/users/keithchew/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/keithchew/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/keithchew/subscriptions",
      "organizations_url": "https://api.github.com/users/keithchew/orgs",
      "repos_url": "https://api.github.com/users/keithchew/repos",
      "events_url": "https://api.github.com/users/keithchew/events{/privacy}",
      "received_events_url": "https://api.github.com/users/keithchew/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-04-08T09:55:22Z",
    "updated_at": "2023-04-08T10:01:30Z",
    "author_association": "NONE",
    "body": "hi @J-A-M-E-5, I have also been thinking about this topic for my own setup. For my case, one of the requirements is to have high availability/redundancy for the dApp and indexer. To achieve this, I setup 2 erigon nodes, and the dApp's back-end has logic to select the node that is the closest with the latest block. So, if one node is lagging (or goes down completely), the dApp continues to function seamlessly. \r\n\r\nSince my setup has redundancy, it is no longer time sensitive, ie I don't need to revive a node as quick as possible (unless both nodes go down, in which case I would need to add more nodes to increase resilience). \r\n\r\nThe next step was to look at how to stand up an erigon node as quick as possible, and that's where I had the same question as you, ie how to backup/restore from a good node to a fresh/bad node. In your case, you are backing up and restoring to the same node (but without redundancy, so your setup is time sensitive).\r\n\r\nI looked deeper into Erigon's design, and the initial sync of downloading snapshots is really smart (and efficient). So instead of a backup/restore, my plan is just to rebuild Erigon when a node dies. To further speed up the initial sync, I plan to see how I can host the snapshots on LAN. My other option is to have 3 nodes, and when 1 node dies, the second node takes over. Then, node 3 is stopped and all contents are rsync'ed to rebuild the dead node. \r\n\r\nWill update and share anything useful here when I get to comparing the restore time for the 2 options. Granted, not everyone can afford to run more than 1 node, and if so, in addition to the backup time, remember to also consider the time to restore and resume operation.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1500850136/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501047808",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1501047808",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1501047808,
    "node_id": "IC_kwDOC0FsAM5ZeCwA",
    "user": {
      "login": "dreadedhamish",
      "id": 5133413,
      "node_id": "MDQ6VXNlcjUxMzM0MTM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5133413?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dreadedhamish",
      "html_url": "https://github.com/dreadedhamish",
      "followers_url": "https://api.github.com/users/dreadedhamish/followers",
      "following_url": "https://api.github.com/users/dreadedhamish/following{/other_user}",
      "gists_url": "https://api.github.com/users/dreadedhamish/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dreadedhamish/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dreadedhamish/subscriptions",
      "organizations_url": "https://api.github.com/users/dreadedhamish/orgs",
      "repos_url": "https://api.github.com/users/dreadedhamish/repos",
      "events_url": "https://api.github.com/users/dreadedhamish/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dreadedhamish/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-04-09T05:48:06Z",
    "updated_at": "2023-04-09T05:48:06Z",
    "author_association": "NONE",
    "body": "Snapshots saves some time downloading, but it's not downloading the processed state, only the transactions in bulk, which erigon then processes. You are still looking at days depending on your system specs. The answer should be just copying the database.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501047808/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501048531",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1501048531",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1501048531,
    "node_id": "IC_kwDOC0FsAM5ZeC7T",
    "user": {
      "login": "keithchew",
      "id": 5557929,
      "node_id": "MDQ6VXNlcjU1NTc5Mjk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5557929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/keithchew",
      "html_url": "https://github.com/keithchew",
      "followers_url": "https://api.github.com/users/keithchew/followers",
      "following_url": "https://api.github.com/users/keithchew/following{/other_user}",
      "gists_url": "https://api.github.com/users/keithchew/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/keithchew/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/keithchew/subscriptions",
      "organizations_url": "https://api.github.com/users/keithchew/orgs",
      "repos_url": "https://api.github.com/users/keithchew/repos",
      "events_url": "https://api.github.com/users/keithchew/events{/privacy}",
      "received_events_url": "https://api.github.com/users/keithchew/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-04-09T05:55:04Z",
    "updated_at": "2023-04-09T10:07:18Z",
    "author_association": "NONE",
    "body": "Correct, but because my setup is not time sensitive, that is an option for me. For copying the DB (my other option stated above using rsync), I would need 3 nodes, so will need to decide if maintaining an extra node is worth the hassle (Note that my main requirement is 0 downtime during failure/restore, thus the extra node for rsync option).",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501048531/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501100275",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1501100275",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1501100275,
    "node_id": "IC_kwDOC0FsAM5ZePjz",
    "user": {
      "login": "dreadedhamish",
      "id": 5133413,
      "node_id": "MDQ6VXNlcjUxMzM0MTM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5133413?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dreadedhamish",
      "html_url": "https://github.com/dreadedhamish",
      "followers_url": "https://api.github.com/users/dreadedhamish/followers",
      "following_url": "https://api.github.com/users/dreadedhamish/following{/other_user}",
      "gists_url": "https://api.github.com/users/dreadedhamish/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dreadedhamish/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dreadedhamish/subscriptions",
      "organizations_url": "https://api.github.com/users/dreadedhamish/orgs",
      "repos_url": "https://api.github.com/users/dreadedhamish/repos",
      "events_url": "https://api.github.com/users/dreadedhamish/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dreadedhamish/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-04-09T10:53:13Z",
    "updated_at": "2023-04-09T10:53:13Z",
    "author_association": "NONE",
    "body": "Check out ZFS. You can perform snapshots and export them without any downtime.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501100275/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501101240",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1501101240",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1501101240,
    "node_id": "IC_kwDOC0FsAM5ZePy4",
    "user": {
      "login": "keithchew",
      "id": 5557929,
      "node_id": "MDQ6VXNlcjU1NTc5Mjk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5557929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/keithchew",
      "html_url": "https://github.com/keithchew",
      "followers_url": "https://api.github.com/users/keithchew/followers",
      "following_url": "https://api.github.com/users/keithchew/following{/other_user}",
      "gists_url": "https://api.github.com/users/keithchew/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/keithchew/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/keithchew/subscriptions",
      "organizations_url": "https://api.github.com/users/keithchew/orgs",
      "repos_url": "https://api.github.com/users/keithchew/repos",
      "events_url": "https://api.github.com/users/keithchew/events{/privacy}",
      "received_events_url": "https://api.github.com/users/keithchew/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-04-09T10:58:35Z",
    "updated_at": "2023-04-09T11:06:43Z",
    "author_association": "NONE",
    "body": "In order to capture the full state (no partial data written) of Erigon, I prefer to stop Erigon and then take a backup. So snapshotting while Erigon is running is not really for me. But if you manage to snapshot on a running Erigon and restore on another Erigon instance without any issues 100% of the time, please let me know, and I will reconsider my options.\r\n\r\nBut I get where you are coming from, instead of:\r\n- stop Erigon\r\n- rsync\r\n- start Erigon\r\n\r\nI could replace rsync with zfs snapshot. Yup, I could look into that after rsync (currently on ext4), but it does not reduce the number of nodes I need, nor change my restore process. Thanks for your suggestion.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501101240/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501110746",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1501110746",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1501110746,
    "node_id": "IC_kwDOC0FsAM5ZeSHa",
    "user": {
      "login": "dreadedhamish",
      "id": 5133413,
      "node_id": "MDQ6VXNlcjUxMzM0MTM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5133413?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dreadedhamish",
      "html_url": "https://github.com/dreadedhamish",
      "followers_url": "https://api.github.com/users/dreadedhamish/followers",
      "following_url": "https://api.github.com/users/dreadedhamish/following{/other_user}",
      "gists_url": "https://api.github.com/users/dreadedhamish/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dreadedhamish/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dreadedhamish/subscriptions",
      "organizations_url": "https://api.github.com/users/dreadedhamish/orgs",
      "repos_url": "https://api.github.com/users/dreadedhamish/repos",
      "events_url": "https://api.github.com/users/dreadedhamish/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dreadedhamish/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-04-09T11:53:20Z",
    "updated_at": "2023-04-09T11:53:20Z",
    "author_association": "NONE",
    "body": "Full disclosure - i haven't set it up yet, and I'm early in the process. Everywhere I've read praises ZFS for these instant snapshots, so I'm hoping it as good as promised. \r\nThere are 2 ways I'm planning on using it - hourly snapshots that aren't kept for very long. I've recently had my erigon database get corrupted, and when this happens again I plan on restoring from these local snapshots. As a secondary backup I'll have another pool somewhere else that uses zfs-send to only send snapshots - so only incremental changes.\r\nLooking at the ZFS features I'm not sure you coudn't set the 2 databases up to mirror each other, and then do a push/pull if one has an error.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501110746/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501118242",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1501118242",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1501118242,
    "node_id": "IC_kwDOC0FsAM5ZeT8i",
    "user": {
      "login": "keithchew",
      "id": 5557929,
      "node_id": "MDQ6VXNlcjU1NTc5Mjk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5557929?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/keithchew",
      "html_url": "https://github.com/keithchew",
      "followers_url": "https://api.github.com/users/keithchew/followers",
      "following_url": "https://api.github.com/users/keithchew/following{/other_user}",
      "gists_url": "https://api.github.com/users/keithchew/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/keithchew/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/keithchew/subscriptions",
      "organizations_url": "https://api.github.com/users/keithchew/orgs",
      "repos_url": "https://api.github.com/users/keithchew/repos",
      "events_url": "https://api.github.com/users/keithchew/events{/privacy}",
      "received_events_url": "https://api.github.com/users/keithchew/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-04-09T12:27:02Z",
    "updated_at": "2023-04-09T12:27:02Z",
    "author_association": "NONE",
    "body": "All the best, keep us posted for sure. I am very happy with my current setup. For my project, the Erigon node(s) is only one part of the whole platform, the main use case is providing redundancy and 100% uptime to dApp (ie API client), and always on the latest block.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1501118242/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1555429062",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1555429062",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1555429062,
    "node_id": "IC_kwDOC0FsAM5ctfbG",
    "user": {
      "login": "github-actions[bot]",
      "id": 41898282,
      "node_id": "MDM6Qm90NDE4OTgyODI=",
      "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/github-actions%5Bbot%5D",
      "html_url": "https://github.com/apps/github-actions",
      "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events",
      "type": "Bot",
      "site_admin": false
    },
    "created_at": "2023-05-20T02:18:59Z",
    "updated_at": "2023-05-20T02:18:59Z",
    "author_association": "NONE",
    "body": "This issue is stale because it has been open for 40 days with no activity. Remove stale label or comment, or this will be closed in 7 days.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1555429062/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1565164812",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/7050#issuecomment-1565164812",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/7050",
    "id": 1565164812,
    "node_id": "IC_kwDOC0FsAM5dSoUM",
    "user": {
      "login": "github-actions[bot]",
      "id": 41898282,
      "node_id": "MDM6Qm90NDE4OTgyODI=",
      "avatar_url": "https://avatars.githubusercontent.com/in/15368?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/github-actions%5Bbot%5D",
      "html_url": "https://github.com/apps/github-actions",
      "followers_url": "https://api.github.com/users/github-actions%5Bbot%5D/followers",
      "following_url": "https://api.github.com/users/github-actions%5Bbot%5D/following{/other_user}",
      "gists_url": "https://api.github.com/users/github-actions%5Bbot%5D/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/github-actions%5Bbot%5D/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/github-actions%5Bbot%5D/subscriptions",
      "organizations_url": "https://api.github.com/users/github-actions%5Bbot%5D/orgs",
      "repos_url": "https://api.github.com/users/github-actions%5Bbot%5D/repos",
      "events_url": "https://api.github.com/users/github-actions%5Bbot%5D/events{/privacy}",
      "received_events_url": "https://api.github.com/users/github-actions%5Bbot%5D/received_events",
      "type": "Bot",
      "site_admin": false
    },
    "created_at": "2023-05-27T02:20:50Z",
    "updated_at": "2023-05-27T02:20:50Z",
    "author_association": "NONE",
    "body": "This issue was closed because it has been stalled for 7 days with no activity.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1565164812/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
