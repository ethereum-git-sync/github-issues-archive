{
  "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
  "repository_url": "https://api.github.com/repos/ledgerwatch/erigon",
  "labels_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772/labels{/name}",
  "comments_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772/comments",
  "events_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772/events",
  "html_url": "https://github.com/ledgerwatch/erigon/issues/2772",
  "id": 1015102194,
  "node_id": "I_kwDOC0FsAM48gTry",
  "number": 2772,
  "title": "Chaindata on HDD not feasible, looking for solutions to reduce MDBX size or to make it faster on slow drives",
  "user": {
    "login": "Tronic",
    "id": 98187,
    "node_id": "MDQ6VXNlcjk4MTg3",
    "avatar_url": "https://avatars.githubusercontent.com/u/98187?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/Tronic",
    "html_url": "https://github.com/Tronic",
    "followers_url": "https://api.github.com/users/Tronic/followers",
    "following_url": "https://api.github.com/users/Tronic/following{/other_user}",
    "gists_url": "https://api.github.com/users/Tronic/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/Tronic/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/Tronic/subscriptions",
    "organizations_url": "https://api.github.com/users/Tronic/orgs",
    "repos_url": "https://api.github.com/users/Tronic/repos",
    "events_url": "https://api.github.com/users/Tronic/events{/privacy}",
    "received_events_url": "https://api.github.com/users/Tronic/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [

  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 18,
  "created_at": "2021-10-04T12:13:35Z",
  "updated_at": "2023-02-24T10:44:52Z",
  "closed_at": "2022-05-27T04:58:35Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Would it be possible to split cooler and hotter parts of the database to separate files? If COW is used on btrfs, erigon instantly fragments the database like crazy, making it very unusable. Because compression can only be used with COW, the database then takes 1.5 TB of disk space (and growing quickly by each day).\r\n\r\nIf old blocks and any indices that don't need to be constantly refreshed could be stored in a separate file, one could enable COW and compression for that, while keeping the current changes on a flat unfragmented file. Further, one could envision keeping bulk data on HDDs and dedicating SSD space on a separate filesystem only for the frequently modified parts.\r\n",
  "closed_by": {
    "login": "AskAlexSharov",
    "id": 46885206,
    "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
    "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/AskAlexSharov",
    "html_url": "https://github.com/AskAlexSharov",
    "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
    "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
    "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
    "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
    "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
    "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
    "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772/reactions",
    "total_count": 1,
    "+1": 1,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/933505636",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-933505636",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 933505636,
    "node_id": "IC_kwDOC0FsAM43pCpk",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-04T13:49:20Z",
    "updated_at": "2021-10-04T13:49:20Z",
    "author_association": "COLLABORATOR",
    "body": "We call this feature \"snapshot sync\" (not very related to geth's snapshot sync) and worked on it long time, but no ETA (don't expect it). \r\n\r\nAlso I believe hot part will be big enough and fragmented same way. \r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/933505636/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 1,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/933543964",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-933543964",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 933543964,
    "node_id": "IC_kwDOC0FsAM43pMAc",
    "user": {
      "login": "Tronic",
      "id": 98187,
      "node_id": "MDQ6VXNlcjk4MTg3",
      "avatar_url": "https://avatars.githubusercontent.com/u/98187?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Tronic",
      "html_url": "https://github.com/Tronic",
      "followers_url": "https://api.github.com/users/Tronic/followers",
      "following_url": "https://api.github.com/users/Tronic/following{/other_user}",
      "gists_url": "https://api.github.com/users/Tronic/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Tronic/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Tronic/subscriptions",
      "organizations_url": "https://api.github.com/users/Tronic/orgs",
      "repos_url": "https://api.github.com/users/Tronic/repos",
      "events_url": "https://api.github.com/users/Tronic/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Tronic/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-04T14:29:45Z",
    "updated_at": "2021-10-04T14:29:45Z",
    "author_association": "NONE",
    "body": "Okay, at least the nodatacow Erigon seems to be running decently well on the SSD-cached HDD RAID now, and spending 1.5 TB of HDD is not that expensive but the HDDs are quite heavily loaded still.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/933543964/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/950855905",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-950855905",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 950855905,
    "node_id": "IC_kwDOC0FsAM44rOjh",
    "user": {
      "login": "Tronic",
      "id": 98187,
      "node_id": "MDQ6VXNlcjk4MTg3",
      "avatar_url": "https://avatars.githubusercontent.com/u/98187?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Tronic",
      "html_url": "https://github.com/Tronic",
      "followers_url": "https://api.github.com/users/Tronic/followers",
      "following_url": "https://api.github.com/users/Tronic/following{/other_user}",
      "gists_url": "https://api.github.com/users/Tronic/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Tronic/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Tronic/subscriptions",
      "organizations_url": "https://api.github.com/users/Tronic/orgs",
      "repos_url": "https://api.github.com/users/Tronic/repos",
      "events_url": "https://api.github.com/users/Tronic/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Tronic/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-25T12:05:48Z",
    "updated_at": "2021-10-25T12:05:48Z",
    "author_association": "NONE",
    "body": "An update to anyone looking into this. **Erigon reads only 4 KiB blocks** and probably because it is MMAP I am not getting any readahead, so as a result the adjacent data does not normally get cached and everything goes extremely slow. This is solved more or less by a cronjob that reads the entire chaindata and throws it away, so that the cache stays warm. But now the database is getting so large that it cannot fit on the cache anymore, so I had to adjust the cronjob to only read the final hundreds of gigabytes of it, which also works decently well. Commit cycles typically end up processing 1-4 blocks with an average lag around 30 seconds.\r\n\r\nHowever, Erigon is having major trouble syncing after the server has been down for a few hours. Syncing from 8 hours behind seems to take about 16 hours until Erigon catches the current blocks. This is with the warm SSD cache still present from before reboot.\r\n\r\nTherefore, it would seem that **the only decent way of running Erigon is to purchase a 4 TB SSD** (which are insanely expensive) or a RAID of smaller SSDs, because very soon the database cannot fit on a 2 TB SSD anymore, and even SSD-cached HDD is just way too slow for reliable and rapid operation.\r\n\r\nThere certainly should be room for improvement and faster performance because bitcoind/electrumx and monerod run on HDD without issues and manage to sync within minutes after the said 8 hour downtime. Since everyone says that Erigon is the way to go, I did not even try Geth or the others, which might possibly give higher performance especially when backed by HDDs.\r\n\r\nOne primary way to improve might be to add an I/O layer without MMAP but presumably that would be a major change to MDBX and not something to be lightly implemented. That would also have the benefit of avoiding SIGBUS crashes because traditional I/O allows graceful handling of errors such as ENOSPC. Another would be to rethink the data structures, which similarly does not appear to be very feasible. Or perhaps by adding more in-RAM or on-SSD caching of indices and hot blocks, perhaps allowing either less space usage making full SSD storage feasible, or allowing for less IOPS making HDDs more feasible, but @AskAlexSharov already said that this probably won't be possible.\r\n\r\nIn any case, I believe this needs to be solved by means other than just requiring everyone to buy ever bigger SSDs. Reopening for discussion and further development.\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/950855905/reactions",
      "total_count": 3,
      "+1": 2,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 1,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/953107889",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-953107889",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 953107889,
    "node_id": "IC_kwDOC0FsAM44z0Wx",
    "user": {
      "login": "Tronic",
      "id": 98187,
      "node_id": "MDQ6VXNlcjk4MTg3",
      "avatar_url": "https://avatars.githubusercontent.com/u/98187?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Tronic",
      "html_url": "https://github.com/Tronic",
      "followers_url": "https://api.github.com/users/Tronic/followers",
      "following_url": "https://api.github.com/users/Tronic/following{/other_user}",
      "gists_url": "https://api.github.com/users/Tronic/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Tronic/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Tronic/subscriptions",
      "organizations_url": "https://api.github.com/users/Tronic/orgs",
      "repos_url": "https://api.github.com/users/Tronic/repos",
      "events_url": "https://api.github.com/users/Tronic/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Tronic/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-27T16:40:09Z",
    "updated_at": "2021-10-27T16:40:09Z",
    "author_association": "NONE",
    "body": "There is also https://man7.org/linux/man-pages/man2/madvise.2.html that could be used if there is any knowledge of next blocks that might be needed. Since processing is mostly sequential, such tips given to kernel might have a great impact on reading speed (allowing reordering of I/O for faster access as well as performing it concurrently with other processing).\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/953107889/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/953432707",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-953432707",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 953432707,
    "node_id": "IC_kwDOC0FsAM441DqD",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-28T01:43:17Z",
    "updated_at": "2021-10-28T01:43:17Z",
    "author_association": "COLLABORATOR",
    "body": "During genesis sync - bottleneck is at reading State (not blocks). But predict future state is impossible without txs execution (we do store senders, so predict them is easy, but it's not enough). \r\n\r\n\"because bitcoind/electrumx and monerod run on HDD without issues\" they are small. We are at the place where hot part of state > RAM.  \r\n\r\nActually - main enemy of Disks - is the crypto-hashed keys. Crypto-hashed keys are guarantee to make your reads/writes as random as possible - means get worst perfomance. Big tables without crypto-hashed keys producing 10x (if not 100x) less writes than small tables with crypto-hashed keys.    \r\n\r\nSnapshot sync (which will move historical data to another db) - not ready yet. No ETA.\r\n\r\nAbout madvise - OS also has PageCache with LRU. So, most of reads already goes to RAM. \r\n\r\nAbout HDD - you can experiment with big --batchSize, and with very small --batchSize (32Mb). Because batchSize > 32Mb does less writes to disk, but does break PageCache at commit, because batch=32mb producing 1 GB of state changes, and 1 Gb is our size of transaction in MDBX (tx_size=RAM/21). Your target is to have 0 \"page spills\" at batch commit (we have this graphic in grafana).\r\n\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/953432707/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/953747973",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-953747973",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 953747973,
    "node_id": "IC_kwDOC0FsAM442QoF",
    "user": {
      "login": "Tronic",
      "id": 98187,
      "node_id": "MDQ6VXNlcjk4MTg3",
      "avatar_url": "https://avatars.githubusercontent.com/u/98187?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/Tronic",
      "html_url": "https://github.com/Tronic",
      "followers_url": "https://api.github.com/users/Tronic/followers",
      "following_url": "https://api.github.com/users/Tronic/following{/other_user}",
      "gists_url": "https://api.github.com/users/Tronic/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/Tronic/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/Tronic/subscriptions",
      "organizations_url": "https://api.github.com/users/Tronic/orgs",
      "repos_url": "https://api.github.com/users/Tronic/repos",
      "events_url": "https://api.github.com/users/Tronic/events{/privacy}",
      "received_events_url": "https://api.github.com/users/Tronic/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-28T11:16:24Z",
    "updated_at": "2021-10-28T11:16:24Z",
    "author_association": "NONE",
    "body": "Thanks for your reply, again. Just some more comments; not planning to carry on this conversation any further because we all have other work to do. Hopefully some of this helps.\r\n\r\nThe page cache is not working too well, due to only a single page being cached at a time. Not sure if adjacent pages to those just accessed have any tendency to be more frequently accessed but since manually warming the cache helps, this seems to be the case. Also, if at any phase you find a list of *several* other pages to load, and Erigon proceeds to access the mmapped memory one of those at a time, it performs much slower than if the kernel could group and reorder all those reads optimally. Providing MADV_WILLNEED with any locations that may be needed as soon as they are known allows for such prefetching and reordering.\r\n\r\nEthereum spec and Erigon internals are too complicated for me to get involved with, but if you say that cryptohashing actually only allows seeing the very next position of the database to read, I will take your word on it.\r\n\r\nI believe that write performance by itself is not an issue. On HDD the random 4 KiB reads seem to be the major problem because it takes about the same time to read either random 4 KiB or sequential 1.2 MiB. If instead of reading only the requested 4 KiB an entire 1 MiB chunk was fetched to cache, it takes less than twice the time and you already benefit if any subsequent request falls within that same megabyte. Providing MADV_WILLNEED with larger chunks than actually required within the known to be hot areas (recent blocks, transactions and indices?) allows the kernel to perform larger reads.\r\n\r\nTo make SSDs much more feasible, variable-sized database pages and/or compression could be used. I see a lot of zeroes and a lot of ASCII strings in the database, and the strings often repeat the same text. Thus it is not surprising that simple disk compression can reduce the size to less than a half. But as stated, disk compression at least on btrfs cannot cope with the database write pattern, so it would be better to implement this within Erigon itself. The drawback of course is that random access on the DB becomes more difficult and that writes in the middle may not be possible without reorganizing the data (i.e. the same problems that the filesystem level compression has to deal with).",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/953747973/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/954361450",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-954361450",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 954361450,
    "node_id": "IC_kwDOC0FsAM444mZq",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-10-29T02:34:54Z",
    "updated_at": "2021-10-29T02:34:54Z",
    "author_association": "COLLABORATOR",
    "body": "MADV_WILLNEED - in general it's of course good idea. We can't mark whole db as MADV_WILLNEED because db > RAM. If we start mark some regions of db with MADV_WILLNEED (because we will need them soon), then need to be sure that we mark them as MADV_DONNEED when this data is not useful anymore. It's manual memory-management. One wrong move - and you will get memory leak - which will very hard to debug: valgrind/hiptrack can't highlight VirtualMemory leaks, OOM killer will never come to us because virtual memory doesn't belong to our process. You will just observe reducing PageCache hit-rate (because more useless data stored there). \r\n\r\nIncrease pagesize from 4Kb to 64Kb maybe can help. Mdbx does support it. But I tested only on SSD and it increased overall disk read/write traffic.\r\n\r\nCrypto-hashed keys - \"cryptohashing actually only allows seeing the very next position of the database to read\" - no, i mean - crypto-hash destroying data-locality. If you have 2 keys \"k1\" and \"k2\", then they will likely located on the same page (Eth state keys are small, up to 50 of them can fit into 1 page). But sha256(k1) and sha256(k2) will lay on different pages with ~100% probability. It leads to bad PageCache utilisations (this is reason why hot part of state > RAM). We did get rid of crypto-hashed keys in most of places, but for 2 places we didn't find good way for this. \r\n\r\nBut. I think that ultimate solution for this - is \"SnapshotSync\" where we just will not execute 5 years of ETH history on HDD. It also will lead to smaller state (because historical state snapshot will live in another file). \r\n\r\nFYI: we did test ZFS compression - and it worked well (20% of speed overhead on ssd). So, maybe for HDD you also can increase zfs compression chunk (default is 128Kb). Then you will read this chunk sequentially.   ",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/954361450/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 1,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/971502202",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-971502202",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 971502202,
    "node_id": "IC_kwDOC0FsAM455_J6",
    "user": {
      "login": "gituser",
      "id": 104405,
      "node_id": "MDQ6VXNlcjEwNDQwNQ==",
      "avatar_url": "https://avatars.githubusercontent.com/u/104405?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/gituser",
      "html_url": "https://github.com/gituser",
      "followers_url": "https://api.github.com/users/gituser/followers",
      "following_url": "https://api.github.com/users/gituser/following{/other_user}",
      "gists_url": "https://api.github.com/users/gituser/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/gituser/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/gituser/subscriptions",
      "organizations_url": "https://api.github.com/users/gituser/orgs",
      "repos_url": "https://api.github.com/users/gituser/repos",
      "events_url": "https://api.github.com/users/gituser/events{/privacy}",
      "received_events_url": "https://api.github.com/users/gituser/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-11-17T11:46:41Z",
    "updated_at": "2021-11-17T11:54:14Z",
    "author_association": "NONE",
    "body": "Many thanks to @Tronic for this research.\r\n\r\nI was considering switching from [openethereum ](https://github.com/openethereum/openethereum) (ex parity) to erigon to run it on HDDs (as NVME/SSD storage is quite expensive) but it seems it's not ready for it at all.\r\n\r\nFurthermore, you can't even split data across multiple storage devices as there is only 1 big file mdbx.\r\n\r\nOn openethereum you could at least move old files to HDD storage and leave e.g. fresh 30 days history on SSD and this way reduce it's usage on SSD.\r\n\r\n@AskAlexSharov somewhere I saw that erigon is capable running on HDDs it seems this claim gone now, I think at this stage it should be noted erigon can only be run on SSDs.\r\n\r\nMaybe add a remark regarding SSD requirement here - https://github.com/ledgerwatch/erigon#system-requirements",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/971502202/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/971514469",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-971514469",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 971514469,
    "node_id": "IC_kwDOC0FsAM456CJl",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-11-17T12:03:00Z",
    "updated_at": "2021-11-17T12:03:00Z",
    "author_association": "COLLABORATOR",
    "body": "You may trust this tweet https://twitter.com/paolorebuffo/status/1400574790679867396?s=21\r\n\r\nIt’s possible to run Erigon on most modern latency-oriented HDD - if you are not in rush and keep real-time tip of chain is not important. But we never recommended it. Some guys had this as a dream - but never get there. \r\n\r\nWe don’t have warp sync yet - can’t move only ancient blocks to hdd now. \r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/971514469/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1139277014",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-1139277014",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 1139277014,
    "node_id": "IC_kwDOC0FsAM5D5_zW",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-05-27T04:58:35Z",
    "updated_at": "2022-05-27T04:58:35Z",
    "author_association": "COLLABORATOR",
    "body": "--syncmode=snap released\r\nnow you can mount datadir/snapshots to HDD and datadir/chaindata to faster disk\r\nsnapshots are using ReadAhead feature of OS (because they store data sequentially) - at least during genesis sysnc\r\n\r\nfuture release of Erigon2 will move more data to Snapshots (only blocks now).\r\n\r\nin some places parallelisation and warmup are added (but not everywhere). \r\n\r\nI have thinking about some new flag (aka --disktype=throughput) which will switch erigon to HDD-friendly or CloudHighThroughputDisk-friendly modes. But it's only in dreams now.\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1139277014/reactions",
      "total_count": 3,
      "+1": 0,
      "-1": 0,
      "laugh": 1,
      "hooray": 2,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1154461510",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-1154461510",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 1154461510,
    "node_id": "IC_kwDOC0FsAM5Ez69G",
    "user": {
      "login": "mtgnoah",
      "id": 5161963,
      "node_id": "MDQ6VXNlcjUxNjE5NjM=",
      "avatar_url": "https://avatars.githubusercontent.com/u/5161963?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mtgnoah",
      "html_url": "https://github.com/mtgnoah",
      "followers_url": "https://api.github.com/users/mtgnoah/followers",
      "following_url": "https://api.github.com/users/mtgnoah/following{/other_user}",
      "gists_url": "https://api.github.com/users/mtgnoah/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mtgnoah/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mtgnoah/subscriptions",
      "organizations_url": "https://api.github.com/users/mtgnoah/orgs",
      "repos_url": "https://api.github.com/users/mtgnoah/repos",
      "events_url": "https://api.github.com/users/mtgnoah/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mtgnoah/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-06-13T21:33:45Z",
    "updated_at": "2022-06-13T21:33:45Z",
    "author_association": "NONE",
    "body": "> now you can mount datadir/snapshots to HDD and datadir/chaindata to faster disk\r\n\r\nSo what will the storage savings be for this? 225gb for the snapshots or are the storage savings greater than this?",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1154461510/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1156272197",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-1156272197",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 1156272197,
    "node_id": "IC_kwDOC0FsAM5E61BF",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2022-06-15T10:08:36Z",
    "updated_at": "2022-06-15T10:08:36Z",
    "author_association": "COLLABORATOR",
    "body": "https://erigon.substack.com/p/disk-footprint-changes-in-new-erigon?s=r",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1156272197/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 1,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1426197837",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-1426197837",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 1426197837,
    "node_id": "IC_kwDOC0FsAM5VAg1N",
    "user": {
      "login": "guglez",
      "id": 15347812,
      "node_id": "MDQ6VXNlcjE1MzQ3ODEy",
      "avatar_url": "https://avatars.githubusercontent.com/u/15347812?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/guglez",
      "html_url": "https://github.com/guglez",
      "followers_url": "https://api.github.com/users/guglez/followers",
      "following_url": "https://api.github.com/users/guglez/following{/other_user}",
      "gists_url": "https://api.github.com/users/guglez/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/guglez/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/guglez/subscriptions",
      "organizations_url": "https://api.github.com/users/guglez/orgs",
      "repos_url": "https://api.github.com/users/guglez/repos",
      "events_url": "https://api.github.com/users/guglez/events{/privacy}",
      "received_events_url": "https://api.github.com/users/guglez/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-02-10T18:42:46Z",
    "updated_at": "2023-02-10T18:42:46Z",
    "author_association": "NONE",
    "body": "@AskAlexSharov did those dreams about CloudHighThroughputDisk friendly modes come true?",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1426197837/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1426555413",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-1426555413",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 1426555413,
    "node_id": "IC_kwDOC0FsAM5VB4IV",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-02-11T01:21:03Z",
    "updated_at": "2023-02-11T01:21:03Z",
    "author_association": "COLLABORATOR",
    "body": "> @AskAlexSharov did those dreams about CloudHighThroughputDisk friendly modes come true?\r\n \r\nProgress is here, but you will suffer anyway. (for example I have mainnet on gcloud pd-ssd). \r\n\r\n- I did add several “parallel warmup” places to Erigon2\r\n- main problem of such disks: or you need parallelize work (read+transform). Or you need mass parallel read - and single-thread transform based on data in RAM. And it’s unclear “how much parallel warmupers it must use”. \r\n- another option is: Moving data out of DB allow change MADVISE, and it’s kind of better than parallel warmup. Erigon3 does it and it getting closer. \r\n- another option: use zfs with big pageSize (and increase page-size in erigon too). It will read more data at once and waste more ram (and likely reduce fragmentation), but overall reduce amount of disk reads. Increase ram will also help - but will need handle server reboot somehow (by some parallel warmup like “integration warmup —table=PlainState”, latest versions of mdbx_dump also have new flags -u/-U) - of course it can be automated if erigon can detect disk type. \r\n- erigon using madv_random on DB - to reduce ram waste. But maybe changing it may help for cloud drives (no time to test it much). \r\n- Also not always clear - how erigon can detect disk type. ",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1426555413/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1441504512",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-1441504512",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 1441504512,
    "node_id": "IC_kwDOC0FsAM5V650A",
    "user": {
      "login": "J-A-M-E-5",
      "id": 26421539,
      "node_id": "MDQ6VXNlcjI2NDIxNTM5",
      "avatar_url": "https://avatars.githubusercontent.com/u/26421539?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/J-A-M-E-5",
      "html_url": "https://github.com/J-A-M-E-5",
      "followers_url": "https://api.github.com/users/J-A-M-E-5/followers",
      "following_url": "https://api.github.com/users/J-A-M-E-5/following{/other_user}",
      "gists_url": "https://api.github.com/users/J-A-M-E-5/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/J-A-M-E-5/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/J-A-M-E-5/subscriptions",
      "organizations_url": "https://api.github.com/users/J-A-M-E-5/orgs",
      "repos_url": "https://api.github.com/users/J-A-M-E-5/repos",
      "events_url": "https://api.github.com/users/J-A-M-E-5/events{/privacy}",
      "received_events_url": "https://api.github.com/users/J-A-M-E-5/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-02-23T10:16:48Z",
    "updated_at": "2023-02-23T10:16:48Z",
    "author_association": "NONE",
    "body": "@AskAlexSharov very interesting discussion.\r\n\r\nI have LVM RAID0 across 2 SSD's, with a ext4 partition dedicated solely to Erigon chaindata (snapshots are on HDD). I can snapshot this partition with LVM snapshot and then restart the node and have reliable reasonably quick backup. Now I could use btrfs maybe and use btrfs snapshots.\r\n\r\nI remember when I striped my LVM RAID I selected 32kb stripe size. So this means 64kb across 2 SSD array. Now I'm not sure if this means I should recompile kernel, format the LVM partition as 64kb ext4 (normal kernel supports 4k).  Or use 32kb ext4. Change erigon mdbx page size to match. Or can I used the erigon db as a block device and skip filesystem altogether and have the file be the partition? This would remove fs-layer from the equation so I'd only have to worry about stripe size of RAID0 array, and page size of erigon db, and of course any attempts by the database to grow!\r\n\r\nThere's so many variables I'd love to test all, but you can imagine the time syncing or dumping/loading to get a real-world config.",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1441504512/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1442751514",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-1442751514",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 1442751514,
    "node_id": "IC_kwDOC0FsAM5V_qQa",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-02-24T03:22:15Z",
    "updated_at": "2023-02-24T03:22:15Z",
    "author_association": "COLLABORATOR",
    "body": "@J-A-M-E-5 \r\n1. change mdbx page size is ok. bigger pages -> less fragmentations and metadata -> smaller db. but also increasing overall write amount - but it may help for HDD because of less fragmentation. \r\n2.  used the erigon db as a block device - no. But you may try reduce FS impact by increasing `mdbx GrowthStep` (less grow steps -> less file fragmentation -> smaller FS/OS metadata to convert virtual addresses to physical. LMDB - by this reason doesn't allow grow/shrink to minimize this factor as much as possible - need re-open db to increase db size (but usually just create huge db from beginning). But in Erigon and MDBX we did 1 step towards usability vs performance).  \r\n3. we had \"erigon on zfs\" thread in discord with much of related info and benchmards - but seems somebody deleted it. \r\n4. FYI: Erigon3 is getting closer - it moving state history and historical indices to snapshots. Mainnet now looks as: `700GB /erigon/snapshots/history/`, `300GB chaindata`. ",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1442751514/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1442763505",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-1442763505",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 1442763505,
    "node_id": "IC_kwDOC0FsAM5V_tLx",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-02-24T03:38:41Z",
    "updated_at": "2023-02-24T03:38:41Z",
    "author_association": "COLLABORATOR",
    "body": "5. We didn't update mdbx for long time (probably will do in Erigon3). It has new feature in WRITE_MAP mode: by using `minicore()` it can avoid generating page-fault for pages which we plan fully re-write (so called pre-fault). It can be game changer for initial sync on HDD. ",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1442763505/reactions",
      "total_count": 1,
      "+1": 1,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1443470997",
    "html_url": "https://github.com/ledgerwatch/erigon/issues/2772#issuecomment-1443470997",
    "issue_url": "https://api.github.com/repos/ledgerwatch/erigon/issues/2772",
    "id": 1443470997,
    "node_id": "IC_kwDOC0FsAM5WCZ6V",
    "user": {
      "login": "AskAlexSharov",
      "id": 46885206,
      "node_id": "MDQ6VXNlcjQ2ODg1MjA2",
      "avatar_url": "https://avatars.githubusercontent.com/u/46885206?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/AskAlexSharov",
      "html_url": "https://github.com/AskAlexSharov",
      "followers_url": "https://api.github.com/users/AskAlexSharov/followers",
      "following_url": "https://api.github.com/users/AskAlexSharov/following{/other_user}",
      "gists_url": "https://api.github.com/users/AskAlexSharov/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/AskAlexSharov/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/AskAlexSharov/subscriptions",
      "organizations_url": "https://api.github.com/users/AskAlexSharov/orgs",
      "repos_url": "https://api.github.com/users/AskAlexSharov/repos",
      "events_url": "https://api.github.com/users/AskAlexSharov/events{/privacy}",
      "received_events_url": "https://api.github.com/users/AskAlexSharov/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-02-24T10:44:51Z",
    "updated_at": "2023-02-24T10:44:51Z",
    "author_association": "COLLABORATOR",
    "body": "Found zfs thread: https://discord.com/channels/687972960811745322/1049704837564084245",
    "reactions": {
      "url": "https://api.github.com/repos/ledgerwatch/erigon/issues/comments/1443470997/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
