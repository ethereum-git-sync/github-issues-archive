{
  "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
  "repository_url": "https://api.github.com/repos/ChainSafe/lodestar",
  "labels_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604/labels{/name}",
  "comments_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604/comments",
  "events_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604/events",
  "html_url": "https://github.com/ChainSafe/lodestar/issues/5604",
  "id": 1738421874,
  "node_id": "I_kwDOCD5_Gc5nnjZy",
  "number": 5604,
  "title": "Network worker extremely busy / high event loop lag / high I/O lag",
  "user": {
    "login": "dapplion",
    "id": 35266934,
    "node_id": "MDQ6VXNlcjM1MjY2OTM0",
    "avatar_url": "https://avatars.githubusercontent.com/u/35266934?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/dapplion",
    "html_url": "https://github.com/dapplion",
    "followers_url": "https://api.github.com/users/dapplion/followers",
    "following_url": "https://api.github.com/users/dapplion/following{/other_user}",
    "gists_url": "https://api.github.com/users/dapplion/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/dapplion/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/dapplion/subscriptions",
    "organizations_url": "https://api.github.com/users/dapplion/orgs",
    "repos_url": "https://api.github.com/users/dapplion/repos",
    "events_url": "https://api.github.com/users/dapplion/events{/privacy}",
    "received_events_url": "https://api.github.com/users/dapplion/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 4754137758,
      "node_id": "LA_kwDOCD5_Gc8AAAABG15ing",
      "url": "https://api.github.com/repos/ChainSafe/lodestar/labels/meta-feature-request",
      "name": "meta-feature-request",
      "color": "B5CF5F",
      "default": false,
      "description": "Issues to track feature requests."
    }
  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/milestones/32",
    "html_url": "https://github.com/ChainSafe/lodestar/milestone/32",
    "labels_url": "https://api.github.com/repos/ChainSafe/lodestar/milestones/32/labels",
    "id": 9640171,
    "node_id": "MI_kwDOCD5_Gc4Akxjr",
    "number": 32,
    "title": "v1.11.0",
    "description": "",
    "creator": {
      "login": "philknows",
      "id": 58080811,
      "node_id": "MDQ6VXNlcjU4MDgwODEx",
      "avatar_url": "https://avatars.githubusercontent.com/u/58080811?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/philknows",
      "html_url": "https://github.com/philknows",
      "followers_url": "https://api.github.com/users/philknows/followers",
      "following_url": "https://api.github.com/users/philknows/following{/other_user}",
      "gists_url": "https://api.github.com/users/philknows/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/philknows/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/philknows/subscriptions",
      "organizations_url": "https://api.github.com/users/philknows/orgs",
      "repos_url": "https://api.github.com/users/philknows/repos",
      "events_url": "https://api.github.com/users/philknows/events{/privacy}",
      "received_events_url": "https://api.github.com/users/philknows/received_events",
      "type": "User",
      "site_admin": false
    },
    "open_issues": 11,
    "closed_issues": 9,
    "state": "open",
    "created_at": "2023-07-11T02:13:12Z",
    "updated_at": "2023-08-22T13:49:59Z",
    "due_on": null,
    "closed_at": null
  },
  "comments": 11,
  "created_at": "2023-06-02T15:38:50Z",
  "updated_at": "2023-08-22T11:38:02Z",
  "closed_at": null,
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "body": "### Problem description\r\n\r\nGeneral issue to recap observations of enabling the network worker on high load nodes.\r\n\r\nOn June 25th network worker is enabled on Goerli on the unstable group nodes. The lg1k node with 1000 validators connected, shows bad network performance with long response times and other metrics indicating very slow network handling.\r\n\r\nOn the week of June 25th we deploy network worker on feat1 group nodes, turning the network worker on and off (moving network stack to the main thread). The metrics below capture\r\n\r\n- after enabling the worker the main thread got less busy (green line decreasing)\r\n- network worker is extremely busy, causing bad network behaviour\r\n\r\n_Below, active handles in pink = network worker on_\r\n_Note there's an unrelated memory leak going on that's being addressed in another issue_\r\n_feat1-mainnet node running on mainnet with --subscribe-all-subnets, no validators attached, version v1.8.0/888c599, timeframe: 5/24 till 5/30_\r\n\r\n![image1](https://github.com/ChainSafe/lodestar/assets/35266934/f03cfe75-3e83-4685-8a8b-832dc92acac0)\r\n![image2](https://github.com/ChainSafe/lodestar/assets/35266934/f8592c3a-7aa4-4d30-9090-11d8245ff25e)\r\n![image3](https://github.com/ChainSafe/lodestar/assets/35266934/79582127-7db6-42e9-a64b-506c852af54f)\r\n\r\nThe biggest difference between using the network worker is the huge increase in outbound network traffic. Outbound gossip traffic jumped from 0.3MB/s to 2MB/s (~6x). Before this node dropped 50% of incoming attestations, now process everything relatively timely.\r\n\r\n_feat1-mainnet node running on mainnet with --subscribe-all-subnets, no validators attached, version v1.8.0/888c599, timeframe: 5/27 till 6/02_\r\n\r\n![image](https://github.com/ChainSafe/lodestar/assets/35266934/8c1fde3c-5e58-4b8d-a3a6-899070bfe129)\r\n\r\nconfirmed with system metrics\r\n\r\n![image](https://github.com/ChainSafe/lodestar/assets/35266934/b4867e50-6342-487c-bb3d-8ac8f8c263b1)\r\n\r\n\r\n\r\n**Questions**\r\n\r\n- What is the network worker doing that chokes so much?\r\n- Why is the overall load of the node up so much?\r\n- Is there any overhead of having most OS I/O interactions in a worker?\r\n\r\n\r\n### Solution description\r\n\r\n--\r\n\r\n### Additional context\r\n\r\n_No response_",
  "closed_by": {
    "login": "tuyennhv",
    "id": 10568965,
    "node_id": "MDQ6VXNlcjEwNTY4OTY1",
    "avatar_url": "https://avatars.githubusercontent.com/u/10568965?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/tuyennhv",
    "html_url": "https://github.com/tuyennhv",
    "followers_url": "https://api.github.com/users/tuyennhv/followers",
    "following_url": "https://api.github.com/users/tuyennhv/following{/other_user}",
    "gists_url": "https://api.github.com/users/tuyennhv/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/tuyennhv/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/tuyennhv/subscriptions",
    "organizations_url": "https://api.github.com/users/tuyennhv/orgs",
    "repos_url": "https://api.github.com/users/tuyennhv/repos",
    "events_url": "https://api.github.com/users/tuyennhv/events{/privacy}",
    "received_events_url": "https://api.github.com/users/tuyennhv/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604/timeline",
  "performed_via_github_app": null,
  "state_reason": "reopened"
}
[
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1575982741",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1575982741",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1575982741,
    "node_id": "IC_kwDOCD5_Gc5d75aV",
    "user": {
      "login": "matthewkeil",
      "id": 18608739,
      "node_id": "MDQ6VXNlcjE4NjA4NzM5",
      "avatar_url": "https://avatars.githubusercontent.com/u/18608739?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/matthewkeil",
      "html_url": "https://github.com/matthewkeil",
      "followers_url": "https://api.github.com/users/matthewkeil/followers",
      "following_url": "https://api.github.com/users/matthewkeil/following{/other_user}",
      "gists_url": "https://api.github.com/users/matthewkeil/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/matthewkeil/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/matthewkeil/subscriptions",
      "organizations_url": "https://api.github.com/users/matthewkeil/orgs",
      "repos_url": "https://api.github.com/users/matthewkeil/repos",
      "events_url": "https://api.github.com/users/matthewkeil/events{/privacy}",
      "received_events_url": "https://api.github.com/users/matthewkeil/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-06-05T03:23:41Z",
    "updated_at": "2023-06-05T04:10:52Z",
    "author_association": "MEMBER",
    "body": "@dapplion I have come up with two strategies to poll the worker to generate profiles.\r\n\r\nThe first is the `perf record` command with the `--tid=***` flag to target the worker thread (and its `libuv` children).  There is also `--per-thread` flag to create separate `mmap` per thread but I am not sure how this will play in with the `V8` output until I pull the trigger a few more times because its not working as expected so need to figure out why.  I am playing with it now to see what is coming out of it and will report back as I know more. \r\n\r\nhttps://man7.org/linux/man-pages/man1/perf-record.1.html\r\n\r\nThis is what I found on one of the boxes running `v1.9.0-rc.0` so def looks like its gonna be one of the second batch on beacon.\r\n```sh\r\nadmin   1814305  212 10.4 209601852 6904800 ?   Ssl  Jun01 10330:54 node ./packages/cli/bin/lodestar beacon --rcConfig /data/rcconfig.yml\r\nadmin   1814731  2.8  0.5 54947096 342896 ?     Ssl  Jun01 139:35 node ./packages/cli/bin/lodestar validator --rcConfig /data/rcconfig.yml\r\nadmin@beta:~/beacon$ ls /proc/1814305/task\r\n1814305  1814318  1814319  1814320  1814321  1814322  1814323  1814325  1814326  1814327  1814328  1814335  1814338  1814339  1814340  1814341  1814342  1814343  1814344  1814345  1814346  1814347  1814348  1814349  1814352\r\nadmin@beta:~/beacon$ ls /proc/1814731/task\r\n1814731  1814743  1814744  1814745  1814746  1814747  1814748  1814749  1814750  1814751  1814752  1814771\r\n```\r\n\r\n\r\nThe second is a native library that plugs into the node inspector protocol and can generate profiles for the worker thread.  This will likely not show the native system (like profiler currently) calls like network but I will attempt to plug it in and see what happens.\r\n\r\nhttps://github.com/hyj1991/v8-profiler-next\r\n\r\n\r\nI suppose there is a third option but its really just an extension of the first option to get the correct `tid` from the runtime.\r\n\r\n`worker.threadId` [is available](https://github.com/nodejs/node/blob/4166d40d0873b6d8a0c7291872c8d20dc680b1d7/lib/worker_threads.js#L9) through the standard node api and that looks like it will [return the `uv_thread_t`](https://github.com/nodejs/node/blob/4166d40d0873b6d8a0c7291872c8d20dc680b1d7/src/node_worker.h#L91)  which is a [typedef for the `p_thread`](https://github.com/nodejs/node/blob/4166d40d0873b6d8a0c7291872c8d20dc680b1d7/deps/uv/include/uv/unix.h#L134) so should correlate correctly with on of the tasks in `/proc/<PID/task` dir theoretically.  If the above does not work I will push a branch that outputs that as a last resort but we should be able to get that right from the system without having to ask node...\r\n\r\n\r\n### the tl/dr; \r\nJust need to figure out the right tid's to poll but getting closer...",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1575982741/reactions",
      "total_count": 2,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 2,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1578241289",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1578241289",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1578241289,
    "node_id": "IC_kwDOCD5_Gc5eEg0J",
    "user": {
      "login": "matthewkeil",
      "id": 18608739,
      "node_id": "MDQ6VXNlcjE4NjA4NzM5",
      "avatar_url": "https://avatars.githubusercontent.com/u/18608739?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/matthewkeil",
      "html_url": "https://github.com/matthewkeil",
      "followers_url": "https://api.github.com/users/matthewkeil/followers",
      "following_url": "https://api.github.com/users/matthewkeil/following{/other_user}",
      "gists_url": "https://api.github.com/users/matthewkeil/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/matthewkeil/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/matthewkeil/subscriptions",
      "organizations_url": "https://api.github.com/users/matthewkeil/orgs",
      "repos_url": "https://api.github.com/users/matthewkeil/repos",
      "events_url": "https://api.github.com/users/matthewkeil/events{/privacy}",
      "received_events_url": "https://api.github.com/users/matthewkeil/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-06-06T09:00:29Z",
    "updated_at": "2023-06-06T09:00:29Z",
    "author_association": "MEMBER",
    "body": "🎉   HOORAY!!  Got a worker thread flamegraph.\r\n\r\nSomething isn't correct but its definitely stating to \"work\".  Couple more tries and I think I will have it working as expected\r\n\r\n<img width=\"1728\" alt=\"Screen Shot 2023-06-06 at 4 58 10 AM\" src=\"https://github.com/ChainSafe/lodestar/assets/18608739/6df65707-1b1f-420a-b235-e5b8b97b5e99\">\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1578241289/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1581091711",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1581091711",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1581091711,
    "node_id": "IC_kwDOCD5_Gc5ePYt_",
    "user": {
      "login": "matthewkeil",
      "id": 18608739,
      "node_id": "MDQ6VXNlcjE4NjA4NzM5",
      "avatar_url": "https://avatars.githubusercontent.com/u/18608739?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/matthewkeil",
      "html_url": "https://github.com/matthewkeil",
      "followers_url": "https://api.github.com/users/matthewkeil/followers",
      "following_url": "https://api.github.com/users/matthewkeil/following{/other_user}",
      "gists_url": "https://api.github.com/users/matthewkeil/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/matthewkeil/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/matthewkeil/subscriptions",
      "organizations_url": "https://api.github.com/users/matthewkeil/orgs",
      "repos_url": "https://api.github.com/users/matthewkeil/repos",
      "events_url": "https://api.github.com/users/matthewkeil/events{/privacy}",
      "received_events_url": "https://api.github.com/users/matthewkeil/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-06-07T15:44:18Z",
    "updated_at": "2023-06-07T15:44:18Z",
    "author_association": "MEMBER",
    "body": "Forwarded from discord on behalf of @dapplion:\r\n\r\nProcess will be included in lodestar docs at a future date.\r\n\r\nwas collected via:\r\n\r\n`sudo perf record -F 999 -p $(pgrep -f '/usr/src/lodestar/packages/cli/bin/lodestar beacon') -g -- sleep 60`\r\n and processed with `sudo perf script -F +pid,+tid -f > perf.out`\r\n\r\nthe flamegraph was created via `inferno` with the following commands\r\n\r\n```sh\r\ncargo install inferno\r\ncat perf.out | inferno-collapse-perf --pid --tid --all | inferno-flamegraph > out.svg\r\n```\r\n\r\nand made more readable by removing `font-family:monospace` from the svg source\r\n\r\nresults were:\r\n\r\n```\r\nthread ID 5905 takes 48.2% of total CPU time there a bunch of overhead with:\r\n- libc.so: 3% @g11tech this is a linux lib for linking?\r\n- epoll: 0.8% (poll i/o)\r\n- garbage collection: 1.2%\r\n- OS tcp handling: 1%\r\n\r\nJS stacks start with 36.7% of total CPU, of which:\r\n- mplex: 4.2%\r\n- gossipsub: rest\r\n\r\nLooking into depth on the stacks:\r\n- noise: 1.5%\r\n- as-sha-256: 1.9%\r\n- MessagePort.PostMessage: 1.4%\r\n```\r\n\r\n![threaded_flamegraph](https://github.com/ChainSafe/lodestar/assets/18608739/e6827cca-7ac6-457a-918f-bb4bafb44a3e)\r\n\r\n![out](https://github.com/ChainSafe/lodestar/assets/18608739/4c085993-8c72-434b-b3da-ad9dcb472093)\r\n\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1581091711/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1586525505",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1586525505",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1586525505,
    "node_id": "IC_kwDOCD5_Gc5ekHVB",
    "user": {
      "login": "tuyennhv",
      "id": 10568965,
      "node_id": "MDQ6VXNlcjEwNTY4OTY1",
      "avatar_url": "https://avatars.githubusercontent.com/u/10568965?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/tuyennhv",
      "html_url": "https://github.com/tuyennhv",
      "followers_url": "https://api.github.com/users/tuyennhv/followers",
      "following_url": "https://api.github.com/users/tuyennhv/following{/other_user}",
      "gists_url": "https://api.github.com/users/tuyennhv/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/tuyennhv/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/tuyennhv/subscriptions",
      "organizations_url": "https://api.github.com/users/tuyennhv/orgs",
      "repos_url": "https://api.github.com/users/tuyennhv/repos",
      "events_url": "https://api.github.com/users/tuyennhv/events{/privacy}",
      "received_events_url": "https://api.github.com/users/tuyennhv/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-06-12T03:39:41Z",
    "updated_at": "2023-06-12T03:39:41Z",
    "author_association": "CONTRIBUTOR",
    "body": "Attaching network thread profiles from #5628 \r\n\r\n[0610_network_thread_lg1k.zip](https://github.com/ChainSafe/lodestar/files/11717306/0610_network_thread_lg1k.zip)\r\n[0610_network_thread_mainnet.zip](https://github.com/ChainSafe/lodestar/files/11717307/0610_network_thread_mainnet.zip)\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1586525505/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1587035357",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1587035357",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1587035357,
    "node_id": "IC_kwDOCD5_Gc5emDzd",
    "user": {
      "login": "tuyennhv",
      "id": 10568965,
      "node_id": "MDQ6VXNlcjEwNTY4OTY1",
      "avatar_url": "https://avatars.githubusercontent.com/u/10568965?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/tuyennhv",
      "html_url": "https://github.com/tuyennhv",
      "followers_url": "https://api.github.com/users/tuyennhv/followers",
      "following_url": "https://api.github.com/users/tuyennhv/following{/other_user}",
      "gists_url": "https://api.github.com/users/tuyennhv/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/tuyennhv/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/tuyennhv/subscriptions",
      "organizations_url": "https://api.github.com/users/tuyennhv/orgs",
      "repos_url": "https://api.github.com/users/tuyennhv/repos",
      "events_url": "https://api.github.com/users/tuyennhv/events{/privacy}",
      "received_events_url": "https://api.github.com/users/tuyennhv/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-06-12T10:20:12Z",
    "updated_at": "2023-06-12T10:20:12Z",
    "author_association": "CONTRIBUTOR",
    "body": "Found this in https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1586525505 when we run libp2p in a separate worker thread\r\n\r\n<img width=\"1052\" alt=\"Screenshot 2023-06-12 at 17 13 29\" src=\"https://github.com/ChainSafe/js-libp2p-gossipsub/assets/10568965/93880b10-c068-4cb6-bccd-df3c32a0601e\">\r\n\r\nin v1.8.0 of lodestar, it has a lot of multiple small `runMicroTasks` (80_041) while way fewer/big `runMicroTasks` (8_978) in network thread version\r\n\r\nI think it's due to more `sleep(0)` call in v1.8.0, we need to add more calls like that in network thread version",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1587035357/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1587529568",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1587529568",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1587529568,
    "node_id": "IC_kwDOCD5_Gc5en8dg",
    "user": {
      "login": "wemeetagain",
      "id": 1348242,
      "node_id": "MDQ6VXNlcjEzNDgyNDI=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1348242?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/wemeetagain",
      "html_url": "https://github.com/wemeetagain",
      "followers_url": "https://api.github.com/users/wemeetagain/followers",
      "following_url": "https://api.github.com/users/wemeetagain/following{/other_user}",
      "gists_url": "https://api.github.com/users/wemeetagain/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/wemeetagain/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/wemeetagain/subscriptions",
      "organizations_url": "https://api.github.com/users/wemeetagain/orgs",
      "repos_url": "https://api.github.com/users/wemeetagain/repos",
      "events_url": "https://api.github.com/users/wemeetagain/events{/privacy}",
      "received_events_url": "https://api.github.com/users/wemeetagain/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-06-12T15:05:04Z",
    "updated_at": "2023-06-12T15:05:04Z",
    "author_association": "MEMBER",
    "body": "Yeah, seems like the network thread has long uninterrupted strands of microqueue work",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1587529568/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1630492520",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1630492520",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1630492520,
    "node_id": "IC_kwDOCD5_Gc5hL1do",
    "user": {
      "login": "matthewkeil",
      "id": 18608739,
      "node_id": "MDQ6VXNlcjE4NjA4NzM5",
      "avatar_url": "https://avatars.githubusercontent.com/u/18608739?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/matthewkeil",
      "html_url": "https://github.com/matthewkeil",
      "followers_url": "https://api.github.com/users/matthewkeil/followers",
      "following_url": "https://api.github.com/users/matthewkeil/following{/other_user}",
      "gists_url": "https://api.github.com/users/matthewkeil/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/matthewkeil/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/matthewkeil/subscriptions",
      "organizations_url": "https://api.github.com/users/matthewkeil/orgs",
      "repos_url": "https://api.github.com/users/matthewkeil/repos",
      "events_url": "https://api.github.com/users/matthewkeil/events{/privacy}",
      "received_events_url": "https://api.github.com/users/matthewkeil/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-07-11T09:38:45Z",
    "updated_at": "2023-07-11T09:38:45Z",
    "author_association": "MEMBER",
    "body": "Making some headway on this after speaking with @bnoordhuis.  He gave us some good breadcrumbs to follow and after pulling some more perf data its pointing to page faults as a likely cause. \r\n\r\n```sh\r\n~/beacon$ sudo perf stat -e \"alignment-faults,bpf-output,cgroup-switches,context-switches,cpu-clock,cpu-migrations,emulation-faults,major-faults,minor-faults,page-faults,task-clock\" -p $(pgrep -f '/usr/src/lodestar/packages/cli/bin/lodestar beacon') sleep 60\r\n\r\nWithout worker loop:\r\n Performance counter stats for process id '1090':\r\n\r\n                 0      alignment-faults          #    0.000 /sec                   \r\n                 0      bpf-output                #    0.000 /sec                   \r\n            66,412      cgroup-switches           #  447.230 /sec                   \r\n            69,557      context-switches          #  468.409 /sec                   \r\n        148,477.87 msec cpu-clock                 #    2.475 CPUs utilized          \r\n             2,124      cpu-migrations            #   14.303 /sec                   \r\n                 0      emulation-faults          #    0.000 /sec                   \r\n                91      major-faults              #    0.613 /sec                   \r\n            87,603      minor-faults              #  589.933 /sec                   \r\n            87,694      page-faults               #  590.546 /sec                   \r\n        148,515.02 msec task-clock                #    2.475 CPUs utilized          \r\n\r\n      60.001487911 seconds time elapsed\r\n\r\nWith the worker loop:\r\n Performance counter stats for process id '31161':\r\n\r\n                 0      alignment-faults          #    0.000 /sec                   \r\n                 0      bpf-output                #    0.000 /sec                   \r\n            83,721      cgroup-switches           #  443.785 /sec                   \r\n            94,519      context-switches          #  501.023 /sec                   \r\n        188,626.29 msec cpu-clock                 #    3.144 CPUs utilized          \r\n             3,892      cpu-migrations            #   20.631 /sec                   \r\n                 0      emulation-faults          #    0.000 /sec                   \r\n                52      major-faults              #    0.276 /sec                   \r\n           265,900      minor-faults              #    1.409 K/sec                  \r\n           265,952      page-faults               #    1.410 K/sec                  \r\n        188,677.76 msec task-clock                #    3.145 CPUs utilized          \r\n\r\n      60.001568935 seconds time elapsed\r\n```\r\n\r\nThe root cause of the page faults is likely GC but a resolution still needs to be determined. As a first pass to try and resolve the issue I upped the new space size as there was a considerable amount of scavenge GC happening.  The new space was set at 32mb and 64 mb.  \r\n\r\nThere quantity of network thread scavenge leveled off at roughly 18mb so setting slightly higher than the default 16mb will have some benefit but it is not the root cause.\r\n\r\n<img width=\"572\" alt=\"Screenshot 2023-07-11 at 5 24 25 AM\" src=\"https://github.com/ChainSafe/lodestar/assets/18608739/9dc29b6a-8e14-4ff7-934f-e5dd1b997ec1\">\r\n\r\nEvent loop lag was measurable down on one instance but basically unchanged on another so its mixed.  Network traffic was much lower on the better performing node though.  There are a few more corners to look in and I will circle back and message Ben to let him know what I found with regard to IPC channel queue and messaging lag.\r\n\r\n<img width=\"828\" alt=\"memory-defaults\" src=\"https://github.com/ChainSafe/lodestar/assets/18608739/7aed33cb-6e1e-4ef8-8ef2-670ae091ca36\">\r\n\r\n<img width=\"836\" alt=\"new-space-32mb\" src=\"https://github.com/ChainSafe/lodestar/assets/18608739/23cb32ba-de0b-4f12-b9e9-6051469dab62\">\r\n\r\n\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1630492520/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1631379481",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1631379481",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1631379481,
    "node_id": "IC_kwDOCD5_Gc5hPOAZ",
    "user": {
      "login": "bnoordhuis",
      "id": 275871,
      "node_id": "MDQ6VXNlcjI3NTg3MQ==",
      "avatar_url": "https://avatars.githubusercontent.com/u/275871?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/bnoordhuis",
      "html_url": "https://github.com/bnoordhuis",
      "followers_url": "https://api.github.com/users/bnoordhuis/followers",
      "following_url": "https://api.github.com/users/bnoordhuis/following{/other_user}",
      "gists_url": "https://api.github.com/users/bnoordhuis/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/bnoordhuis/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/bnoordhuis/subscriptions",
      "organizations_url": "https://api.github.com/users/bnoordhuis/orgs",
      "repos_url": "https://api.github.com/users/bnoordhuis/repos",
      "events_url": "https://api.github.com/users/bnoordhuis/events{/privacy}",
      "received_events_url": "https://api.github.com/users/bnoordhuis/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-07-11T19:15:57Z",
    "updated_at": "2023-07-11T19:15:57Z",
    "author_association": "NONE",
    "body": "Drive-by observation: the number of cpu-migrations in the worker thread is almost twice as high.\r\n\r\nThat's bad for performance (flushes cpu caches, page tables, etc.) but is probably explained by the kernel rescheduling the thread when it incurs a page fault.\r\n\r\nDid upping the new space reduce the number of page faults and migrations?",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1631379481/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1631464320",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1631464320",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1631464320,
    "node_id": "IC_kwDOCD5_Gc5hPiuA",
    "user": {
      "login": "matthewkeil",
      "id": 18608739,
      "node_id": "MDQ6VXNlcjE4NjA4NzM5",
      "avatar_url": "https://avatars.githubusercontent.com/u/18608739?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/matthewkeil",
      "html_url": "https://github.com/matthewkeil",
      "followers_url": "https://api.github.com/users/matthewkeil/followers",
      "following_url": "https://api.github.com/users/matthewkeil/following{/other_user}",
      "gists_url": "https://api.github.com/users/matthewkeil/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/matthewkeil/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/matthewkeil/subscriptions",
      "organizations_url": "https://api.github.com/users/matthewkeil/orgs",
      "repos_url": "https://api.github.com/users/matthewkeil/repos",
      "events_url": "https://api.github.com/users/matthewkeil/events{/privacy}",
      "received_events_url": "https://api.github.com/users/matthewkeil/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-07-11T20:26:19Z",
    "updated_at": "2023-07-11T20:26:19Z",
    "author_association": "MEMBER",
    "body": "Thanks for checking in and the SUPER quick response last week!! I still need to add the metric for IPC communication and we had a bit of a fake out with loop-lag metrics because the node that was deployed to first was seeing half the amount of network traffic as the others (just a function of the number of peers it was communicating with).\r\n\r\nI moved the branch to another cluster and it has been stabilizing for a few days now.  I pulled updated `stat` and it does seem like like the minor and page faults are way down and near that of the non-worker case.  🎉   The metrics are showing that we scavenge roughly 17mb on the worker so bumping the new space was probably prudent.  I also did a test bumping to 64mb but there was no difference from the 32 so we have probably raised it enough to cover the workload.\r\n\r\nRun 1\r\n```sh\r\nPerformance counter stats for process id '838397':\r\n\r\n                 0      alignment-faults          #    0.000 /sec                   \r\n                 0      bpf-output                #    0.000 /sec                   \r\n            71,029      cgroup-switches           #  623.165 /sec                   \r\n            72,103      context-switches          #  632.588 /sec                   \r\n        113,959.82 msec cpu-clock                 #    1.899 CPUs utilized          \r\n             1,956      cpu-migrations            #   17.161 /sec                   \r\n                 0      emulation-faults          #    0.000 /sec                   \r\n                 0      major-faults              #    0.000 /sec                   \r\n            88,493      minor-faults              #  776.383 /sec                   \r\n            88,493      page-faults               #  776.383 /sec                   \r\n        114,002.29 msec task-clock                #    1.900 CPUs utilized          \r\n\r\n      60.001479677 seconds time elapsed\r\n```\r\nRun 2\r\n```sh\r\nPerformance counter stats for process id '838397':\r\n\r\n                 0      alignment-faults          #    0.000 /sec                   \r\n                 0      bpf-output                #    0.000 /sec                   \r\n            67,617      cgroup-switches           #  576.157 /sec                   \r\n            71,075      context-switches          #  605.623 /sec                   \r\n        117,337.69 msec cpu-clock                 #    1.956 CPUs utilized          \r\n             2,192      cpu-migrations            #   18.678 /sec                   \r\n                 0      emulation-faults          #    0.000 /sec                   \r\n                 0      major-faults              #    0.000 /sec                   \r\n            71,858      minor-faults              #  612.295 /sec                   \r\n            71,858      page-faults               #  612.295 /sec                   \r\n        117,379.38 msec task-clock                #    1.956 CPUs utilized          \r\n\r\n      60.001200425 seconds time elapsed\r\n```\r\n\r\nThe event loop lag is still pretty high though but the network response times have come down a bit.\r\n\r\nI have an unrelated branch that I am near complete working on and then I was going to switch back over and add the worker/main thread communication metrics so we can see what is cooking there.\r\n\r\nAs a note I was able to confirm that we have `cgroupv2` on our machines.\r\n```sh\r\nadmin@feat2~$ cd /sys/fs/cgroup/\r\nadmin@feat2:/sys/fs/cgroup$ ls\r\ncgroup.controllers      cgroup.subtree_control  cpu.stat             io.cost.qos       memory.pressure                sys-kernel-debug.mount\r\ncgroup.max.depth        cgroup.threads          dev-hugepages.mount  io.pressure       memory.stat                    sys-kernel-tracing.mount\r\ncgroup.max.descendants  cpu.pressure            dev-mqueue.mount     io.prio.class     misc.capacity                  system.slice\r\ncgroup.procs            cpuset.cpus.effective   init.scope           io.stat           sys-fs-fuse-connections.mount  user.slice\r\ncgroup.stat             cpuset.mems.effective   io.cost.model        memory.numa_stat  sys-kernel-config.mount\r\nadmin@feat2:/sys/fs/cgroup$ cat cgroup.controllers\r\ncpuset cpu io memory hugetlb pids rdma misc\r\n```\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1631464320/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1643003384",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1643003384",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1643003384,
    "node_id": "IC_kwDOCD5_Gc5h7j34",
    "user": {
      "login": "tuyennhv",
      "id": 10568965,
      "node_id": "MDQ6VXNlcjEwNTY4OTY1",
      "avatar_url": "https://avatars.githubusercontent.com/u/10568965?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/tuyennhv",
      "html_url": "https://github.com/tuyennhv",
      "followers_url": "https://api.github.com/users/tuyennhv/followers",
      "following_url": "https://api.github.com/users/tuyennhv/following{/other_user}",
      "gists_url": "https://api.github.com/users/tuyennhv/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/tuyennhv/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/tuyennhv/subscriptions",
      "organizations_url": "https://api.github.com/users/tuyennhv/orgs",
      "repos_url": "https://api.github.com/users/tuyennhv/repos",
      "events_url": "https://api.github.com/users/tuyennhv/events{/privacy}",
      "received_events_url": "https://api.github.com/users/tuyennhv/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-07-20T02:12:54Z",
    "updated_at": "2023-07-20T02:12:54Z",
    "author_association": "CONTRIBUTOR",
    "body": "> Drive-by observation: the number of cpu-migrations in the worker thread is almost twice as high.\r\n\r\ncpu is reduced from > 300% to ~200% on a mainnet node in https://github.com/ChainSafe/lodestar/pull/5747#issuecomment-1641884347 . I see better event loop lag there\r\n\r\n<img width=\"1279\" alt=\"Screenshot 2023-07-20 at 09 11 55\" src=\"https://github.com/ChainSafe/lodestar/assets/10568965/91acbc99-6cea-4d2f-bfa4-4bd3bf446e64\">\r\n\r\nvs unstable\r\n\r\n<img width=\"1289\" alt=\"Screenshot 2023-07-20 at 09 12 25\" src=\"https://github.com/ChainSafe/lodestar/assets/10568965/eec8acc1-12c1-4e06-969d-ecfee65afb6a\">\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1643003384/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1666534436",
    "html_url": "https://github.com/ChainSafe/lodestar/issues/5604#issuecomment-1666534436",
    "issue_url": "https://api.github.com/repos/ChainSafe/lodestar/issues/5604",
    "id": 1666534436,
    "node_id": "IC_kwDOCD5_Gc5jVUwk",
    "user": {
      "login": "nflaig",
      "id": 38436224,
      "node_id": "MDQ6VXNlcjM4NDM2MjI0",
      "avatar_url": "https://avatars.githubusercontent.com/u/38436224?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/nflaig",
      "html_url": "https://github.com/nflaig",
      "followers_url": "https://api.github.com/users/nflaig/followers",
      "following_url": "https://api.github.com/users/nflaig/following{/other_user}",
      "gists_url": "https://api.github.com/users/nflaig/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/nflaig/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/nflaig/subscriptions",
      "organizations_url": "https://api.github.com/users/nflaig/orgs",
      "repos_url": "https://api.github.com/users/nflaig/repos",
      "events_url": "https://api.github.com/users/nflaig/events{/privacy}",
      "received_events_url": "https://api.github.com/users/nflaig/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-08-05T15:28:25Z",
    "updated_at": "2023-08-07T16:52:10Z",
    "author_association": "MEMBER",
    "body": "After looking at benchmarks of `worker_threads` vs `child_process.fork` here https://github.com/orgs/nodejs/discussions/44264, I really wonder if it is good to use a worker_thread for the network.\r\n\r\nThe drawbacks of child processes mentioned in https://github.com/orgs/nodejs/discussions/44264#discussioncomment-3428883 don't really apply in our case since we spin up the network worker just once and we are not taking advantage of shared memory.\r\n\r\nBut the drawbacks of worker_threads might cause the issues we are seeing\r\n> the former (worker_thread) will use a CPU slice in the process schedule while the later (child_process) practically gets a better CPU share, being a full process.\r\n\r\nAnother good argument for using a child process is mentioned in https://github.com/piscinajs/piscina/issues/81#issuecomment-807139880, it would provide better DOS protection for the main thread which is one of the main goals mentioned in https://github.com/ChainSafe/lodestar/issues/5447.",
    "reactions": {
      "url": "https://api.github.com/repos/ChainSafe/lodestar/issues/comments/1666534436/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
