{
  "url": "https://api.github.com/repos/hyperledger/besu/issues/4319",
  "repository_url": "https://api.github.com/repos/hyperledger/besu",
  "labels_url": "https://api.github.com/repos/hyperledger/besu/issues/4319/labels{/name}",
  "comments_url": "https://api.github.com/repos/hyperledger/besu/issues/4319/comments",
  "events_url": "https://api.github.com/repos/hyperledger/besu/issues/4319/events",
  "html_url": "https://github.com/hyperledger/besu/issues/4319",
  "id": 1352505347,
  "node_id": "I_kwDODE2jmc5QnZgD",
  "number": 4319,
  "title": "Validator node can't sync with other nodes after restart",
  "user": {
    "login": "LucasSalmen",
    "id": 4901301,
    "node_id": "MDQ6VXNlcjQ5MDEzMDE=",
    "avatar_url": "https://avatars.githubusercontent.com/u/4901301?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/LucasSalmen",
    "html_url": "https://github.com/LucasSalmen",
    "followers_url": "https://api.github.com/users/LucasSalmen/followers",
    "following_url": "https://api.github.com/users/LucasSalmen/following{/other_user}",
    "gists_url": "https://api.github.com/users/LucasSalmen/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/LucasSalmen/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/LucasSalmen/subscriptions",
    "organizations_url": "https://api.github.com/users/LucasSalmen/orgs",
    "repos_url": "https://api.github.com/users/LucasSalmen/repos",
    "events_url": "https://api.github.com/users/LucasSalmen/events{/privacy}",
    "received_events_url": "https://api.github.com/users/LucasSalmen/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 2152224197,
      "node_id": "MDU6TGFiZWwyMTUyMjI0MTk3",
      "url": "https://api.github.com/repos/hyperledger/besu/labels/TeamRevenant",
      "name": "TeamRevenant",
      "color": "78e298",
      "default": false,
      "description": "GH issues worked on by Revenant Team"
    }
  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 3,
  "created_at": "2022-08-26T16:48:51Z",
  "updated_at": "2023-01-08T09:24:46Z",
  "closed_at": null,
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "<!-- Have you done the following? -->\r\n<!--   * read the Code of Conduct? By filing an Issue, you are expected to -->  \r\n<!--     comply with it, including treating everyone with respect: -->\r\n<!--     https://github.com/hyperledger/besu/blob/main/CODE_OF_CONDUCT.md -->\r\n<!--   * Reproduced the issue in the latest version of the software -->\r\n<!--   * Read the debugging docs: https://besu.hyperledger.org/en/stable/HowTo/Monitor/Logging/ -->\r\n<!--   * Duplicate Issue check:  https://github.com/search?q=+is%3Aissue+repo%3Ahyperledger/Besu -->\r\n<!-- Note:  Not all sections will apply to all issue types. -->\r\n\r\n### Description\r\nI'm currently creating a private besu network with 6 mining nodes (fast sync) and 3 bootnodes which are archives nodes. We are using AWS for this\r\nwith EKS and EC2 instances, each node has its own EC2 and EBS.\r\nOur network works fine until we try to do a disaster recovery test, destroying one of the EC2. When we do this the node that are running in that EC2 \r\nstays offline for some time (around 10 minutes) which is sufficient to be behind 50 blocks from the other nodes. After it comes online it just sits there\r\nand wait, without even trying to sync.\r\n\r\nLogs:\r\n```\r\n2022-08-25 19:31:38.291+00:00 | main | INFO  | WaitForPeersTask | Waiting for 1 total peers to connect. 0 peers currently connected.\r\n2022-08-25 19:31:40.454+00:00 | nioEventLoopGroup-3-3 | INFO  | FastWorldStateDownloader | World state already available for block 1 (0xc0eb914959d6abdb5170bcdcead16767af345aaca04cf08a99fbaf2488b7da18). State root 0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421\r\n2022-08-25 19:31:40.507+00:00 | nioEventLoopGroup-3-3 | INFO  | FastSyncTargetManager | No sync target, checking current peers for usefulness: 8\r\n2022-08-25 19:31:42.762+00:00 | main | INFO  | Runner | Ethereum main loop is up.\r\n```\r\n\r\nAfter a while this is one of the log messages:\r\n`2022-08-25 21:38:34.138+00:00 | nioEventLoopGroup-3-6 | TRACE | BlockPropagationManager | Do not import new block from network 19460 (0xcd5ddd3ef74314387f1d2c3f4edfb17ed27d3e91b43a3a6cdf63cc261ec8e1f1), current chain heights are: local 14876, best 19459`\r\n\r\nWhen we try to do another scenario deleting both the EC2 and the EBS, the node starts fast syncing and then full sync the last blocks which is odd because in this case it works as intended.\r\nThese are some of the logs messages for this last scenario:\r\n```\r\n2022-08-25 18:51:11.428+00:00 | main | INFO  | DefaultSynchronizer | Starting synchronizer.\r\n2022-08-25 18:51:11.430+00:00 | main | INFO  | FastSyncDownloader | Starting sync.\r\n2022-08-25 18:51:11.464+00:00 | main | INFO  | WaitForPeersTask | Waiting for 2 total peers to connect. 0 peers currently connected.\r\n2022-08-25 18:51:11.540+00:00 | main | INFO  | Runner | Ethereum main loop is up.\r\n2022-08-25 18:51:18.132+00:00 | EthScheduler-Timer-0 | INFO  | PivotSelectorFromPeers | Selecting block number 18491 as fast sync pivot block.\r\n2022-08-25 18:51:18.135+00:00 | EthScheduler-Timer-0 | INFO  | PivotBlockRetriever | Retrieve a pivot block that can be confirmed by at least 2 peers.\r\n2022-08-25 18:51:18.139+00:00 | EthScheduler-Timer-0 | INFO  | PivotBlockConfirmer | Confirm pivot block 18491 with at least 2 peers.\r\n2022-08-25 18:51:18.169+00:00 | EthScheduler-Timer-0 | INFO  | PivotBlockConfirmer | Received 1 confirmation(s) for pivot block header 18491: 0xadd5a49dcb37857b12ec62da12d15bd5d0cdafbc829d4cd2479b420caff66f70\r\n2022-08-25 18:51:18.181+00:00 | nioEventLoopGroup-3-5 | INFO  | PivotBlockConfirmer | Confirmed pivot block at 18491: 0xadd5a49dcb37857b12ec62da12d15bd5d0cdafbc829d4cd2479b420caff66f70\r\n2022-08-25 18:51:18.196+00:00 | nioEventLoopGroup-3-5 | INFO  | FastWorldStateDownloader | World state already available for block 18491 (0xadd5a49dcb37857b12ec62da12d15bd5d0cdafbc829d4cd2479b420caff66f70). State root 0x56e81f171bcc55a6ff8345e692c0f86e5b48e01b996cadc001622fb5e363b421\r\n2022-08-25 18:51:42.070+00:00 | EthScheduler-Services-5 (importBlock) | INFO  | FastImportBlocksStep | Completed importing chain segment 601 to 1600 (1000 blocks in 11940ms), Peers: 12\r\n....\r\n2022-08-25 18:53:55.372+00:00 | EthScheduler-Services-5 (importBlock) | INFO  | PipelineChainDownloader | PipelineChain download complete\r\n2022-08-25 18:53:55.385+00:00 | EthScheduler-Services-5 (importBlock) | INFO  | DefaultSynchronizer | Sync completed successfully with pivot block 18491\r\n2022-08-25 18:53:55.388+00:00 | EthScheduler-Services-5 (importBlock) | INFO  | FullSyncDownloader | Starting full sync.\r\n2022-08-25 18:53:55.556+00:00 | EthScheduler-Services-1 (importBlock) | INFO  | FullImportBlockStep | Import reached block 18492 (0xd6071d1338d7815c0b43dc6d5bcbd68ff7c82a1d8e121026bd0ad2e1003d4b24), - Mg/s, Peers: 12\r\n```\r\n\r\nAfter a couple more tests we found that if we try to do the same test just destroying the EC2 after we destroyed EC2 and EBS the node comes back online.\r\nThis issue seems to happen only in the first time that we destroy our EC2.\r\n\r\n### Acceptance Criteria\r\n* Have our validator node syncing with other nodes after the first time it gets destroyed in a DR scenario.\r\n\r\n### Steps to Reproduce (Bug)\r\n1. Start the network from the genesis file;\r\n2. Destroy one of the validator's EC2 and wait for EKS to provide another EC2 for this node;\r\n3. When it comes back online it doesn't sync with other nodes\r\n\r\n**Expected behavior:** [What you expect to happen]\r\n1. Start the network from the genesis file;\r\n2. Destroy one of the validator's EC2 and wait for EKS to provide another EC2 for this node;\r\n3. When it comes back online it should sync with other nodes\r\n\r\n**Frequency:** [What percentage of the time does it occur?]\r\nJust the first time that we destroy the EC2 (keeping it's EBS alive). If we destroy both EC2 and EBS it syncs but if we do this and after a while we destroy the EC2 again it syncs as it should.\r\n\r\n### Versions (Add all that apply)\r\n* Software version: besu/v22.7.1/linux-x86_64/openjdk-java-11\r\n* Cloud VM, type, size: AWS T3-large\r\n\r\n### Additional Information (Add any of the following or anything else that may be relevant)\r\nHere are the config options for our validator node\r\n\r\n```\r\n# Node Information\r\nsync-mode=\"FAST\"\r\nfast-sync-min-peers=2\r\n\r\n# Node Paths\r\ndata-path=\"/usr/local/bin/besudata\"\r\npid-path=\"/usr/local/bin/.pid\"\r\ngenesis-file=\"/usr/local/bin/config/genesisQBFT.json\"\r\n\r\n# P2P\r\nnat-method=\"KUBERNETES\"\r\np2p-enabled=true\r\ndiscovery-enabled=true\r\nhost-allowlist=[\"*\"]\r\n\r\n# JSON-RPC\r\nrpc-http-enabled=false\r\n\r\n# WebSocket\r\nrpc-ws-enabled=false\r\n\r\n# GraphQL\r\ngraphql-http-enabled=false\r\n\r\n# Transaction Pool\r\n# Default to All\r\n\r\n# Logging\r\n#logging=\"INFO\"\r\nlogging=\"ALL\"\r\ncolor-enabled=false\r\n\r\n# Mining\r\nminer-enabled=true\r\nmin-gas-price=0\r\n\r\n# Prometheus Metrics\r\nmetrics-enabled=false\r\n\r\n# Pruning\r\npruning-enabled=false\r\n\r\n# Permissioning\r\npermissions-nodes-config-file-enabled=false\r\n\r\n# Privacy\r\nprivacy-enabled=false\r\n\r\n# Experimental Features\r\nXp2p-tls-enabled=false\r\nXdns-enabled=true\r\n# Xdns-update-enabled=true\r\n\r\n# Reference:\r\n# https://github.com/hyperledger/besu/blob/main/besu/src/test/resources/everything_config.toml\r\n```",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/hyperledger/besu/issues/4319/reactions",
    "total_count": 1,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 1
  },
  "timeline_url": "https://api.github.com/repos/hyperledger/besu/issues/4319/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
[
  {
    "url": "https://api.github.com/repos/hyperledger/besu/issues/comments/1369651624",
    "html_url": "https://github.com/hyperledger/besu/issues/4319#issuecomment-1369651624",
    "issue_url": "https://api.github.com/repos/hyperledger/besu/issues/4319",
    "id": 1369651624,
    "node_id": "IC_kwDODE2jmc5Rozmo",
    "user": {
      "login": "ItayPodhajcer",
      "id": 19306955,
      "node_id": "MDQ6VXNlcjE5MzA2OTU1",
      "avatar_url": "https://avatars.githubusercontent.com/u/19306955?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ItayPodhajcer",
      "html_url": "https://github.com/ItayPodhajcer",
      "followers_url": "https://api.github.com/users/ItayPodhajcer/followers",
      "following_url": "https://api.github.com/users/ItayPodhajcer/following{/other_user}",
      "gists_url": "https://api.github.com/users/ItayPodhajcer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ItayPodhajcer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ItayPodhajcer/subscriptions",
      "organizations_url": "https://api.github.com/users/ItayPodhajcer/orgs",
      "repos_url": "https://api.github.com/users/ItayPodhajcer/repos",
      "events_url": "https://api.github.com/users/ItayPodhajcer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ItayPodhajcer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-01-03T11:17:27Z",
    "updated_at": "2023-01-03T11:18:11Z",
    "author_association": "NONE",
    "body": "Hi\r\n\r\nSeeing the same behavior without EKS, just EC2 instances with mounted EBS volumes for the data directory (we use an injected script to mount the volume and then start a container that uses that mounted volume).\r\n\r\nOn our case it's completely random, it might not happen at all, but occasionally, a node won't be able to sync after a restart.\r\n\r\n@LucasSalmen did you discover anything about this issue or you're still having it?",
    "reactions": {
      "url": "https://api.github.com/repos/hyperledger/besu/issues/comments/1369651624/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/hyperledger/besu/issues/comments/1374617819",
    "html_url": "https://github.com/hyperledger/besu/issues/4319#issuecomment-1374617819",
    "issue_url": "https://api.github.com/repos/hyperledger/besu/issues/4319",
    "id": 1374617819,
    "node_id": "IC_kwDODE2jmc5R7wDb",
    "user": {
      "login": "LucasSalmen",
      "id": 4901301,
      "node_id": "MDQ6VXNlcjQ5MDEzMDE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4901301?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/LucasSalmen",
      "html_url": "https://github.com/LucasSalmen",
      "followers_url": "https://api.github.com/users/LucasSalmen/followers",
      "following_url": "https://api.github.com/users/LucasSalmen/following{/other_user}",
      "gists_url": "https://api.github.com/users/LucasSalmen/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/LucasSalmen/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/LucasSalmen/subscriptions",
      "organizations_url": "https://api.github.com/users/LucasSalmen/orgs",
      "repos_url": "https://api.github.com/users/LucasSalmen/repos",
      "events_url": "https://api.github.com/users/LucasSalmen/events{/privacy}",
      "received_events_url": "https://api.github.com/users/LucasSalmen/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-01-07T21:25:26Z",
    "updated_at": "2023-01-07T21:25:26Z",
    "author_association": "NONE",
    "body": "Hey @ItayPodhajcer \r\n\r\nWe are still facing this problem, although we didn't make any advances in this regard for the past few months. Me and my team will check this issue again during this month.\r\nFor your case I have three questions. \r\n\r\n1. Are you using a private network?\r\n2. Did you try checking if your node got back in the sync after 50 blocks? In our case the sync didn't happen only if it tried to sync in the fast mode.\r\n3. In our case it happened only after the first termination of the node. If we destroy the EBS and the EC2 of the EKS and try to destroy again the node it syncs as it should. Did you tried to destroy the EBS and sync it from the beginning of the chain to check this? ",
    "reactions": {
      "url": "https://api.github.com/repos/hyperledger/besu/issues/comments/1374617819/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/hyperledger/besu/issues/comments/1374774080",
    "html_url": "https://github.com/hyperledger/besu/issues/4319#issuecomment-1374774080",
    "issue_url": "https://api.github.com/repos/hyperledger/besu/issues/4319",
    "id": 1374774080,
    "node_id": "IC_kwDODE2jmc5R8WNA",
    "user": {
      "login": "ItayPodhajcer",
      "id": 19306955,
      "node_id": "MDQ6VXNlcjE5MzA2OTU1",
      "avatar_url": "https://avatars.githubusercontent.com/u/19306955?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ItayPodhajcer",
      "html_url": "https://github.com/ItayPodhajcer",
      "followers_url": "https://api.github.com/users/ItayPodhajcer/followers",
      "following_url": "https://api.github.com/users/ItayPodhajcer/following{/other_user}",
      "gists_url": "https://api.github.com/users/ItayPodhajcer/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ItayPodhajcer/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ItayPodhajcer/subscriptions",
      "organizations_url": "https://api.github.com/users/ItayPodhajcer/orgs",
      "repos_url": "https://api.github.com/users/ItayPodhajcer/repos",
      "events_url": "https://api.github.com/users/ItayPodhajcer/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ItayPodhajcer/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-01-08T09:24:46Z",
    "updated_at": "2023-01-08T09:24:46Z",
    "author_association": "NONE",
    "body": "@LucasSalmen \r\n1. We are running an IBFT2.0 network\r\n2. We are using node on-chain permissionig. when I turn it off, the node immediately manages to sync. If I turn it back on right after seeing it manages to sync (the node catches up with the network), then it will fail to sync again. Only if I let it run for a while without on-chain permissioning (not just until it finishes syncing the blocks it missed) and only then turn it back on, it'll behave properly.\r\n3. That's the thing, under no circumstances I want to recreate the EBS volume, as it means full re-sync, which I want to avoid as much as possible.",
    "reactions": {
      "url": "https://api.github.com/repos/hyperledger/besu/issues/comments/1374774080/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
