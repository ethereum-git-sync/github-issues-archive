{
  "url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/8787",
  "repository_url": "https://api.github.com/repos/prysmaticlabs/prysm",
  "labels_url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/8787/labels{/name}",
  "comments_url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/8787/comments",
  "events_url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/8787/events",
  "html_url": "https://github.com/prysmaticlabs/prysm/issues/8787",
  "id": 861292285,
  "node_id": "MDU6SXNzdWU4NjEyOTIyODU=",
  "number": 8787,
  "title": "Allow Beacon DB Pruning",
  "user": {
    "login": "nisdas",
    "id": 33201827,
    "node_id": "MDQ6VXNlcjMzMjAxODI3",
    "avatar_url": "https://avatars.githubusercontent.com/u/33201827?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/nisdas",
    "html_url": "https://github.com/nisdas",
    "followers_url": "https://api.github.com/users/nisdas/followers",
    "following_url": "https://api.github.com/users/nisdas/following{/other_user}",
    "gists_url": "https://api.github.com/users/nisdas/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/nisdas/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/nisdas/subscriptions",
    "organizations_url": "https://api.github.com/users/nisdas/orgs",
    "repos_url": "https://api.github.com/users/nisdas/repos",
    "events_url": "https://api.github.com/users/nisdas/events{/privacy}",
    "received_events_url": "https://api.github.com/users/nisdas/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 934596141,
      "node_id": "MDU6TGFiZWw5MzQ1OTYxNDE=",
      "url": "https://api.github.com/repos/prysmaticlabs/prysm/labels/Discussion",
      "name": "Discussion",
      "color": "f9d0c4",
      "default": false,
      "description": "Simply a thread for talking about stuff"
    },
    {
      "id": 1241586918,
      "node_id": "MDU6TGFiZWwxMjQxNTg2OTE4",
      "url": "https://api.github.com/repos/prysmaticlabs/prysm/labels/Tracking",
      "name": "Tracking",
      "color": "d0ff7f",
      "default": false,
      "description": "Gotta Catch 'Em All"
    }
  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2021-04-19T13:08:44Z",
  "updated_at": "2022-02-01T23:13:21Z",
  "closed_at": null,
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "body": "# ðŸš€ Feature Request\r\n\r\n### Description\r\n\r\nWith the chain reaching 1,000,000 slots soon, we would need to start looking into ways to reduce the overall db size of the beacon node. While we do not save often(Once every 2048 slots), with 1 million slots, the number of states now compromises a significant size of the total database. For normal beacon operations only the current finalized state is required, any historical state beyond that can be pruned away with no effect on current beacon operations.\r\n\r\n### Describe the solution you'd like\r\n\r\nThere are multiple ways to approach this: \r\n\r\n- Have a Background Cleanup Routine.\r\n\r\nThis allows the beacon node to only keep up to N states saved in the database beyond the current finalized checkpoint. ( excluding genesis state). During each migration to the cold state we can also prune away historical states that are uneeded. This can effectively keep database size at a constant size( ignoring new blocks), instead of the linear growth in size currently seen. The downside of this is that there would need to be an initial state 'cleanup' before we can make it a background routine. As the initial state deletion would be very big(~ 10 GB compressed), this might end up taking some time and memory. \r\n\r\n- Make DB Pruning a Subcommand.\r\n\r\nThis makes DB pruning opt-in rather than the default, ensuring that users arent impacted during normal operations. However the main advantage is also its downside as any user will have to deal with some downtime while pruning the db. \r\n\r\nOne important thing to note of is that, once the unneeded states are deleted, the freed up disk space will be put into a freelist.\r\nDue to how bolt is structured, any value deleted from the bucket is placed in its freelist. However there is no way to reclaim this from disk and it each subsequent write after will involve syncing the freelist also. This leads to a noticeable negative impact on DB writes. We could potentially get around this by not syncing the freelist on each write, however this can lead to very long recovery times on a node restart( if freelist sync is re-enabled).\r\n\r\n### Describe alternatives you've considered\r\n\r\nInstead of storing large states, we instead store the field differences between the current state, and a previously stored root state. This would significantly reduce the size for each new state saved at the cost of increasing implementation complexity significantly. ",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/8787/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/8787/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
[
  {
    "url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/comments/822483884",
    "html_url": "https://github.com/prysmaticlabs/prysm/issues/8787#issuecomment-822483884",
    "issue_url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/8787",
    "id": 822483884,
    "node_id": "MDEyOklzc3VlQ29tbWVudDgyMjQ4Mzg4NA==",
    "user": {
      "login": "mrabino1",
      "id": 4902221,
      "node_id": "MDQ6VXNlcjQ5MDIyMjE=",
      "avatar_url": "https://avatars.githubusercontent.com/u/4902221?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mrabino1",
      "html_url": "https://github.com/mrabino1",
      "followers_url": "https://api.github.com/users/mrabino1/followers",
      "following_url": "https://api.github.com/users/mrabino1/following{/other_user}",
      "gists_url": "https://api.github.com/users/mrabino1/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mrabino1/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mrabino1/subscriptions",
      "organizations_url": "https://api.github.com/users/mrabino1/orgs",
      "repos_url": "https://api.github.com/users/mrabino1/repos",
      "events_url": "https://api.github.com/users/mrabino1/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mrabino1/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-04-19T13:52:32Z",
    "updated_at": "2021-04-19T13:52:32Z",
    "author_association": "CONTRIBUTOR",
    "body": "From my lens, the default should be that pruning happens automatically every X slots (maybe every 6 hours or 24 hours) unless explicitly instructed not to via CLI (e.g. --no_db_pruning ). While not expected, one can also imagine the other subsequent scenarios, 1.) the user in the future removes that flag which kicks off the pruning... OR 2.) the user after pruning, decides to add that flag.. \r\n\r\nEither way, I agree that the sooner we start this this routine clean-up the easier it will be in the future. I would recommend a similar UX as geth's most recent clean-up implementation that started and stopped in between blocks to not disrupt uptime. The overall process took longer but with no outage. ",
    "reactions": {
      "url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/comments/822483884/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
