{
  "url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/13028",
  "repository_url": "https://api.github.com/repos/prysmaticlabs/prysm",
  "labels_url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/13028/labels{/name}",
  "comments_url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/13028/comments",
  "events_url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/13028/events",
  "html_url": "https://github.com/prysmaticlabs/prysm/issues/13028",
  "id": 1935943835,
  "node_id": "I_kwDOBvuov85zZCib",
  "number": 13028,
  "title": "Decouple backfill block persistence and indexing",
  "user": {
    "login": "kasey",
    "id": 489222,
    "node_id": "MDQ6VXNlcjQ4OTIyMg==",
    "avatar_url": "https://avatars.githubusercontent.com/u/489222?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/kasey",
    "html_url": "https://github.com/kasey",
    "followers_url": "https://api.github.com/users/kasey/followers",
    "following_url": "https://api.github.com/users/kasey/following{/other_user}",
    "gists_url": "https://api.github.com/users/kasey/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/kasey/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/kasey/subscriptions",
    "organizations_url": "https://api.github.com/users/kasey/orgs",
    "repos_url": "https://api.github.com/users/kasey/repos",
    "events_url": "https://api.github.com/users/kasey/events{/privacy}",
    "received_events_url": "https://api.github.com/users/kasey/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 2061040048,
      "node_id": "MDU6TGFiZWwyMDYxMDQwMDQ4",
      "url": "https://api.github.com/repos/prysmaticlabs/prysm/labels/Sync",
      "name": "Sync",
      "color": "5967ba",
      "default": false,
      "description": "Sync (regular, initial, checkpoint) related issues"
    },
    {
      "id": 5462402659,
      "node_id": "LA_kwDOBvuov88AAAABRZWmYw",
      "url": "https://api.github.com/repos/prysmaticlabs/prysm/labels/Deneb",
      "name": "Deneb",
      "color": "040874",
      "default": false,
      "description": "PRs or issues for the Deneb upgrade"
    },
    {
      "id": 6067756451,
      "node_id": "LA_kwDOBvuov88AAAABaaqdow",
      "url": "https://api.github.com/repos/prysmaticlabs/prysm/labels/backfill",
      "name": "backfill",
      "color": "62E5D3",
      "default": false,
      "description": ""
    }
  ],
  "state": "open",
  "locked": false,
  "assignee": {
    "login": "kasey",
    "id": 489222,
    "node_id": "MDQ6VXNlcjQ4OTIyMg==",
    "avatar_url": "https://avatars.githubusercontent.com/u/489222?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/kasey",
    "html_url": "https://github.com/kasey",
    "followers_url": "https://api.github.com/users/kasey/followers",
    "following_url": "https://api.github.com/users/kasey/following{/other_user}",
    "gists_url": "https://api.github.com/users/kasey/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/kasey/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/kasey/subscriptions",
    "organizations_url": "https://api.github.com/users/kasey/orgs",
    "repos_url": "https://api.github.com/users/kasey/repos",
    "events_url": "https://api.github.com/users/kasey/events{/privacy}",
    "received_events_url": "https://api.github.com/users/kasey/received_events",
    "type": "User",
    "site_admin": false
  },
  "assignees": [
    {
      "login": "kasey",
      "id": 489222,
      "node_id": "MDQ6VXNlcjQ4OTIyMg==",
      "avatar_url": "https://avatars.githubusercontent.com/u/489222?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/kasey",
      "html_url": "https://github.com/kasey",
      "followers_url": "https://api.github.com/users/kasey/followers",
      "following_url": "https://api.github.com/users/kasey/following{/other_user}",
      "gists_url": "https://api.github.com/users/kasey/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/kasey/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/kasey/subscriptions",
      "organizations_url": "https://api.github.com/users/kasey/orgs",
      "repos_url": "https://api.github.com/users/kasey/repos",
      "events_url": "https://api.github.com/users/kasey/events{/privacy}",
      "received_events_url": "https://api.github.com/users/kasey/received_events",
      "type": "User",
      "site_admin": false
    }
  ],
  "milestone": null,
  "comments": 0,
  "created_at": "2023-10-10T18:16:52Z",
  "updated_at": "2023-10-10T18:19:34Z",
  "closed_at": null,
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "body": "# ðŸš€ Feature Request\r\n\r\n### Description\r\n\r\nWe could backfill blocks faster if we decouple downloading and lineage checking / index building. In order to understand the current performance limitation, consider:\r\n- We want to backfill blocks that are ancestors of the known finalized chain.\r\n- We download multiple batches of blocks in parallel.\r\n- Only one of these batches is connected to the finalized chain - MRFB \"most recently finalized batch\".\r\n- Batches older than the MRFB are in limbo, because we can't connect them until we have downloaded and verified the MRFB. They take up memory while we wait for that to happen. So we limit the number of batches in progress to limit the memory overhead of the backfill process.\r\n- Allowing these batches to be written to the db before we know they are connected would allow us to get them out of memory and keep downloading older batches. Doing this requires some changes to how the backfill service works - namely decoupling index construction and block downloading.\r\n\r\n### Describe the solution you'd like\r\n\r\nIf we separate the batch data structure from the blocks themselves, we can keep batches around longer and write blocks to the db sooner. This should be fairly safe since we have a limited horizon of blocks to backfill, and we do proposer signature verification before writing to the db, so we can be pretty confident the blocks are worth writing. This does change some of the assumptions in how the batcher works, but it should be doable with changes to only a few of the backfill service components. The batcher could keep the same assumptions for importable blocks, but expose an additional method to get blocks that are downloaded. We would then only consider a block \"imported\" if we have connected it to the canonical chain and updated the finalized index and BackfillStatus. If we are unable to do this for any reason, the existing state machine flow of marking the batch as in a retryable error state should suffice to download it again. The main change is redefining how we move between downloaded and importable states.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/13028/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/prysmaticlabs/prysm/issues/13028/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
[

]
