{
  "url": "https://api.github.com/repos/ConsenSys/teku/issues/3326",
  "repository_url": "https://api.github.com/repos/ConsenSys/teku",
  "labels_url": "https://api.github.com/repos/ConsenSys/teku/issues/3326/labels{/name}",
  "comments_url": "https://api.github.com/repos/ConsenSys/teku/issues/3326/comments",
  "events_url": "https://api.github.com/repos/ConsenSys/teku/issues/3326/events",
  "html_url": "https://github.com/ConsenSys/teku/issues/3326",
  "id": 751969543,
  "node_id": "MDU6SXNzdWU3NTE5Njk1NDM=",
  "number": 3326,
  "title": "Optimization: Epoch Transition with precomputed validator status array",
  "user": {
    "login": "protolambda",
    "id": 19571989,
    "node_id": "MDQ6VXNlcjE5NTcxOTg5",
    "avatar_url": "https://avatars.githubusercontent.com/u/19571989?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/protolambda",
    "html_url": "https://github.com/protolambda",
    "followers_url": "https://api.github.com/users/protolambda/followers",
    "following_url": "https://api.github.com/users/protolambda/following{/other_user}",
    "gists_url": "https://api.github.com/users/protolambda/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/protolambda/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/protolambda/subscriptions",
    "organizations_url": "https://api.github.com/users/protolambda/orgs",
    "repos_url": "https://api.github.com/users/protolambda/repos",
    "events_url": "https://api.github.com/users/protolambda/events{/privacy}",
    "received_events_url": "https://api.github.com/users/protolambda/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1271198478,
      "node_id": "MDU6TGFiZWwxMjcxMTk4NDc4",
      "url": "https://api.github.com/repos/ConsenSys/teku/labels/performance%20%F0%9F%9A%80",
      "name": "performance ðŸš€",
      "color": "ffcce3",
      "default": false,
      "description": "Improves performance without changing functionality"
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": {
    "login": "ajsutton",
    "id": 72675,
    "node_id": "MDQ6VXNlcjcyNjc1",
    "avatar_url": "https://avatars.githubusercontent.com/u/72675?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ajsutton",
    "html_url": "https://github.com/ajsutton",
    "followers_url": "https://api.github.com/users/ajsutton/followers",
    "following_url": "https://api.github.com/users/ajsutton/following{/other_user}",
    "gists_url": "https://api.github.com/users/ajsutton/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ajsutton/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ajsutton/subscriptions",
    "organizations_url": "https://api.github.com/users/ajsutton/orgs",
    "repos_url": "https://api.github.com/users/ajsutton/repos",
    "events_url": "https://api.github.com/users/ajsutton/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ajsutton/received_events",
    "type": "User",
    "site_admin": false
  },
  "assignees": [
    {
      "login": "ajsutton",
      "id": 72675,
      "node_id": "MDQ6VXNlcjcyNjc1",
      "avatar_url": "https://avatars.githubusercontent.com/u/72675?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ajsutton",
      "html_url": "https://github.com/ajsutton",
      "followers_url": "https://api.github.com/users/ajsutton/followers",
      "following_url": "https://api.github.com/users/ajsutton/following{/other_user}",
      "gists_url": "https://api.github.com/users/ajsutton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ajsutton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ajsutton/subscriptions",
      "organizations_url": "https://api.github.com/users/ajsutton/orgs",
      "repos_url": "https://api.github.com/users/ajsutton/repos",
      "events_url": "https://api.github.com/users/ajsutton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ajsutton/received_events",
      "type": "User",
      "site_admin": false
    }
  ],
  "milestone": null,
  "comments": 4,
  "created_at": "2020-11-27T04:18:42Z",
  "updated_at": "2020-12-07T22:08:51Z",
  "closed_at": "2020-12-07T22:08:51Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "body": "With Pyrmont, optimizations are critical for good validator performance. Running a sample of 20 validating Teku nodes, 250 validators each, we have observed:\r\n- Teku blocks getting orphaned just after epoch transitions\r\n- Gossip output dipping during epoch transitions. Causing significant asymmetrical network traffic: other clients are missing more than they are sending. Teku is still receiving data, but regularly failing to process it on time. And failing to publish data on time.\r\n\r\n![image](https://user-images.githubusercontent.com/19571989/100410325-a7855100-306e-11eb-96ac-ce1dfa035253.png)\r\n\r\n\r\nWith some profiling, you can find Teku struggle (relative to other work) on the epoch transition during sync:\r\n\r\nThe forkchoice and the sync running a costly epoch transition:\r\n![deltas2](https://user-images.githubusercontent.com/19571989/100408396-2b3d3e80-306b-11eb-9de3-13a7a9611858.png)\r\n\r\nAn example epoch transition:\r\n![deltas](https://user-images.githubusercontent.com/19571989/100408421-3d1ee180-306b-11eb-9d98-a6aa03784925.png)\r\n\r\n*(Above profiles were on a slow and memory-limited machine, don't mind the slow processing, it's about relative performance to other parts of Teku)*\r\n\r\nNote that the majority of the epoch transition is:\r\n- process rewards and penalties (almost 2/3 of epoch transition)\r\n- process justification and finalization (almost 1/3 of epoch transition)\r\n\r\nFrom there, the same thing happens two or three calls deeper: the pending attestations are iterated, matched against some committee data, and returning some resulting data such as \"validator 1, 2, 3 participated with inclusion distance x, y, z and correct performance on target/head, while being unslashed, etc. etc.\".\r\n\r\nAnd it does so for 100.000+ validators. And overhead may be more than twice that, due to attestation bitlists: attestations are not perfectly aggregated, there are many more pending attestation bits in the state than validators.\r\n\r\nHere is an example of converting some list of attestations to unslashed indices: https://github.com/ConsenSys/teku/blob/d7cdf221cba78718888462fe9b58853215f03796/ethereum/core/src/main/java/tech/pegasys/teku/core/epoch/EpochProcessorUtil.java#L92\r\nIt iterates every attestation bit of every attestation, every call of the function. And while doing so, it converts the bitlist (a byte array) to a boolean list with `getAggregation_bits` before then converting it to a list of validator indices. I'm not completely sure about allocations, but just the repeated unnecessary conversion and huge amount of data is already a great optimization target.\r\n\r\nThis is exactly what other eth2 clients did, and I strongly recommend implementing the same optimization. It works roughly like:\r\n1. Iterate the pending attestations once during the epoch transition\r\n2. Be as efficient as possible with iterating the attestation bits, and looking up the corresponding indices\r\n3. Keep track of a nice summary of relevant per-validator performance (known as the \"validator status array\" with other implementers):\r\n    - inclusion distance per validator\r\n    - voting mode per validator (flags for attesting at all, attesting to the head, to the target)\r\n    - being slashed or not (repeated state lookups slower, might as well cache being slashed or not here, local with the other validator data)\r\n4. Sum attesting stake totals efficiently from above summary data, avoiding later lookups with the state\r\n5. Pass the stake totals to the `process_justification_and_finalization` function\r\n    - the stake totals are just numbers, much better than going through the whole work of 100.000 validators. Then compare some numbers, and justify/finalize or not.\r\n6. Pass the status array and stake totals to the `process_rewards_and_penalties` function \r\n   - now all data for rewards/penalties can instantly be looked up from the status array, avoiding slow state access, complicated cache lookups, or painful repeated attestation bits iteration.\r\n\r\nEdit: I also recommend pooling the \"Validator statuses\" array. Then you can avoid GC of it as much as possible, and not re-allocate 100.000 objects each transition.\r\n\r\nThis validator status optimization was introduced as early as April 2019 in the Eth2 workshop in Sydney, original by Lighthouse, and then developed as the spec evolved.\r\n\r\nYou can see lighthouse run the optimization here: https://github.com/sigp/lighthouse/blob/c6baa0eed131c5e8ecc5860778ffc7d4a4c18d2d/consensus/state_processing/src/per_epoch_processing.rs#L41\r\n\r\nAnd then other implementations do their version of it here:\r\n- optimized pyspec (readable but optimized, not spec v1.0.0 yet however): https://github.com/protolambda/eth2fastspec/blob/3af03bd89112b58db262da07f12fb3c6f988f6af/eth2fastspec.py#L612\r\n- ZRNT: https://github.com/protolambda/zrnt/blob/6445ee81cda9a36bf4b3139bd74c2ce3f1ea05db/eth2/beacon/epoch.go#L46\r\n- Prysm: https://github.com/prysmaticlabs/prysm/blob/b243665d3ef6ce588c77e16bb694c4ee6c7eb3db/beacon-chain/core/state/transition.go#L590\r\n\r\nThis should help reduce the epoch processing to something more manageable, and is hopefully enough to make Teku validators perform on-par with the best, even under high load like with Pyrmont.\r\n\r\nAnd then not calling the slowest function repeatedly would also help, https://github.com/ConsenSys/teku/pull/3265 is improving that :clap: ",
  "closed_by": {
    "login": "ajsutton",
    "id": 72675,
    "node_id": "MDQ6VXNlcjcyNjc1",
    "avatar_url": "https://avatars.githubusercontent.com/u/72675?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/ajsutton",
    "html_url": "https://github.com/ajsutton",
    "followers_url": "https://api.github.com/users/ajsutton/followers",
    "following_url": "https://api.github.com/users/ajsutton/following{/other_user}",
    "gists_url": "https://api.github.com/users/ajsutton/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/ajsutton/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/ajsutton/subscriptions",
    "organizations_url": "https://api.github.com/users/ajsutton/orgs",
    "repos_url": "https://api.github.com/users/ajsutton/repos",
    "events_url": "https://api.github.com/users/ajsutton/events{/privacy}",
    "received_events_url": "https://api.github.com/users/ajsutton/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/ConsenSys/teku/issues/3326/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ConsenSys/teku/issues/3326/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/ConsenSys/teku/issues/comments/738452359",
    "html_url": "https://github.com/ConsenSys/teku/issues/3326#issuecomment-738452359",
    "issue_url": "https://api.github.com/repos/ConsenSys/teku/issues/3326",
    "id": 738452359,
    "node_id": "MDEyOklzc3VlQ29tbWVudDczODQ1MjM1OQ==",
    "user": {
      "login": "ajsutton",
      "id": 72675,
      "node_id": "MDQ6VXNlcjcyNjc1",
      "avatar_url": "https://avatars.githubusercontent.com/u/72675?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ajsutton",
      "html_url": "https://github.com/ajsutton",
      "followers_url": "https://api.github.com/users/ajsutton/followers",
      "following_url": "https://api.github.com/users/ajsutton/following{/other_user}",
      "gists_url": "https://api.github.com/users/ajsutton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ajsutton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ajsutton/subscriptions",
      "organizations_url": "https://api.github.com/users/ajsutton/orgs",
      "repos_url": "https://api.github.com/users/ajsutton/repos",
      "events_url": "https://api.github.com/users/ajsutton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ajsutton/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-12-03T23:35:55Z",
    "updated_at": "2020-12-03T23:35:55Z",
    "author_association": "CONTRIBUTOR",
    "body": ">Edit: I also recommend pooling the \"Validator statuses\" array. Then you can avoid GC of it as much as possible, and not re-allocate 100.000 objects each transition.\r\n\r\nCounter-intuitively this is generally very bad for performance in Java because it pushes all the objects into the old gen where GC is more expensive.  100k objects is a lot though so we'll have to profile and see what shows up.",
    "reactions": {
      "url": "https://api.github.com/repos/ConsenSys/teku/issues/comments/738452359/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ConsenSys/teku/issues/comments/739527625",
    "html_url": "https://github.com/ConsenSys/teku/issues/3326#issuecomment-739527625",
    "issue_url": "https://api.github.com/repos/ConsenSys/teku/issues/3326",
    "id": 739527625,
    "node_id": "MDEyOklzc3VlQ29tbWVudDczOTUyNzYyNQ==",
    "user": {
      "login": "protolambda",
      "id": 19571989,
      "node_id": "MDQ6VXNlcjE5NTcxOTg5",
      "avatar_url": "https://avatars.githubusercontent.com/u/19571989?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/protolambda",
      "html_url": "https://github.com/protolambda",
      "followers_url": "https://api.github.com/users/protolambda/followers",
      "following_url": "https://api.github.com/users/protolambda/following{/other_user}",
      "gists_url": "https://api.github.com/users/protolambda/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/protolambda/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/protolambda/subscriptions",
      "organizations_url": "https://api.github.com/users/protolambda/orgs",
      "repos_url": "https://api.github.com/users/protolambda/repos",
      "events_url": "https://api.github.com/users/protolambda/events{/privacy}",
      "received_events_url": "https://api.github.com/users/protolambda/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-12-06T16:35:34Z",
    "updated_at": "2020-12-06T16:36:20Z",
    "author_association": "CONTRIBUTOR",
    "body": "@ajsutton I'm not suggesting to pool them as individual objects. But to pool the thing as a whole (an array of objects). If the GC is able to efficiently ignore it as a whole, and Teku is able to consistently re-use it every 6.4 minutes, that sounds like a win to me. I'm not a JVM expert though, profiling and just seeing what works best sounds like a better idea.",
    "reactions": {
      "url": "https://api.github.com/repos/ConsenSys/teku/issues/comments/739527625/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ConsenSys/teku/issues/comments/739592023",
    "html_url": "https://github.com/ConsenSys/teku/issues/3326#issuecomment-739592023",
    "issue_url": "https://api.github.com/repos/ConsenSys/teku/issues/3326",
    "id": 739592023,
    "node_id": "MDEyOklzc3VlQ29tbWVudDczOTU5MjAyMw==",
    "user": {
      "login": "ajsutton",
      "id": 72675,
      "node_id": "MDQ6VXNlcjcyNjc1",
      "avatar_url": "https://avatars.githubusercontent.com/u/72675?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ajsutton",
      "html_url": "https://github.com/ajsutton",
      "followers_url": "https://api.github.com/users/ajsutton/followers",
      "following_url": "https://api.github.com/users/ajsutton/following{/other_user}",
      "gists_url": "https://api.github.com/users/ajsutton/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ajsutton/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ajsutton/subscriptions",
      "organizations_url": "https://api.github.com/users/ajsutton/orgs",
      "repos_url": "https://api.github.com/users/ajsutton/repos",
      "events_url": "https://api.github.com/users/ajsutton/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ajsutton/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-12-07T00:18:08Z",
    "updated_at": "2020-12-07T00:18:08Z",
    "author_association": "CONTRIBUTOR",
    "body": "> @ajsutton I'm not suggesting to pool them as individual objects. But to pool the thing as a whole (an array of objects). If the GC is able to efficiently ignore it as a whole, and Teku is able to consistently re-use it every 6.4 minutes, that sounds like a win to me. I'm not a JVM expert though, profiling and just seeing what works best sounds like a better idea.\r\n\r\nEach entry in an array would still be its own object which the GC would have to track (not sure how smart the GC is at discarding whole subtrees when doing reference analysis these days).\r\n\r\nBut it is a unique little corner case where it may wind up being useful. Mostly commented because I wasn't adding it in the initial PR and didn't want to just completely ignore the comment.  \r\n\r\nInitial profiling suggests the creation of the validator status is about 5% of the time and dominated by state access so unlikely to need to do caching at this point, but will have to monitor GC logs more carefully in real world scenarios.  Seeing about a 2-2.5x speed up on the old code - just pushed a few extra optimisations based on that profiling.\r\n\r\nNext big target is to improve the performance of `PendingAttestation.getAggregation_bits`. If we get a `Bitlist` implementation that works more directly on the underlying SSZ data I suspect we can save almost 10%.",
    "reactions": {
      "url": "https://api.github.com/repos/ConsenSys/teku/issues/comments/739592023/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ConsenSys/teku/issues/comments/739594431",
    "html_url": "https://github.com/ConsenSys/teku/issues/3326#issuecomment-739594431",
    "issue_url": "https://api.github.com/repos/ConsenSys/teku/issues/3326",
    "id": 739594431,
    "node_id": "MDEyOklzc3VlQ29tbWVudDczOTU5NDQzMQ==",
    "user": {
      "login": "protolambda",
      "id": 19571989,
      "node_id": "MDQ6VXNlcjE5NTcxOTg5",
      "avatar_url": "https://avatars.githubusercontent.com/u/19571989?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/protolambda",
      "html_url": "https://github.com/protolambda",
      "followers_url": "https://api.github.com/users/protolambda/followers",
      "following_url": "https://api.github.com/users/protolambda/following{/other_user}",
      "gists_url": "https://api.github.com/users/protolambda/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/protolambda/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/protolambda/subscriptions",
      "organizations_url": "https://api.github.com/users/protolambda/orgs",
      "repos_url": "https://api.github.com/users/protolambda/repos",
      "events_url": "https://api.github.com/users/protolambda/events{/privacy}",
      "received_events_url": "https://api.github.com/users/protolambda/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2020-12-07T00:26:33Z",
    "updated_at": "2020-12-07T00:26:33Z",
    "author_association": "CONTRIBUTOR",
    "body": "Yep, sounds good. Bit access is known to be really important in this part. Since you access `validator_count * redundanty_attestations_factor`, one function call (and maybe deeper) per bit, each masking bytes and extracting booleans. Especially with boxed uints or byte types, it can get quite slow. In javascript and python we mostly solved it with specialized iterators, that do not call the get-bit method for each byte, but rather iterate over each byte slice, then each byte, then each bit, while streaming the results (via some efficient type of callback). And depending on the language, this can look very different. In JS it's faster to convert to strings than to try do native array access, to name something unexpected.\r\nEven optimizing it a tiny bit amounts to a big overall reduction if it counts `2 * 100.000+` times.\r\n\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ConsenSys/teku/issues/comments/739594431/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
