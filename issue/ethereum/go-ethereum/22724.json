{
  "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/22724",
  "repository_url": "https://api.github.com/repos/ethereum/go-ethereum",
  "labels_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/22724/labels{/name}",
  "comments_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/22724/comments",
  "events_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/22724/events",
  "html_url": "https://github.com/ethereum/go-ethereum/issues/22724",
  "id": 865902449,
  "node_id": "MDU6SXNzdWU4NjU5MDI0NDk=",
  "number": 22724,
  "title": "Info on State Prefetching",
  "user": {
    "login": "jon-chuang",
    "id": 9093549,
    "node_id": "MDQ6VXNlcjkwOTM1NDk=",
    "avatar_url": "https://avatars.githubusercontent.com/u/9093549?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/jon-chuang",
    "html_url": "https://github.com/jon-chuang",
    "followers_url": "https://api.github.com/users/jon-chuang/followers",
    "following_url": "https://api.github.com/users/jon-chuang/following{/other_user}",
    "gists_url": "https://api.github.com/users/jon-chuang/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/jon-chuang/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/jon-chuang/subscriptions",
    "organizations_url": "https://api.github.com/users/jon-chuang/orgs",
    "repos_url": "https://api.github.com/users/jon-chuang/repos",
    "events_url": "https://api.github.com/users/jon-chuang/events{/privacy}",
    "received_events_url": "https://api.github.com/users/jon-chuang/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 268304226,
      "node_id": "MDU6TGFiZWwyNjgzMDQyMjY=",
      "url": "https://api.github.com/repos/ethereum/go-ethereum/labels/type:docs",
      "name": "type:docs",
      "color": "fef2c0",
      "default": false,
      "description": null
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 4,
  "created_at": "2021-04-23T08:55:41Z",
  "updated_at": "2021-11-04T10:47:08Z",
  "closed_at": "2021-11-03T18:34:16Z",
  "author_association": "NONE",
  "active_lock_reason": null,
  "body": "Dear Geth Team,\r\n\r\nI am currently looking into some optimisations to Geth related to parallelism, state fetching and snapshots as part of my work on the downstream `celo-blockchain`. \r\n\r\nAlthough it is not a priority, I think there is a chance that some work done could end up being merged upstream. Even if not, I think it is still a good idea to start a conversation.\r\n\r\nI have a number of questions:\r\n1. Is it correct to say as of now no actual optimisations exist based on the Berlin activated `AccessList` in terms of `Trie` (i.e. DB warming) or even snapshot object prefetching? What are the team’s plans for such things going forward? More generally, is there some sort of roadmap capturing planned features or are these only captured ephemerally in discussions/issues? \r\n2. Somewhat relatedly, is it correct to say that the `core/state_prefetcher.go` code is outdated in the sense that one would not like to call `TransitionDB` in advance to warm the state, as it is costly, what’s more, in parallel? What is the (future) purpose of this code since it’s currently not invoked anywhere as far as I can tell? Is the future for this code to morph into DB prefetching based on AccessList? If so, what would be a good entry point to spawning the prefetching? \r\n3. Why is it that the `TriePrefetcher` that lives in the `StateDB` uses one go worker per state root to walk the Trie? This seems inefficient to me, and in my mind, one should spawn as many goroutines as there are `trie.TryGet`s to be walked. In my mind, one ought to maintain a hashmap of `Tries` and pop tasks off a global task list and spawn as many goroutines as there are tasks. The global prefetcher loop will then respond to stop commands.. This way, one can leverage concurrency for `Trie` prefetching even within a single contract’s state Trie. Since `disk fetch >> goroutine context switch`, I think this is a reasonable change. Since this is a relatively isolated change, I guess I could submit a PR here to familiarise with the contribution process on geth. I guess I’ll make an issue first. One question is whether it is preferable to maintain copies of Tries per thread (since this is rather lightweight - just a pointer to a global? `Database` and the root node). Further, if the intention is to warm the underlying DB, there is not much reason (apart, perhaps, for convenience) to continue to maintain the `Trie`s in memory, is there? In essence, one can request for the `Trie`s anew from the `Database` from a separate location after deleting the corresponding prefetcher `Trie` object in memory, as long as one is maintaining a single global `Database` object.\r\n\r\nCheers,\r\nJon\r\n",
  "closed_by": {
    "login": "holiman",
    "id": 142290,
    "node_id": "MDQ6VXNlcjE0MjI5MA==",
    "avatar_url": "https://avatars.githubusercontent.com/u/142290?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/holiman",
    "html_url": "https://github.com/holiman",
    "followers_url": "https://api.github.com/users/holiman/followers",
    "following_url": "https://api.github.com/users/holiman/following{/other_user}",
    "gists_url": "https://api.github.com/users/holiman/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/holiman/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/holiman/subscriptions",
    "organizations_url": "https://api.github.com/users/holiman/orgs",
    "repos_url": "https://api.github.com/users/holiman/repos",
    "events_url": "https://api.github.com/users/holiman/events{/privacy}",
    "received_events_url": "https://api.github.com/users/holiman/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/22724/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/22724/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/825544885",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/22724#issuecomment-825544885",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/22724",
    "id": 825544885,
    "node_id": "MDEyOklzc3VlQ29tbWVudDgyNTU0NDg4NQ==",
    "user": {
      "login": "holiman",
      "id": 142290,
      "node_id": "MDQ6VXNlcjE0MjI5MA==",
      "avatar_url": "https://avatars.githubusercontent.com/u/142290?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/holiman",
      "html_url": "https://github.com/holiman",
      "followers_url": "https://api.github.com/users/holiman/followers",
      "following_url": "https://api.github.com/users/holiman/following{/other_user}",
      "gists_url": "https://api.github.com/users/holiman/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/holiman/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/holiman/subscriptions",
      "organizations_url": "https://api.github.com/users/holiman/orgs",
      "repos_url": "https://api.github.com/users/holiman/repos",
      "events_url": "https://api.github.com/users/holiman/events{/privacy}",
      "received_events_url": "https://api.github.com/users/holiman/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-04-23T09:55:14Z",
    "updated_at": "2021-04-23T09:55:25Z",
    "author_association": "MEMBER",
    "body": "> Is it correct to say as of now no actual optimisations exist based on the Berlin activated AccessList in terms of Trie (i.e. DB warming) or even snapshot object prefetching? What are the team’s plans for such things going forward? More generally, is there some sort of roadmap capturing planned features or are these only captured ephemerally in discussions/issues?\r\n\r\nThere are currently no such optimizations, correct. I also don't think anyone is working on adding such optimizations -- note, the access lists are not expected to be used by 'mainstream' users anytime soon. If that changes, and they start becoming more common, then it might be worth looking into properly. \r\n\r\n> Somewhat relatedly, is it correct to say that the core/state_prefetcher.go code is outdated\r\n\r\nYes, I'd say so. That prefetcher is only active when you are catchiing up, and have future blocks already downloaded. We've discussed removing it several times, it may just cause problems due to high IO. \r\n\r\nThe `core/state/trie_prefetcher` is a better approach, where we resolve the trie based on what we're going to write. It works in all modes of operation, not just when catching up. Look into that for more details on how it works -- you can also read up some more info here: https://github.com/ethereum/go-ethereum/pull/21047 \r\n\r\n> Why is it that the TriePrefetcher that lives in the StateDB uses one go worker per state root to walk the Trie? \r\n\r\nIIUC, you mean that we would load tries into one trie concurrently? AFAIK the trie is not safe to be used like this. The trie is concurrency-safe in the sense that any time it resolves something, it creates new nodes \"on the way up\" and you get a new root element. But your idea would be, as I understand it, to insert two things at the same time into the trie, which I don't think will work. \r\n\r\nI guess one could build a new trie structure. At one point, I PR:ed a 'batch-mode' for the trie, in which I just updated the nodes in place without replacing them. That _would_ make it possible to insert several things at once, as long as they operated on different subpaths in the trie. Maybe. It's not a trivial problem, feel free to see if you can sketch something up. \r\n\r\n> Further, if the intention is to warm the underlying DB, there is not much reason (apart, perhaps, for convenience) to continue to maintain the Tries in memory, is there?\r\n \r\nNo, the idea is not to just warm the db, but to actually hand out a fully expanded trie to the caller. \r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/825544885/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/825740412",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/22724#issuecomment-825740412",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/22724",
    "id": 825740412,
    "node_id": "MDEyOklzc3VlQ29tbWVudDgyNTc0MDQxMg==",
    "user": {
      "login": "jon-chuang",
      "id": 9093549,
      "node_id": "MDQ6VXNlcjkwOTM1NDk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/9093549?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jon-chuang",
      "html_url": "https://github.com/jon-chuang",
      "followers_url": "https://api.github.com/users/jon-chuang/followers",
      "following_url": "https://api.github.com/users/jon-chuang/following{/other_user}",
      "gists_url": "https://api.github.com/users/jon-chuang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jon-chuang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jon-chuang/subscriptions",
      "organizations_url": "https://api.github.com/users/jon-chuang/orgs",
      "repos_url": "https://api.github.com/users/jon-chuang/repos",
      "events_url": "https://api.github.com/users/jon-chuang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jon-chuang/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-04-23T15:34:16Z",
    "updated_at": "2021-04-23T19:11:03Z",
    "author_association": "NONE",
    "body": "Hi @holiman , thank for the very detailed and quick reply!\r\n\r\nSome replies and more questions:\r\n\r\n1. Am I right to say that as of now, all `Trie`s one expects to encounter are in fact `SecureTrie`s? \r\n\r\n2. TryGet mutates state iff `trie.root.(type) == HashNode` or `n.Children[key[pos]] = newnode`. However, in the former, this branch is defensive programming and is never invoked since `core/state/database.OpenTrie -> trie.NewSecure -> trie.New` sets `Trie.root` to a resolved node. \r\n\r\n3. > No, the idea is not to just warm the db, but to actually hand out a fully expanded trie to the caller.\r\n\r\nOk, I agree here. `trie.Database` actually has a lot of state. ~~Nonetheless, `Trie` and `SecureTrie` themselves are essentially stateless wrappers (apart from some key hash cacheing and ...metrics - on number of leaf inserts, not relevant to our read-only use-case).~~ Furthermore, in the comment description of `trie.Database`\r\n```\r\n// Note, the trie Database is **not** thread safe in its mutations, but it **is**\r\n// thread safe in providing individual, independent node access.\r\n```\r\n~~So calling `Trie.TryGet` concurrently, the only method called in `triePrefetcher` ought not to be a problem. One maintains a reference in each goroutine worker to a given `Trie` living in a `map` that lives in the global `TriePrefetcher` and calls `TryGet` from it concurrently.~~\r\n\r\n~~EDIT: So I think the comment is false. If one mutates the in-memory Trie by modifying the children, then a race condition occurs wherein only the fetches made by the last of n threads to pop off node objects off its call stack and clone and modify them in the event of `didResolve` would persist in memory, while the other \"branch\" would wither and be GCed. What I don't understand is why the modification cannot be performed in place (this would avoid the copy race condition issues by having multiple threads always mutate separate fields). The copy itself solves no problems. We merely need to edit the function to distinguish when the child node is a `HashNode`, and when the entire call `didResolve` (actually, we never need to propagate this all the way upwards, seems like a mistake).~~\r\n\r\n~~However, this still does not make it \"safe\" because if we ever modify a node by having two threads write to the same location, they are writing two different pieces of data, that being two nodes in memory possibly resolved separately. Notice barring this, `TryGet`s of two separate `Trie` keys will always result in nonoverlapping updates to children pointers in a single `FullNode`. This indicates that to solve this problem, one merely needs to ensure that the call stack of every thread references the same nodes in memory. The problem is that currently, walking from the root would result in \"stale\" parents who don't yet know that a child `HashNode` has been resolved.~~\r\n\r\nThe solution to the problem is to lock the parent node's pointer to the child node, whenever a child is a `HashNode`. Then, once `ResolveHash` has been resolved, secondary threads waiting for a parent node would gain access to the in-memory child node.\r\n\r\nEDIT: Ok, so I finally understood your point.\r\n\r\n4. Some \"obvious\" optimisations:\r\na. parallelise `core/state/statedb.IntermediateRoot`: both `StateObject.UpdateRoot -> Trie.TryUpdate/TryDelete` and `StateObject.CommitTrie(s.db)` write to memory via commiting to the expanded `Trie` and writing the updated Trie to the in-memory `trie.Database` respectively, and these can each be parallelised, I think. This ought to improve commit (as seen to be non-trivial - 14.5ms avg v.s. execution with lion's share of ~38.5ms - in a [bench](https://user-images.githubusercontent.com/142290/81902610-b455c200-95c0-11ea-80d7-715dc0623bfd.png) in the PR you linked) depending on available cores. However, I have some questions about the benchmarks. What do commit, account-commit and storage-commit refer to specifically? \r\n\r\nAs for parallelising account commits, I have a `TODO`: identify possible parallelism/batching when writing to `trie.Database`.\r\n\r\n5. From what I understand, `trie.Database` flushes to disk based on a memory cap? However, I can't seem to find where `trie.Database.Cap` is actually called.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/825740412/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/825870234",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/22724#issuecomment-825870234",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/22724",
    "id": 825870234,
    "node_id": "MDEyOklzc3VlQ29tbWVudDgyNTg3MDIzNA==",
    "user": {
      "login": "jon-chuang",
      "id": 9093549,
      "node_id": "MDQ6VXNlcjkwOTM1NDk=",
      "avatar_url": "https://avatars.githubusercontent.com/u/9093549?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jon-chuang",
      "html_url": "https://github.com/jon-chuang",
      "followers_url": "https://api.github.com/users/jon-chuang/followers",
      "following_url": "https://api.github.com/users/jon-chuang/following{/other_user}",
      "gists_url": "https://api.github.com/users/jon-chuang/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jon-chuang/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jon-chuang/subscriptions",
      "organizations_url": "https://api.github.com/users/jon-chuang/orgs",
      "repos_url": "https://api.github.com/users/jon-chuang/repos",
      "events_url": "https://api.github.com/users/jon-chuang/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jon-chuang/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2021-04-23T19:23:32Z",
    "updated_at": "2021-04-23T20:02:40Z",
    "author_association": "NONE",
    "body": "So, in case I was a little too slow in understanding your comment, my main question now, @holiman is whether you think adding a mutex to `NodeFlag` would be acceptable. Possibly this could lead to concurrent `Trie` updates too. But unclear to me how useful this is.\r\n\r\nInstead of handling the `HashNode` case via recursion, we check while in the parent node if the child has type `HashNode` (trivial), if so, lock the parent and resolve the `HashNode`, and immediately modify the child pointer, atomically. So we never have to call `tryGet` with first arg of type `HashNode`. \r\n\r\nAlternatively, the mutex would be in `HashNode`, and we check if it has been locked. If so, we wait until it unlocks, at which point the child pointer would now be pointing to the resolved node. The latter solution is a minimal solution that is limited to hash resolution.\r\n\r\nAn alternate lock-free way of solving this particular problem is to develop a concurrent `HashResolver` service. The service spawns goroutines to run `trie.Database.node` and maintains a `map[Hash] node` for resolved nodes and `map[Hash] struct {}` for nodes it is looking for. A worker running `tryGet` queries the global `HashResolver` for a node. If it is not available, it goes to sleep. This way, we ensure a single global state as managed via the HashMap. If we ensure that no nodes are copied and that all nodes are spawned via the `HashResolver`, then there is a single source of truth for the state of the nodes. Unlike the above solution using mutex, however, we can't ensure that state can be mutated concurrently, only that there is a single resolution of every hash to an object in memory.\r\n\r\nMy rationale for exploring the `Trie`-level prefetch concurrency is if txs are dominated by a single contract like an ERC-20 (and also to better prefetch the account `Trie`). Since this is as far as I can tell not the situation for ETH TXs, it's unclear how much the bench that I linked above reflects the lack of a need for such a workload.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/825870234/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
