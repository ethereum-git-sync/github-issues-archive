{
  "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266",
  "repository_url": "https://api.github.com/repos/ethereum/go-ethereum",
  "labels_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266/labels{/name}",
  "comments_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266/comments",
  "events_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266/events",
  "html_url": "https://github.com/ethereum/go-ethereum/issues/28266",
  "id": 1929306218,
  "node_id": "I_kwDOAOvK985y_uBq",
  "number": 28266,
  "title": "Parallel Intermediate Node Fetching (for a single trie)",
  "user": {
    "login": "aaronbuchwald",
    "id": 24684335,
    "node_id": "MDQ6VXNlcjI0Njg0MzM1",
    "avatar_url": "https://avatars.githubusercontent.com/u/24684335?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/aaronbuchwald",
    "html_url": "https://github.com/aaronbuchwald",
    "followers_url": "https://api.github.com/users/aaronbuchwald/followers",
    "following_url": "https://api.github.com/users/aaronbuchwald/following{/other_user}",
    "gists_url": "https://api.github.com/users/aaronbuchwald/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/aaronbuchwald/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/aaronbuchwald/subscriptions",
    "organizations_url": "https://api.github.com/users/aaronbuchwald/orgs",
    "repos_url": "https://api.github.com/users/aaronbuchwald/repos",
    "events_url": "https://api.github.com/users/aaronbuchwald/events{/privacy}",
    "received_events_url": "https://api.github.com/users/aaronbuchwald/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 72233652,
      "node_id": "MDU6TGFiZWw3MjIzMzY1Mg==",
      "url": "https://api.github.com/repos/ethereum/go-ethereum/labels/type:feature",
      "name": "type:feature",
      "color": "84b6eb",
      "default": false,
      "description": null
    }
  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 2,
  "created_at": "2023-10-06T01:45:20Z",
  "updated_at": "2023-10-10T15:07:15Z",
  "closed_at": null,
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "body": "# Rationale\r\n\r\nCurrently, when go-ethereum builds/executes a block it processes transactions in the EVM (while using the O(1) snapshot to perform DB reads as needed) and then needs to apply all of the state changes to the trie and compute a new state root.\r\n\r\nTypically, the state shuffling is significantly more expensive than the actual EVM processing time (although for the new path based scheme with too much RAM this is close to no longer being the case https://twitter.com/peter_szilagyi/status/1708013385558671662).\r\n\r\nWhen executing transactions in the EVM, the stateDB uses prefetching logic to attempt to pre-warm the trie's cache with all of the intermediate nodes that will need to be shuffled around when it's time to commit the statedb and compute a new state root. If the intermediate nodes are not already in memory, then this can result in a large number of DB reads which can take up a large amount of the time spent on state shuffling.\r\n\r\nFor large storage tries the performance of state fetching can be much lower since the trie implementation is not safe for concurrent use (https://github.com/ethereum/go-ethereum/blob/v1.13.1/trie/trie.go#L37). Although each storage trie gets its own prefetching goroutine (https://github.com/ethereum/go-ethereum/blob/master/core/state/trie_prefetcher.go#L153) if the majority of the workload comes from a single storage trie, then prefetching can be extremely inefficient.\r\n\r\nIdeally, we can parallelize the DB reads to cache all of the intermediate nodes in memory prior to committing the statedb.\r\n\r\n# Implementation\r\n\r\nThere are two different approaches that I've played around with and I'm happy to complete either implementation. I wanted to put this issue up first to get feedback on whether this change makes sense to the geth team and if so, which implementation would be preferred.\r\n\r\nThe difficult part is finding a way to work around the fact that the trie implementation is not safe for concurrent use and refactoring it to support concurrent operations from an external caller would be a very non-trivial re-write.\r\n\r\nMuch better to work completely around that problem.\r\n\r\n## Fetch in Parallel Using Independent Tries\r\n \r\nEach individual trie is not safe for concurrent use, but we can instead create multiple instances of the same trie in order to fetch all of the requested keys in parallel and pull all of the necessary intermediate trie nodes from disk into the trie database's cache.\r\n\r\nAlthough the instance of the trie held by the statedb may not have all fully expanded nodes, it would fetch all of the intermediate nodes into the trie database's cache, so that when it came time to commit the trie, each trie node is already in memory.\r\n\r\nI put up a rough implementation of what it would look like to add this into `updateTrie` within each state object here: https://github.com/ethereum/go-ethereum/compare/master...aaronbuchwald:go-ethereum:parallel-fetch-update-trie. It may make more sense to move this to the prefetcher code, but this was much simpler as a proof of concept.\r\n\r\n## Support `BatchCacheKeys` / `BatchPut` Internally to the Trie\r\n\r\nMuch easier than parallelizing the trie for external callers is to support parallel operations internal to the trie!\r\n\r\nInstead of re-writing the trie to support concurrency, we can construct a trie out of the get/put operations that we want to apply.\r\n\r\nFor `BatchCacheKeys`, we can construct a trie from the requested keys and arbitrary non-empty values (as required by the current trie code since an empty value is treated as a delete). \r\n\r\nThen we can traverse the actual trie and our batchTrie. By traversing both tries, we can serve all of the requests encoded in the batch trie and parallelize different sub tries that do not depend on each other.\r\n\r\nFor example:\r\n\r\nt:\r\n```mermaid\r\ngraph TD;\r\nr-->0;\r\nr-->1;\r\n0-->A;\r\n1-->B;\r\n```\r\n\r\nt':\r\n```mermaid\r\ngraph TD;\r\nr'-->0;\r\nr'-->1;\r\n0-->A';\r\n1-->B';\r\n```\r\n\r\nIn this case, we traverse r and r' and see they both have children at nibbles 0 and 1. Therefore, we can apply A' to A and B' to B in parallel since they are completely independent. Once both sub tries have completed, we can apply the resulting update to get `r''`.\r\n\r\nThe same logic can be applied to either `BatchGet` or `BatchPut` operations to either warm the cache or directly parallelize the put operation.\r\n\r\nI have a WIP for this implementation here: https://github.com/aaronbuchwald/go-ethereum/blob/trie-batch/trie/trie_parallel.go#L43 but since there are 4 different node types to deal with my current implementation is much more complex than I'd like and I am still running into a bug in my fuzz test when dealing with values of length 0 (which should be treated as deletes, but still pass the test unless I'm missing something).\r\n\r\nAt least as a first change, I think the first solution is much better since it's significantly simpler and since DB reads will be the dominating factor, it should be very similar in performance. Also, huge thanks to @dboehm-avalabs for coming up with this much simpler approach here: https://github.com/ava-labs/avalanchego/pull/2128.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266/reactions",
    "total_count": 1,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 1,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
[
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1750003989",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/28266#issuecomment-1750003989",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266",
    "id": 1750003989,
    "node_id": "IC_kwDOAOvK985oTvEV",
    "user": {
      "login": "karalabe",
      "id": 129561,
      "node_id": "MDQ6VXNlcjEyOTU2MQ==",
      "avatar_url": "https://avatars.githubusercontent.com/u/129561?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/karalabe",
      "html_url": "https://github.com/karalabe",
      "followers_url": "https://api.github.com/users/karalabe/followers",
      "following_url": "https://api.github.com/users/karalabe/following{/other_user}",
      "gists_url": "https://api.github.com/users/karalabe/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/karalabe/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/karalabe/subscriptions",
      "organizations_url": "https://api.github.com/users/karalabe/orgs",
      "repos_url": "https://api.github.com/users/karalabe/repos",
      "events_url": "https://api.github.com/users/karalabe/events{/privacy}",
      "received_events_url": "https://api.github.com/users/karalabe/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-10-06T05:26:25Z",
    "updated_at": "2023-10-06T05:26:25Z",
    "author_association": "MEMBER",
    "body": "I'm wondering about a 3rd option :trollface: \r\n\r\nMy main concern with the first option is that it's kind of racey. By that I mean that if I have say 2 tries and want to expand sibling leaves, then the entire path will be shared, apart of the last branching. If these paths are expanded - timewise - apart from each other, then one will warm up the cache and the second might pull it in, true. However, since execution can throw these at the prefetcher fairly quickly, you might end up with both actually working in parallel, both reading from the DB. It would depend on the db internals as to how well it can short circuit reads for the same keys, but I'm a bit uncomfortable to leave it that low.\r\n\r\nNow, with the other case of doing batch expansions, my concern is that we don't know how many accesses we need to wait for or what the timings will be between two. If I wait until the EVM execution is done, we might have wasted precious time in which we could have been busy pulling stuff from disk. It gets a bit hard to fine tune and reason about.\r\n\r\nMy preferred solution would be if we could have thread safe prefetching within the trie, so that I can throw as many concurrent loads at it as I want and it would sync within. Still, there are a few catches: I'm unsure what the synchronisation cost would be at a node level, possibly big. And the other thing we want to avoid is starving the main EVM execution because we're hitting the prefetching on gazillions of threads. Limiting the thread count per trie would get ugly fast, and limiting it across all prefetching tries would get ugly even faster :)\r\n\r\nIMO, *the* solution here is probably to try and implement a variety of options and benchmark them one against the other. There is no clear winner either complexity or runtime wise, so I can't really say \"go with X\".... X might suck. My proposal would be to implement - at least up to a benchmarkable state - all variations and see how they compare against the current state.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1750003989/reactions",
      "total_count": 1,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 1,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1750955505",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/28266#issuecomment-1750955505",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266",
    "id": 1750955505,
    "node_id": "IC_kwDOAOvK985oXXXx",
    "user": {
      "login": "aaronbuchwald",
      "id": 24684335,
      "node_id": "MDQ6VXNlcjI0Njg0MzM1",
      "avatar_url": "https://avatars.githubusercontent.com/u/24684335?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/aaronbuchwald",
      "html_url": "https://github.com/aaronbuchwald",
      "followers_url": "https://api.github.com/users/aaronbuchwald/followers",
      "following_url": "https://api.github.com/users/aaronbuchwald/following{/other_user}",
      "gists_url": "https://api.github.com/users/aaronbuchwald/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/aaronbuchwald/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/aaronbuchwald/subscriptions",
      "organizations_url": "https://api.github.com/users/aaronbuchwald/orgs",
      "repos_url": "https://api.github.com/users/aaronbuchwald/repos",
      "events_url": "https://api.github.com/users/aaronbuchwald/events{/privacy}",
      "received_events_url": "https://api.github.com/users/aaronbuchwald/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-10-06T15:47:03Z",
    "updated_at": "2023-10-10T15:07:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "Thanks for the input!\r\n\r\nI'd think that the DB would handle concurrent reads for the same node around the same time well, but I could definitely be wrong and hard to say how well without a benchmark.\r\n\r\nReally appreciate the input, I'll work on taking this further and getting each to a benchmarkable state.\r\n\r\nDo you typically use the benchmarks in https://github.com/ethereum/go-ethereum/blob/master/core/blockchain_test.go or do you have a strong preference for bootstrapping to compare performance?",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1750955505/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
