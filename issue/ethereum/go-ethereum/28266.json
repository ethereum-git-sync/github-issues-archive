{
  "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266",
  "repository_url": "https://api.github.com/repos/ethereum/go-ethereum",
  "labels_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266/labels{/name}",
  "comments_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266/comments",
  "events_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266/events",
  "html_url": "https://github.com/ethereum/go-ethereum/issues/28266",
  "id": 1929306218,
  "node_id": "I_kwDOAOvK985y_uBq",
  "number": 28266,
  "title": "Parallel Intermediate Node Fetching (for a single trie)",
  "user": {
    "login": "aaronbuchwald",
    "id": 24684335,
    "node_id": "MDQ6VXNlcjI0Njg0MzM1",
    "avatar_url": "https://avatars.githubusercontent.com/u/24684335?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/aaronbuchwald",
    "html_url": "https://github.com/aaronbuchwald",
    "followers_url": "https://api.github.com/users/aaronbuchwald/followers",
    "following_url": "https://api.github.com/users/aaronbuchwald/following{/other_user}",
    "gists_url": "https://api.github.com/users/aaronbuchwald/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/aaronbuchwald/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/aaronbuchwald/subscriptions",
    "organizations_url": "https://api.github.com/users/aaronbuchwald/orgs",
    "repos_url": "https://api.github.com/users/aaronbuchwald/repos",
    "events_url": "https://api.github.com/users/aaronbuchwald/events{/privacy}",
    "received_events_url": "https://api.github.com/users/aaronbuchwald/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 72233652,
      "node_id": "MDU6TGFiZWw3MjIzMzY1Mg==",
      "url": "https://api.github.com/repos/ethereum/go-ethereum/labels/type:feature",
      "name": "type:feature",
      "color": "84b6eb",
      "default": false,
      "description": null
    }
  ],
  "state": "open",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 5,
  "created_at": "2023-10-06T01:45:20Z",
  "updated_at": "2023-10-31T20:39:04Z",
  "closed_at": null,
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "body": "# Rationale\r\n\r\nCurrently, when go-ethereum builds/executes a block it processes transactions in the EVM (while using the O(1) snapshot to perform DB reads as needed) and then needs to apply all of the state changes to the trie and compute a new state root.\r\n\r\nTypically, the state shuffling is significantly more expensive than the actual EVM processing time (although for the new path based scheme with too much RAM this is close to no longer being the case https://twitter.com/peter_szilagyi/status/1708013385558671662).\r\n\r\nWhen executing transactions in the EVM, the stateDB uses prefetching logic to attempt to pre-warm the trie's cache with all of the intermediate nodes that will need to be shuffled around when it's time to commit the statedb and compute a new state root. If the intermediate nodes are not already in memory, then this can result in a large number of DB reads which can take up a large amount of the time spent on state shuffling.\r\n\r\nFor large storage tries the performance of state fetching can be much lower since the trie implementation is not safe for concurrent use (https://github.com/ethereum/go-ethereum/blob/v1.13.1/trie/trie.go#L37). Although each storage trie gets its own prefetching goroutine (https://github.com/ethereum/go-ethereum/blob/master/core/state/trie_prefetcher.go#L153) if the majority of the workload comes from a single storage trie, then prefetching can be extremely inefficient.\r\n\r\nIdeally, we can parallelize the DB reads to cache all of the intermediate nodes in memory prior to committing the statedb.\r\n\r\n# Implementation\r\n\r\nThere are two different approaches that I've played around with and I'm happy to complete either implementation. I wanted to put this issue up first to get feedback on whether this change makes sense to the geth team and if so, which implementation would be preferred.\r\n\r\nThe difficult part is finding a way to work around the fact that the trie implementation is not safe for concurrent use and refactoring it to support concurrent operations from an external caller would be a very non-trivial re-write.\r\n\r\nMuch better to work completely around that problem.\r\n\r\n## Fetch in Parallel Using Independent Tries\r\n \r\nEach individual trie is not safe for concurrent use, but we can instead create multiple instances of the same trie in order to fetch all of the requested keys in parallel and pull all of the necessary intermediate trie nodes from disk into the trie database's cache.\r\n\r\nAlthough the instance of the trie held by the statedb may not have all fully expanded nodes, it would fetch all of the intermediate nodes into the trie database's cache, so that when it came time to commit the trie, each trie node is already in memory.\r\n\r\nI put up a rough implementation of what it would look like to add this into `updateTrie` within each state object here: https://github.com/ethereum/go-ethereum/compare/master...aaronbuchwald:go-ethereum:parallel-fetch-update-trie. It may make more sense to move this to the prefetcher code, but this was much simpler as a proof of concept.\r\n\r\n## Support `BatchCacheKeys` / `BatchPut` Internally to the Trie\r\n\r\nMuch easier than parallelizing the trie for external callers is to support parallel operations internal to the trie!\r\n\r\nInstead of re-writing the trie to support concurrency, we can construct a trie out of the get/put operations that we want to apply.\r\n\r\nFor `BatchCacheKeys`, we can construct a trie from the requested keys and arbitrary non-empty values (as required by the current trie code since an empty value is treated as a delete). \r\n\r\nThen we can traverse the actual trie and our batchTrie. By traversing both tries, we can serve all of the requests encoded in the batch trie and parallelize different sub tries that do not depend on each other.\r\n\r\nFor example:\r\n\r\nt:\r\n```mermaid\r\ngraph TD;\r\nr-->0;\r\nr-->1;\r\n0-->A;\r\n1-->B;\r\n```\r\n\r\nt':\r\n```mermaid\r\ngraph TD;\r\nr'-->0;\r\nr'-->1;\r\n0-->A';\r\n1-->B';\r\n```\r\n\r\nIn this case, we traverse r and r' and see they both have children at nibbles 0 and 1. Therefore, we can apply A' to A and B' to B in parallel since they are completely independent. Once both sub tries have completed, we can apply the resulting update to get `r''`.\r\n\r\nThe same logic can be applied to either `BatchGet` or `BatchPut` operations to either warm the cache or directly parallelize the put operation.\r\n\r\nI have a WIP for this implementation here: https://github.com/aaronbuchwald/go-ethereum/blob/trie-batch/trie/trie_parallel.go#L43 but since there are 4 different node types to deal with my current implementation is much more complex than I'd like and I am still running into a bug in my fuzz test when dealing with values of length 0 (which should be treated as deletes, but still pass the test unless I'm missing something).\r\n\r\nAt least as a first change, I think the first solution is much better since it's significantly simpler and since DB reads will be the dominating factor, it should be very similar in performance. Also, huge thanks to @dboehm-avalabs for coming up with this much simpler approach here: https://github.com/ava-labs/avalanchego/pull/2128.",
  "closed_by": null,
  "reactions": {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266/reactions",
    "total_count": 1,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 1,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266/timeline",
  "performed_via_github_app": null,
  "state_reason": null
}
[
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1750003989",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/28266#issuecomment-1750003989",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266",
    "id": 1750003989,
    "node_id": "IC_kwDOAOvK985oTvEV",
    "user": {
      "login": "karalabe",
      "id": 129561,
      "node_id": "MDQ6VXNlcjEyOTU2MQ==",
      "avatar_url": "https://avatars.githubusercontent.com/u/129561?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/karalabe",
      "html_url": "https://github.com/karalabe",
      "followers_url": "https://api.github.com/users/karalabe/followers",
      "following_url": "https://api.github.com/users/karalabe/following{/other_user}",
      "gists_url": "https://api.github.com/users/karalabe/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/karalabe/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/karalabe/subscriptions",
      "organizations_url": "https://api.github.com/users/karalabe/orgs",
      "repos_url": "https://api.github.com/users/karalabe/repos",
      "events_url": "https://api.github.com/users/karalabe/events{/privacy}",
      "received_events_url": "https://api.github.com/users/karalabe/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-10-06T05:26:25Z",
    "updated_at": "2023-10-06T05:26:25Z",
    "author_association": "MEMBER",
    "body": "I'm wondering about a 3rd option :trollface: \r\n\r\nMy main concern with the first option is that it's kind of racey. By that I mean that if I have say 2 tries and want to expand sibling leaves, then the entire path will be shared, apart of the last branching. If these paths are expanded - timewise - apart from each other, then one will warm up the cache and the second might pull it in, true. However, since execution can throw these at the prefetcher fairly quickly, you might end up with both actually working in parallel, both reading from the DB. It would depend on the db internals as to how well it can short circuit reads for the same keys, but I'm a bit uncomfortable to leave it that low.\r\n\r\nNow, with the other case of doing batch expansions, my concern is that we don't know how many accesses we need to wait for or what the timings will be between two. If I wait until the EVM execution is done, we might have wasted precious time in which we could have been busy pulling stuff from disk. It gets a bit hard to fine tune and reason about.\r\n\r\nMy preferred solution would be if we could have thread safe prefetching within the trie, so that I can throw as many concurrent loads at it as I want and it would sync within. Still, there are a few catches: I'm unsure what the synchronisation cost would be at a node level, possibly big. And the other thing we want to avoid is starving the main EVM execution because we're hitting the prefetching on gazillions of threads. Limiting the thread count per trie would get ugly fast, and limiting it across all prefetching tries would get ugly even faster :)\r\n\r\nIMO, *the* solution here is probably to try and implement a variety of options and benchmark them one against the other. There is no clear winner either complexity or runtime wise, so I can't really say \"go with X\".... X might suck. My proposal would be to implement - at least up to a benchmarkable state - all variations and see how they compare against the current state.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1750003989/reactions",
      "total_count": 2,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 2,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1750955505",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/28266#issuecomment-1750955505",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266",
    "id": 1750955505,
    "node_id": "IC_kwDOAOvK985oXXXx",
    "user": {
      "login": "aaronbuchwald",
      "id": 24684335,
      "node_id": "MDQ6VXNlcjI0Njg0MzM1",
      "avatar_url": "https://avatars.githubusercontent.com/u/24684335?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/aaronbuchwald",
      "html_url": "https://github.com/aaronbuchwald",
      "followers_url": "https://api.github.com/users/aaronbuchwald/followers",
      "following_url": "https://api.github.com/users/aaronbuchwald/following{/other_user}",
      "gists_url": "https://api.github.com/users/aaronbuchwald/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/aaronbuchwald/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/aaronbuchwald/subscriptions",
      "organizations_url": "https://api.github.com/users/aaronbuchwald/orgs",
      "repos_url": "https://api.github.com/users/aaronbuchwald/repos",
      "events_url": "https://api.github.com/users/aaronbuchwald/events{/privacy}",
      "received_events_url": "https://api.github.com/users/aaronbuchwald/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-10-06T15:47:03Z",
    "updated_at": "2023-10-10T15:07:15Z",
    "author_association": "CONTRIBUTOR",
    "body": "Thanks for the input!\r\n\r\nI'd think that the DB would handle concurrent reads for the same node around the same time well, but I could definitely be wrong and hard to say how well without a benchmark.\r\n\r\nReally appreciate the input, I'll work on taking this further and getting each to a benchmarkable state.\r\n\r\nDo you typically use the benchmarks in https://github.com/ethereum/go-ethereum/blob/master/core/blockchain_test.go or do you have a strong preference for bootstrapping to compare performance?",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1750955505/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1763160938",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/28266#issuecomment-1763160938",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266",
    "id": 1763160938,
    "node_id": "IC_kwDOAOvK985pF7Nq",
    "user": {
      "login": "ameya-deshmukh",
      "id": 74180822,
      "node_id": "MDQ6VXNlcjc0MTgwODIy",
      "avatar_url": "https://avatars.githubusercontent.com/u/74180822?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/ameya-deshmukh",
      "html_url": "https://github.com/ameya-deshmukh",
      "followers_url": "https://api.github.com/users/ameya-deshmukh/followers",
      "following_url": "https://api.github.com/users/ameya-deshmukh/following{/other_user}",
      "gists_url": "https://api.github.com/users/ameya-deshmukh/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/ameya-deshmukh/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/ameya-deshmukh/subscriptions",
      "organizations_url": "https://api.github.com/users/ameya-deshmukh/orgs",
      "repos_url": "https://api.github.com/users/ameya-deshmukh/repos",
      "events_url": "https://api.github.com/users/ameya-deshmukh/events{/privacy}",
      "received_events_url": "https://api.github.com/users/ameya-deshmukh/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-10-14T19:47:29Z",
    "updated_at": "2023-10-14T19:47:29Z",
    "author_association": "NONE",
    "body": "@karalabe is this open to take up? Would love to take a stab at this.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1763160938/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1781269127",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/28266#issuecomment-1781269127",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266",
    "id": 1781269127,
    "node_id": "IC_kwDOAOvK985qLAKH",
    "user": {
      "login": "aaronbuchwald",
      "id": 24684335,
      "node_id": "MDQ6VXNlcjI0Njg0MzM1",
      "avatar_url": "https://avatars.githubusercontent.com/u/24684335?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/aaronbuchwald",
      "html_url": "https://github.com/aaronbuchwald",
      "followers_url": "https://api.github.com/users/aaronbuchwald/followers",
      "following_url": "https://api.github.com/users/aaronbuchwald/following{/other_user}",
      "gists_url": "https://api.github.com/users/aaronbuchwald/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/aaronbuchwald/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/aaronbuchwald/subscriptions",
      "organizations_url": "https://api.github.com/users/aaronbuchwald/orgs",
      "repos_url": "https://api.github.com/users/aaronbuchwald/repos",
      "events_url": "https://api.github.com/users/aaronbuchwald/events{/privacy}",
      "received_events_url": "https://api.github.com/users/aaronbuchwald/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-10-26T14:41:26Z",
    "updated_at": "2023-10-26T14:41:26Z",
    "author_association": "CONTRIBUTOR",
    "body": "WIP for this is here: https://github.com/ethereum/go-ethereum/compare/master...aaronbuchwald:go-ethereum:trie-batch-strategies?expand=1.\r\n\r\nI'm working on setting up an EC2 to test this out when running on a large leveldb instance (instead of mocked iowait using sleep or a very small leveldb instance).\r\n\r\nAfter benchmarking the trie implementation in isolation, I'm going to:\r\n1. refactor the trie prefetcher to use any of the batched prefetch functions\r\n2. benchmark each batch prefetch function used in the trie prefetcher\r\n3. benchmark using the parallel prefetcher prior to large storage trie writes\r\n\r\n@ameya-deshmukh lmk if you're interested to collaborate. A review on the existing work would be much appreciated (I think there's probably still bugs in `BatchGet` but I reached a point where the fuzz test struggles to find a new issue). You could also take a stab at implementing a `BatchPut` operation that follows the same style as `BatchGet` to perform put a batch of put operations in parallel internal to the trie.\r\n\r\nIf we have `BatchPut`, then we can use the prefetcher prior to committing the trie and perform `BatchPut` when it's time to commit so that any remaining work is performed in parallel.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1781269127/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1787996843",
    "html_url": "https://github.com/ethereum/go-ethereum/issues/28266#issuecomment-1787996843",
    "issue_url": "https://api.github.com/repos/ethereum/go-ethereum/issues/28266",
    "id": 1787996843,
    "node_id": "IC_kwDOAOvK985qkqqr",
    "user": {
      "login": "aaronbuchwald",
      "id": 24684335,
      "node_id": "MDQ6VXNlcjI0Njg0MzM1",
      "avatar_url": "https://avatars.githubusercontent.com/u/24684335?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/aaronbuchwald",
      "html_url": "https://github.com/aaronbuchwald",
      "followers_url": "https://api.github.com/users/aaronbuchwald/followers",
      "following_url": "https://api.github.com/users/aaronbuchwald/following{/other_user}",
      "gists_url": "https://api.github.com/users/aaronbuchwald/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/aaronbuchwald/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/aaronbuchwald/subscriptions",
      "organizations_url": "https://api.github.com/users/aaronbuchwald/orgs",
      "repos_url": "https://api.github.com/users/aaronbuchwald/repos",
      "events_url": "https://api.github.com/users/aaronbuchwald/events{/privacy}",
      "received_events_url": "https://api.github.com/users/aaronbuchwald/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2023-10-31T20:39:03Z",
    "updated_at": "2023-10-31T20:39:03Z",
    "author_association": "CONTRIBUTOR",
    "body": "Updated the PR with some benchmarks that are isolated to the trie code.\r\n\r\nThe trie DB does not support writing trie nodes to disk except for the normal access pattern, so I implemented some mocked node readers.\r\n\r\nFor the hash based leveldb on a 50GB disk, I'm seeing:\r\n```\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetch-TrieSize=10000-NumOps=10000-Parallelism=100-8         \t       1\t  15510834 ns/op\t      1004 reads/op\t 200520869 setup/op\t17771864 B/op\t  148579 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchCopies-TrieSize=10000-NumOps=10000-Parallelism=100-8   \t       1\t  20603739 ns/op\t      1019 reads/op\t 149537223 setup/op\t32820912 B/op\t  397762 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchSequential-TrieSize=10000-NumOps=10000-8               \t       1\t   7892993 ns/op\t       973.0 reads/op\t1242217518 setup/op\t 3039272 B/op\t   46459 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetch-TrieSize=1000000-NumOps=10000-Parallelism=100-8       \t       1\t  78410055 ns/op\t     13437 reads/op\t3166969154 setup/op\t72700384 B/op\t  789398 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchCopies-TrieSize=1000000-NumOps=10000-Parallelism=100-8 \t       1\t 106937484 ns/op\t     13460 reads/op\t 550216983 setup/op\t120255304 B/op\t 1250465 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchSequential-TrieSize=1000000-NumOps=10000-8             \t       1\t 342994046 ns/op\t     13363 reads/op\t3332154309 setup/op\t77223752 B/op\t  778211 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetch-TrieSize=10000000-NumOps=10000-Parallelism=100-8      \t       1\t 301627975 ns/op\t     21315 reads/op\t14254487217 setup/op\t151359424 B/op\t 1814877 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchCopies-TrieSize=10000000-NumOps=10000-Parallelism=100-8          1\t 357851357 ns/op\t     21402 reads/op\t18521055157 setup/op\t199365208 B/op\t 2571689 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchSequential-TrieSize=10000000-NumOps=10000-8                      1\t5212844952 ns/op\t     21268 reads/op\t17684188933 setup/op\t441997576 B/op\t 4154303 allocs/op\r\n```\r\n\r\nFor a mock path based (lookup trie nodes based off of path, not actually using the pathdb implementation):\r\n\r\n```\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetch-TrieSize=10000-NumOps=10000-Parallelism=100-8         \t       1\t  17083787 ns/op\t       990.0 reads/op\t1294497008 setup/op\t18927160 B/op\t  149373 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchCopies-TrieSize=10000-NumOps=10000-Parallelism=100-8   \t       1\t  14954369 ns/op\t       996.0 reads/op\t1280698162 setup/op\t29083600 B/op\t  330451 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchSequential-TrieSize=10000-NumOps=10000-8               \t       1\t  10130656 ns/op\t       954.0 reads/op\t1231005866 setup/op\t 5074472 B/op\t   46426 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetch-TrieSize=1000000-NumOps=10000-Parallelism=100-8       \t       1\t  52354034 ns/op\t     13319 reads/op\t3329864425 setup/op\t59983688 B/op\t  663393 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchCopies-TrieSize=1000000-NumOps=10000-Parallelism=100-8 \t       1\t  88611409 ns/op\t     13585 reads/op\t 601209565 setup/op\t104368504 B/op\t 1114752 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchSequential-TrieSize=1000000-NumOps=10000-8             \t       1\t 292722501 ns/op\t     13433 reads/op\t 599777794 setup/op\t87862248 B/op\t  883739 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetch-TrieSize=10000000-NumOps=10000-Parallelism=100-8      \t       1\t 111618086 ns/op\t     21315 reads/op\t8705843886 setup/op\t117762184 B/op\t 1367677 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchCopies-TrieSize=10000000-NumOps=10000-Parallelism=100-8        1\t 214599153 ns/op\t     21430 reads/op\t7060706413 setup/op\t191390792 B/op\t 2300811 allocs/op\r\nBenchmarkBatchPrefetchStrategies/BatchPrefetchSequential-TrieSize=10000000-NumOps=10000-8                    1\t 531480799 ns/op\t     21255 reads/op\t8568405414 setup/op\t154002872 B/op\t 1605778 allocs/op\r\n```\r\n\r\nFor the lower trie sizes (which is unfortunately unknown to the state prefetcher and during commit) it ends up slowing down the benchmark while for larger tries it can be a 10x performance improvement.\r\n\r\nI also added a benchmark for the construction of the internal trie node used to parallelize the `BatchPrefetch` operation and for 10k operations this takes 10ms, which is larger than the performance difference between `BatchPrefetch` and `BatchPrefetchSequential`. In other words, the setup cost is high and results in an overall decrease in performance for a small trie and large number of operations, but the parallel execution is still slightly faster than the sequential execution.\r\n\r\nAlso noticing that the `BatchPrefetch` implementation is slightly faster than `BatchPrefetchWithCopies`, but not by an order of magnitude. Since it's significantly more complex, `BatchPrefetchWithCopies` is probably the better first pass imo.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/go-ethereum/issues/comments/1787996843/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
