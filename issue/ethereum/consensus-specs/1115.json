{
  "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115",
  "repository_url": "https://api.github.com/repos/ethereum/consensus-specs",
  "labels_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115/labels{/name}",
  "comments_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115/comments",
  "events_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115/events",
  "html_url": "https://github.com/ethereum/consensus-specs/issues/1115",
  "id": 447766723,
  "node_id": "MDU6SXNzdWU0NDc3NjY3MjM=",
  "number": 1115,
  "title": "Another possibility for hash_tree_root of dynamic lists",
  "user": {
    "login": "vbuterin",
    "id": 2230894,
    "node_id": "MDQ6VXNlcjIyMzA4OTQ=",
    "avatar_url": "https://avatars.githubusercontent.com/u/2230894?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/vbuterin",
    "html_url": "https://github.com/vbuterin",
    "followers_url": "https://api.github.com/users/vbuterin/followers",
    "following_url": "https://api.github.com/users/vbuterin/following{/other_user}",
    "gists_url": "https://api.github.com/users/vbuterin/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/vbuterin/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/vbuterin/subscriptions",
    "organizations_url": "https://api.github.com/users/vbuterin/orgs",
    "repos_url": "https://api.github.com/users/vbuterin/repos",
    "events_url": "https://api.github.com/users/vbuterin/events{/privacy}",
    "received_events_url": "https://api.github.com/users/vbuterin/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1170174610,
      "node_id": "MDU6TGFiZWwxMTcwMTc0NjEw",
      "url": "https://api.github.com/repos/ethereum/consensus-specs/labels/scope:SSZ",
      "name": "scope:SSZ",
      "color": "77428D",
      "default": false,
      "description": "Simple Serialize"
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 9,
  "created_at": "2019-05-23T16:43:11Z",
  "updated_at": "2019-06-15T19:44:37Z",
  "closed_at": "2019-06-15T19:44:37Z",
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "body": "Epistemic status: very uncertain if this is a good idea but IMO worth talking about the issues.\r\n\r\n### Status quo\r\n\r\nIn English: make a Merkle tree of the data, padding it with zeroes to make the length an exact power of two. Then take the hash of the root of that tree together with the length of the list.\r\n\r\nIn code:\r\n\r\n```python\r\ndef merkle_tree(lst):\r\n    o = [0] * next_power_of_two(len(lst)) + lst + [0] * (next_power_of_two(len(lst)) - len(lst))\r\n    for i in range(next_power_of_two(len(lst))-1, 0, -1):\r\n       o[i] = hash(o[i*2] + o[i*2+1])\r\n    return o[1]\r\ndef hash_tree_root(lst):\r\n    return hash(merkle_tree(lst) + len(lst).to_bytes(32, 'little'))\r\n```\r\n\r\nExample with three-item list:\r\n\r\n```\r\n      R\r\n     / \\\r\n    /\\  3\r\n   /  \\\r\n  /\\  /\\\r\n A B  C 0\r\n```\r\n\r\n### Alternative option\r\n\r\nIn English: make an imbalanced tree where the top left node is the length, then the right->left node points to the first 2 elements, then the right->right->left node points to the next 4 elements, and so forth, so at any depth N there's a root of a tree of 2**(N-1) of the elements.\r\n\r\nIn code:\r\n\r\n```python\r\ndef merkle_tree(lst, full_length, empty=b'\\x00'*32):\r\n    if full_length == 1:\r\n        return lst[0]\r\n    if len(lst) % 2 == 1:\r\n        lst = lst + [empty]\r\n    return merkle_tree(\r\n        [hash(lst[i] + lst[i+1]) for i in range(0, len(lst), 2)],\r\n        full_length//2, \r\n        empty=hash(empty+empty)\r\n    )\r\ndef hash_tree_root(lst):\r\n    o = b'\\x00'*32\r\n    lst = [None, len(lst).to_bytes(32, 'little')] + lst\r\n    lst += [b'\\x00' * 32 + (next_power_of_2(len(lst)+1) - len(lst) - 1)]\r\n    for i in range(log2(len(lst))-1, -1, -1):\r\n        o = hash(merkle_tree(lst[2**i:2**(i+1)], 2**i) + o)\r\n    return o\r\n```\r\n\r\nExample with three-item list:\r\n\r\n```\r\n     R\r\n    / \\\r\n   3  /\\\r\n     /\\ \\\r\n    A B /\\\r\n       /  \\\r\n      /\\   0\r\n     /  \\  \r\n    /\\  /\\\r\n   C 0 0 0\r\n```\r\n\r\n### Rationale\r\n\r\nCurrently there is a perfect correspondence between SSZ path (eg. `obj -> obj.member[17].other_member[3]`) and tree path (the steps of where you descend left or right from the root to get to that specific value) in all cases except for one: that of dynamic lists. This increases complexity for light client protocol implementers because:\r\n\r\n1. A proof of a single value in an SSZ tree may require multiple logical branches rather than just one to determine what the length is so that the verifier can determine the depth to prove a value (technically the length will always be along the Merkle branch that proves any item, but it's still extra complexity to extract it)\r\n\r\n2. `pop` or `append` operations to lists, if they cross the power-of-two boundary, require a rebalancing of the tree that changes the paths to every item in an entire subtree.\r\n\r\nThis proposal makes it so that the correspondence between SSZ path and tree path is always one-to-one, and any operation is a single Merkle branch update (or two Merkle branch updates to update the length for an `append` or `pop`).\r\n\r\nWeaknesses:\r\n\r\n* More base-protocol and implementation complexity\r\n* ~1 extra hash per Merkle proof of a single value\r\n* Still need to check length values if you want to check validity\r\n* Insert and pop still require nontrivial extra logic to append or pop items",
  "closed_by": {
    "login": "JustinDrake",
    "id": 731743,
    "node_id": "MDQ6VXNlcjczMTc0Mw==",
    "avatar_url": "https://avatars.githubusercontent.com/u/731743?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/JustinDrake",
    "html_url": "https://github.com/JustinDrake",
    "followers_url": "https://api.github.com/users/JustinDrake/followers",
    "following_url": "https://api.github.com/users/JustinDrake/following{/other_user}",
    "gists_url": "https://api.github.com/users/JustinDrake/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/JustinDrake/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/JustinDrake/subscriptions",
    "organizations_url": "https://api.github.com/users/JustinDrake/orgs",
    "repos_url": "https://api.github.com/users/JustinDrake/repos",
    "events_url": "https://api.github.com/users/JustinDrake/events{/privacy}",
    "received_events_url": "https://api.github.com/users/JustinDrake/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495347393",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/1115#issuecomment-495347393",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115",
    "id": 495347393,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NTM0NzM5Mw==",
    "user": {
      "login": "protolambda",
      "id": 19571989,
      "node_id": "MDQ6VXNlcjE5NTcxOTg5",
      "avatar_url": "https://avatars.githubusercontent.com/u/19571989?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/protolambda",
      "html_url": "https://github.com/protolambda",
      "followers_url": "https://api.github.com/users/protolambda/followers",
      "following_url": "https://api.github.com/users/protolambda/following{/other_user}",
      "gists_url": "https://api.github.com/users/protolambda/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/protolambda/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/protolambda/subscriptions",
      "organizations_url": "https://api.github.com/users/protolambda/orgs",
      "repos_url": "https://api.github.com/users/protolambda/repos",
      "events_url": "https://api.github.com/users/protolambda/events{/privacy}",
      "received_events_url": "https://api.github.com/users/protolambda/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-05-23T19:10:35Z",
    "updated_at": "2019-05-25T13:11:14Z",
    "author_association": "MEMBER",
    "body": "Some comments on the Rationale part, with possible suggestions:\r\n\r\n1. We already length-mix-in it right? And getting the next power of 2 is constant time. The real problem is just the extra logic step necessary to locate both check the branch length and the proof (correct?). ~~Maybe we can mix in the next-power of 2 as well, enforce that, and use it to proof the leaf together with the length? Locating the item (considering re-balances) still requires some effort, but really is not that complicated, and worth whatever the small cost.~~ Edit: real challenge: need to keep branch paths stable with additions.\r\n2. List re-balancing is not so bad. I think it is better than having to hash extra ~~linearly~~ for each additional element, ~~effectively making dynamic lists much less applicable than fixed length lists.~~ Edit: if each next level is expanded more and more, it's not linear. But item at index `0` still has huge benefit with this design.\r\n3. I do like how it preserves the binary-tree generelized index system, but indices can get ~~very~~ long*er* this way because of the imbalance. ~~IMO, something to avoid at other costs. (e.g. you don't want a 10k bits bitstring as generalized index to identify a validator in a large dynamic list, like the registry)~~ Not linear, but also not perfect.\r\n\r\n\r\nAlso, I considered a similar idea during Edcon in sydney, but not directly applied to merkle trees; i.e. use a bitstring to identify which elements in a structure are present (effectively the same as a generalized index, if you only consider 1 element), but for multiple elements. If ssz-encoded messages are prefixed with such a thing, you effectively implement the ability to null/union everything you want (reason for bringing up the idea, nulls/unions are still not implemented :( ). But for large lists it is not practical for the same reasons as *a linear* merkle structure is not.\r\n\r\nEdit TLDR: misunderstood the structure. It's not linear, evert level keeps expanding more, to allow for bigger additions. But high level leafs still have some cost benefits over lower level leafs.\r\n\r\nAnd here's a quick helper function for calculating the next power of 2 for merkleization, for in future pseudo-code/experiments. I updated the merkle tree code in the SSZ typing draft PR, but that is still stuck in a limbo status after I changed back to testing. https://github.com/ethereum/eth2.0-specs/blob/08faa86d706c31cd9690cb483d0df32f66696396/test_libs/pyspec/eth2spec/utils/merkle_minimal.py\r\n\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495347393/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495419002",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/1115#issuecomment-495419002",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115",
    "id": 495419002,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NTQxOTAwMg==",
    "user": {
      "login": "vbuterin",
      "id": 2230894,
      "node_id": "MDQ6VXNlcjIyMzA4OTQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/2230894?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vbuterin",
      "html_url": "https://github.com/vbuterin",
      "followers_url": "https://api.github.com/users/vbuterin/followers",
      "following_url": "https://api.github.com/users/vbuterin/following{/other_user}",
      "gists_url": "https://api.github.com/users/vbuterin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vbuterin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vbuterin/subscriptions",
      "organizations_url": "https://api.github.com/users/vbuterin/orgs",
      "repos_url": "https://api.github.com/users/vbuterin/repos",
      "events_url": "https://api.github.com/users/vbuterin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vbuterin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-05-23T23:22:47Z",
    "updated_at": "2019-05-23T23:22:47Z",
    "author_association": "MEMBER",
    "body": "> (e.g. you don't want a 10k bits bitstring as generalized index to identify a validator in a large dynamic list, like the registry)\r\n\r\nTo be clear, there is no linear length blowup like this; the increase in length is only one single hash (this is because the number of leaves at each level of the tree still goes up by 2 per level). If Merkle proofs were length 8 before, on average they'll be ~length 9.\r\n\r\n> And here's a quick helper function for calculating the next power of 2 for merkleization,\r\n\r\nOoh, fun! Probably not the best thing to put in code that's meant for people to read (`def next_power_of_2(x): return 1 if x == 1 else 2 * next_power_of_2((x+1)//2)` is clearer to mathematically reason about in your head and understand), but definitely much higher performance.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495419002/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495892282",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/1115#issuecomment-495892282",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115",
    "id": 495892282,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NTg5MjI4Mg==",
    "user": {
      "login": "dankrad",
      "id": 6130607,
      "node_id": "MDQ6VXNlcjYxMzA2MDc=",
      "avatar_url": "https://avatars.githubusercontent.com/u/6130607?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/dankrad",
      "html_url": "https://github.com/dankrad",
      "followers_url": "https://api.github.com/users/dankrad/followers",
      "following_url": "https://api.github.com/users/dankrad/following{/other_user}",
      "gists_url": "https://api.github.com/users/dankrad/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/dankrad/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/dankrad/subscriptions",
      "organizations_url": "https://api.github.com/users/dankrad/orgs",
      "repos_url": "https://api.github.com/users/dankrad/repos",
      "events_url": "https://api.github.com/users/dankrad/events{/privacy}",
      "received_events_url": "https://api.github.com/users/dankrad/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-05-25T09:12:03Z",
    "updated_at": "2019-05-25T09:12:03Z",
    "author_association": "MEMBER",
    "body": "I think I found a much more elegant way to write next_power_of_2 in python in when working on the phase 1 execution:\r\n```python\r\ndef next_power_of_2(v: int) -> int:\r\n    return 1 << v.bit_length()\r\n```",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495892282/reactions",
      "total_count": 2,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 2,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495919431",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/1115#issuecomment-495919431",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115",
    "id": 495919431,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NTkxOTQzMQ==",
    "user": {
      "login": "protolambda",
      "id": 19571989,
      "node_id": "MDQ6VXNlcjE5NTcxOTg5",
      "avatar_url": "https://avatars.githubusercontent.com/u/19571989?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/protolambda",
      "html_url": "https://github.com/protolambda",
      "followers_url": "https://api.github.com/users/protolambda/followers",
      "following_url": "https://api.github.com/users/protolambda/following{/other_user}",
      "gists_url": "https://api.github.com/users/protolambda/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/protolambda/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/protolambda/subscriptions",
      "organizations_url": "https://api.github.com/users/protolambda/orgs",
      "repos_url": "https://api.github.com/users/protolambda/repos",
      "events_url": "https://api.github.com/users/protolambda/events{/privacy}",
      "received_events_url": "https://api.github.com/users/protolambda/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-05-25T13:42:16Z",
    "updated_at": "2019-05-25T13:42:16Z",
    "author_association": "MEMBER",
    "body": "@dankrad Nice, knew about a few other scripting languages that tracked bitlength for large integers, but forgot about it here. Here's some testing + benching code: https://gist.github.com/protolambda/9ad3f46665cb9bdfdb38599cbc626c30 Bitlength outperforms mine by 2x, and the old one by 15x\r\n\r\nNow back to merkle-tree discussion :)",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495919431/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495925177",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/1115#issuecomment-495925177",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115",
    "id": 495925177,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NTkyNTE3Nw==",
    "user": {
      "login": "protolambda",
      "id": 19571989,
      "node_id": "MDQ6VXNlcjE5NTcxOTg5",
      "avatar_url": "https://avatars.githubusercontent.com/u/19571989?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/protolambda",
      "html_url": "https://github.com/protolambda",
      "followers_url": "https://api.github.com/users/protolambda/followers",
      "following_url": "https://api.github.com/users/protolambda/following{/other_user}",
      "gists_url": "https://api.github.com/users/protolambda/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/protolambda/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/protolambda/subscriptions",
      "organizations_url": "https://api.github.com/users/protolambda/orgs",
      "repos_url": "https://api.github.com/users/protolambda/repos",
      "events_url": "https://api.github.com/users/protolambda/events{/privacy}",
      "received_events_url": "https://api.github.com/users/protolambda/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-05-25T15:05:57Z",
    "updated_at": "2019-05-27T11:23:03Z",
    "author_association": "MEMBER",
    "body": "Another more stylistic (but *experimental* and *somewhat broken*) approach:\r\n\r\nAct like it is a fixed-length list of max. size (e.g. 32), and do a normal binary-tree merkle-root. Very similar to what we currently have with deposit-tree. *However*, we wrap the hash-function, to make smaller lists less expensive. This new hash-function definition would be:\r\n\r\n```python\r\ndef combine_chunks(a, b, level, index_at_level, length_at_level): # level of the combination node, index of the combination node, length of the level\r\n   # check if b is out of bounds\r\n   if index_at_level + 1 == length_at_level:\r\n      assert b == ZERO_CHUNK\r\n      return a  # just propagate a if b is zero.\r\n   elif level < MAX_LEVELS:\r\n      return hash(a + b) # hash of concatenated chunks, like currently\r\n   else:\r\n      return hash(a + b + to_chunk(index_at_level))\r\n# Note: last two returns could be combined, see comments on consistency.\r\n```\r\n*note: verification is not exactly the same, one needs to mix in the index at leaf-level based on type*\r\n\r\nNow, we can ignore the empty part of the tree, and just supply a bunch of zeroes (not higher order hashes of zero) for the branch part that completes it to a `MAX_LEVELS` deep merkle-tree.\r\n\r\n\r\n```txt\r\n               R\r\n              / \\\r\n            / \\  3\r\n          / \\  0\r\n       ...   0\r\n     / \\\r\n   /  \\  0\r\n  /\\  /\\\r\n A B  C 0\r\n```\r\nNote that we are still mixing in the length, to differentiate a list ending in zeroes with the same list without (some of) these zeroes.\r\n\r\nAnd the zeroes in the merkle-proof can be compressed where necessary. And the hash with zero is essentially free, so that's great. (side-effect: hashing default lists filled with 0 will be super fast :tada:)\r\n\r\nNow leafs have an easily identifiable place, and have \"the same\" proof-length, and the same general index, at all times.\r\nAnother nice property is that the generalized index is super easy to compute with the standard formula `2**depth + index` since we have a virtual constant `depth` of `MAX_LEVELS+1` (don't forget the length mix-in). So the average generalized index looks like `100000.....000001101010` (big endian here, index at the right end). Given that we are not nesting dynamic lists super deep, maybe 3 levels at most, this inefficiency seems fine.\r\n\r\nOpen question: if one would agree to standardize the compression of the zero chunks in the proof, we essentially are using the length data to read the proof (very much the same as we had before the unbalanced tree idea, now just supporting static indices without extra hashing).\r\n\r\nI would put the `MAX_LEVELS` at 31 or 63, to make the depth of the tree, with length mix-in, a nice power of 2.\r\n\r\nTLDR:\r\n- virtual generalized indices, to keep them in the same place, good for light-clients.\r\n- some extra zeroes in proof, easily compressed if necessary\r\n- effectively 0 extra hashing, absolute minimum hashing for dynamically sized binary merkle tree.\r\n- maximum dynamic list size, but adjustable per use-case (change `MAX_LEVELS`).\r\n- positioning and generalized indices are easy and fast to compute.\r\n\r\n## SHA-256\r\n\r\nSo, standard merkle input of 2 chunks is: `32*2*8=512` bits. However, SHA-256 mixes in the length of the input `64` bits, and a non-zero delimiter `1` bit. And then it pads to a multiple of `512` bits, each `512` bits being a chunk to hash on top of the starting state. This means that we have `512-64-1=447` bits to mix in extra data, like the pair-index, for essentially free.\r\n\r\n## Light clients / Verification flow\r\n\r\nNow, we can have a light client ask for a piece of data, with a proof. \"hey full node, give me data at general index 1234 please\". The light client then verifies the proof like a normal merkle tree, but additionally mixes in the expected index in the dynamic list during verification, whenever it passes a node that is part of the leaf-level of a dynamic list.\r\n\r\nPro: Stable generalized indices, simple proof construction, easy proof compression, and length-independent verification.\r\n\r\nCon: verification is more complex. But if we ask for data, we are not asking for it because of random reasons, we know the location + typing we are asking for, so we can deal with the verification just fine.\r\n\r\n## Consistent complexity, no typing\r\n\r\nWe could make the thing more consistent with unnecessary mix-ins: mix in the general index at every non-out-of-bounds node combination. Now, a verifier doesn't have to care about the type anymore, it can just repeatedly mix in the index. For free, if this index is within 447 bits.\r\n\r\n## Consistency with normal verification\r\n\r\nInstead of mixing in a third argument at leaf combination level, we could also do an extra hash, and mix in the index of the pair at that level. This makes it valid to do the current merkle-proof verification. At the cost of 1 hash per pair of leafs.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495925177/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495947874",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/1115#issuecomment-495947874",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115",
    "id": 495947874,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NTk0Nzg3NA==",
    "user": {
      "login": "protolambda",
      "id": 19571989,
      "node_id": "MDQ6VXNlcjE5NTcxOTg5",
      "avatar_url": "https://avatars.githubusercontent.com/u/19571989?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/protolambda",
      "html_url": "https://github.com/protolambda",
      "followers_url": "https://api.github.com/users/protolambda/followers",
      "following_url": "https://api.github.com/users/protolambda/following{/other_user}",
      "gists_url": "https://api.github.com/users/protolambda/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/protolambda/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/protolambda/subscriptions",
      "organizations_url": "https://api.github.com/users/protolambda/orgs",
      "repos_url": "https://api.github.com/users/protolambda/repos",
      "events_url": "https://api.github.com/users/protolambda/events{/privacy}",
      "received_events_url": "https://api.github.com/users/protolambda/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-05-25T20:55:24Z",
    "updated_at": "2019-05-27T11:20:41Z",
    "author_association": "MEMBER",
    "body": "Ok, let's summarize all the variants of merkleization, for dynamic-length lists:\r\n\r\n## [Status Quo](https://github.com/ethereum/eth2.0-specs/issues/1115#issue-447766723)\r\n\r\n- **balanced** binary tree\r\n- generalized indices work, but **indices change** when tree balance changes (on power of 2 boundaries)\r\n- simple, **standard verification**\r\n- proofs are **dynamic size** (tree size power-of-2 change)\r\n- generalized indices are easy to compute, but **leaf depth can change**\r\n\r\n\r\n## [Unbalanced Merkle Tree](https://github.com/ethereum/eth2.0-specs/issues/1115#issue-447766723)\r\n\r\n- **unbalanced** binary tree. Cost is approx. 1 hash extra for proof of 1 element.\r\n- **fixed indices**, even with append/pop\r\n- some indices **cheaper**, others more **expensive** to verify\r\n- simple, **standard verification**\r\n- proofs are a **dynamic size** (larger indices, more cost)\r\n- generalized indices are easy to compute, but **leaf depth is variable**.\r\n\r\n\r\n## [Virtually balanced Merkle Tree](https://github.com/ethereum/eth2.0-specs/issues/1115#issuecomment-495925177)\r\n\r\n**Note: wrapped special-case hash-function introduces many edge-cases, design variants need to be adjusted still**\r\n\r\nFor all sub-variants applies:\r\n- **balanced**, extra cost depends on sub-variant, 1 extra hash at most\r\n- **fixed indices**\r\n- all nodes have **equal cost** verification\r\n- maximum on list contents, can be high.\r\n- proofs are **constant size**, *but the size is relatively big*. The difference is that it's filled with zeroes. Although, that is easy to compress.\r\n- generalized indices are easy to compute, but relatively large (`MAX_LEVELS + 1` bits), **leaf depth is fixed**\r\n\r\n### Leaf-pair index mix-in\r\n\r\n- **0 extra hashing cost**. Since indices are mixed into the 447 bits available SHA-256 input space.\r\n- **Non-standard verification**. One needs add the index to the hash input at the right level(s) of the merkle proof, to get the correct hash verification.\r\n- `H(a, 0) -> a`, except for leaf-level, see `1-hash extra` below for comments on collisions + efficiency.\r\n\r\n### Consistent index mix-in\r\n- **0 extra hashing cost**, same available hash input space is used, at every level.\r\n- **Non-standard verification**. But no detailed type information necessary. Just know to add the index at the height or generalized index (TBD) to the hash input.\r\n\r\n### 1-hash extra\r\n- **just 1 hash more than absolute minimum**\r\n- **familiar verification**. Mix in (additional hash) the index for each pair of leafs, like combination of normal chunks. Possibly cheap, for multi-proofs of adjacent data.\r\n- essentially the balanced version of the unbalanced approach. Trade-off: preset maximum size, zeroes need to be compressed. Reward: standard generalized index computation, balanced tree.\r\n- `H(a, 0) -> a`, except for extra-hash level. This potential case, but with the covered index-mix-based collision work-around, means we could re-use some of the hashes. (but tree is not sparse, so small benefit)\r\n\r\n## [Sparse merkle-tree alike](https://ethresear.ch/t/a-nearly-trivial-on-zero-inputs-32-bytes-long-collision-resistant-hash-function/5511)\r\n\r\n- Also a virtually balanced tree, but with different hashing.\r\n  - **fixed indices**\r\n  - all nodes have **equal cost** verification\r\n  - maximum on list contents, can be high.\r\n  - similar proof + generalized index size issues as the other virtual tree. *Both* within manageable (optimizable) size still, see full comment.\r\n- works for sparse merkle trees. Can be optimized not too, and only handle the `H(a, 0)` case, not the `H(0, b)` case.\r\n- **Non-standard verification**: One needs to deal with 1 or 2 bytes of hash output being thrown away.\r\n- cheap (but not cheapest) approach to merkle-tree zeroes.\r\n\r\n\r\n## Sources\r\n\r\nGeneralized indices: [eth2 light client specs > generalized index](https://github.com/ethereum/eth2.0-specs/blob/2787fea5feb8d5977ebee7c578c5d835cff6dc21/specs/light_client/merkle_proofs.md#generalized-merkle-tree-index)\r\n\r\n0-based generalized indices: [eth2 specs Issue 1008](https://github.com/ethereum/eth2.0-specs/issues/1008#issue-438046881)\r\n\r\nSHA-256 pseudocode, performance related: [on SHA-2-family wikipedia](https://en.wikipedia.org/wiki/SHA-2#Pseudocode)\r\n\r\nEth2 exec-spec merkle code: [`merkle_minimal.py`](https://github.com/ethereum/eth2.0-specs/blob/dev/test_libs/pyspec/eth2spec/utils/merkle_minimal.py), [ssz code > `merkleize(chunks)`](https://github.com/ethereum/eth2.0-specs/blob/dd091724d091f3a1fd066675d1d5d2a64d22fe4c/test_libs/pyspec/eth2spec/utils/minimal_ssz.py#L226)\r\n\r\nCredits to Vitalik for pushing so many different ideas forward. Hope my alternative + this summary helps to get to a **balanced**, **easy**, **small** and **constant index supporting** merkle tree design.\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/495947874/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/496021782",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/1115#issuecomment-496021782",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115",
    "id": 496021782,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NjAyMTc4Mg==",
    "user": {
      "login": "vbuterin",
      "id": 2230894,
      "node_id": "MDQ6VXNlcjIyMzA4OTQ=",
      "avatar_url": "https://avatars.githubusercontent.com/u/2230894?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/vbuterin",
      "html_url": "https://github.com/vbuterin",
      "followers_url": "https://api.github.com/users/vbuterin/followers",
      "following_url": "https://api.github.com/users/vbuterin/following{/other_user}",
      "gists_url": "https://api.github.com/users/vbuterin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/vbuterin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/vbuterin/subscriptions",
      "organizations_url": "https://api.github.com/users/vbuterin/orgs",
      "repos_url": "https://api.github.com/users/vbuterin/repos",
      "events_url": "https://api.github.com/users/vbuterin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/vbuterin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-05-26T18:36:09Z",
    "updated_at": "2019-05-26T18:36:09Z",
    "author_association": "MEMBER",
    "body": "> simple, standard verification. Mix in (additional hash) the index for each pair of leafs. Possibly cheap, for multi-proofs of adjacent data.\r\n\r\nWhat do you mean by \"the index\" here? The index in the list?\r\n\r\nI would not call it \"standard verification\" if the generalized index alone isn't enough to fully define the verification path + sequence of operations required to verify a branch, so if there's extra data being added in at some levels of the tree that breaks the invariant...",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/496021782/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/496177878",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/1115#issuecomment-496177878",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115",
    "id": 496177878,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ5NjE3Nzg3OA==",
    "user": {
      "login": "protolambda",
      "id": 19571989,
      "node_id": "MDQ6VXNlcjE5NTcxOTg5",
      "avatar_url": "https://avatars.githubusercontent.com/u/19571989?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/protolambda",
      "html_url": "https://github.com/protolambda",
      "followers_url": "https://api.github.com/users/protolambda/followers",
      "following_url": "https://api.github.com/users/protolambda/following{/other_user}",
      "gists_url": "https://api.github.com/users/protolambda/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/protolambda/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/protolambda/subscriptions",
      "organizations_url": "https://api.github.com/users/protolambda/orgs",
      "repos_url": "https://api.github.com/users/protolambda/repos",
      "events_url": "https://api.github.com/users/protolambda/events{/privacy}",
      "received_events_url": "https://api.github.com/users/protolambda/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-05-27T11:18:32Z",
    "updated_at": "2019-05-27T11:18:32Z",
    "author_association": "MEMBER",
    "body": "> What do you mean by \"the index\" here? The index in the list?\r\n\r\nI think it can be both. It's really just more an idea than a verified/tested approach. We can start breaking + fixing things when the basic idea is there.\r\n\r\n\r\n> I would not call it \"standard verification\" \r\n\r\nHmm, yes, hash function is different still. But it's more \"standard\" than adding a additional data to the hash input of combining leafs (like the other variants). Instead It's like a normal mix-in. `A+B->P`, `P+I->X` (`A` and `B` are leafs, `I` is the index). So branch verification doesn't break, it's just 1 longer. And what I'm trying to do here is to make the leaf elements effectively unique, to avoid collision problems. (Yes, there are issues here still, no free lunch in CS ...) Although I'm not sure what exact \"attacks\" are actually fine. E.g. I'm fine with people supplying shorter proofs when the result of verification for every index is the same. But when leafs are interchangeable, or leafs can be replaced with their hashes, or something else, things could go very wrong.\r\n\r\n\r\n\r\n",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/496177878/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/502394344",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/1115#issuecomment-502394344",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/1115",
    "id": 502394344,
    "node_id": "MDEyOklzc3VlQ29tbWVudDUwMjM5NDM0NA==",
    "user": {
      "login": "JustinDrake",
      "id": 731743,
      "node_id": "MDQ6VXNlcjczMTc0Mw==",
      "avatar_url": "https://avatars.githubusercontent.com/u/731743?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/JustinDrake",
      "html_url": "https://github.com/JustinDrake",
      "followers_url": "https://api.github.com/users/JustinDrake/followers",
      "following_url": "https://api.github.com/users/JustinDrake/following{/other_user}",
      "gists_url": "https://api.github.com/users/JustinDrake/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/JustinDrake/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/JustinDrake/subscriptions",
      "organizations_url": "https://api.github.com/users/JustinDrake/orgs",
      "repos_url": "https://api.github.com/users/JustinDrake/repos",
      "events_url": "https://api.github.com/users/JustinDrake/events{/privacy}",
      "received_events_url": "https://api.github.com/users/JustinDrake/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-06-15T19:44:34Z",
    "updated_at": "2019-06-15T19:44:34Z",
    "author_association": "MEMBER",
    "body": "Closing in favour of issue #1160 which has now achieved rough consensus :)",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/502394344/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
