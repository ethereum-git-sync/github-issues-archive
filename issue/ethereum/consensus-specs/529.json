{
  "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/529",
  "repository_url": "https://api.github.com/repos/ethereum/consensus-specs",
  "labels_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/529/labels{/name}",
  "comments_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/529/comments",
  "events_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/529/events",
  "html_url": "https://github.com/ethereum/consensus-specs/issues/529",
  "id": 404826428,
  "node_id": "MDU6SXNzdWU0MDQ4MjY0Mjg=",
  "number": 529,
  "title": "Concrete proposals for what data gets committed to in a crosslink",
  "user": {
    "login": "vbuterin",
    "id": 2230894,
    "node_id": "MDQ6VXNlcjIyMzA4OTQ=",
    "avatar_url": "https://avatars.githubusercontent.com/u/2230894?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/vbuterin",
    "html_url": "https://github.com/vbuterin",
    "followers_url": "https://api.github.com/users/vbuterin/followers",
    "following_url": "https://api.github.com/users/vbuterin/following{/other_user}",
    "gists_url": "https://api.github.com/users/vbuterin/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/vbuterin/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/vbuterin/subscriptions",
    "organizations_url": "https://api.github.com/users/vbuterin/orgs",
    "repos_url": "https://api.github.com/users/vbuterin/repos",
    "events_url": "https://api.github.com/users/vbuterin/events{/privacy}",
    "received_events_url": "https://api.github.com/users/vbuterin/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1170173759,
      "node_id": "MDU6TGFiZWwxMTcwMTczNzU5",
      "url": "https://api.github.com/repos/ethereum/consensus-specs/labels/phase1",
      "name": "phase1",
      "color": "F7C242",
      "default": false,
      "description": ""
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 1,
  "created_at": "2019-01-30T15:32:13Z",
  "updated_at": "2019-04-17T22:56:47Z",
  "closed_at": "2019-04-17T22:56:47Z",
  "author_association": "MEMBER",
  "active_lock_reason": null,
  "body": "Currently, the `AttestationData` structure asks crosslink committee members to sign a `shard_block_hash`, the hash of a shard block at some recent slot (perhaps the epoch start slot of the epoch during which the crosslink is made, though this has not yet been specified). There is also a custody bit, which is the first bit of the hash of _something_, which has also not yet been specified. This post will attempt to come up with concrete proposals to tackle these issues.\r\n\r\nFirst, some facts to keep in mind:\r\n\r\n* The `AttestationData` structure includes a `latest_crosslink_root`, so validators signing a crosslink do know what the last crosslink was, and therefore what slot it included blocks up to.\r\n* The shard chain does _not_ know when the latest crosslink was, and it fundamentally can't. A crosslink of a shard chain up to slot N will take up to slot N + EPOCH_LENGTH before we know whether or not that crosslink will be included in the beacon chain, so the shard chain between slots N and N + EPOCH_LENGTH does not know whether it's part of the \"new crosslink period\" or the old one\r\n* If the last crosslink was up to slot N, the curent crosslink could be up to slot N2 > N for an arbitrarily high difference N2 - N; there is no upper bound on the amount of data that needs to be included\r\n* Some slots have blocks, other slots are skips\r\n* A shard block has a header (currently min 344 bytes, max 856 bytes) and a body (~16 kb); there is also a desire to add state roots, which could add another few hundred bytes to the \"header\".\r\n\r\nThe simplest approach would be to have `shard_block_hash` point to the shard block at the end of the epoch before the epoch in which the crosslink was included, and make a proof of custody of just the shard block data. Note that because all shard block data is perfectly 2^k sized (16 KB = 2^14 bytes, or 2^9 32-byte chunks), a Merkle tree of Merkle trees of shard data from N blocks is the same as a Merkle tree of the concatenated shard data, as long as we make sure to fill unused leaves in the tree with `merkle_root([b'\\x00' * 32] * 512)` instead of the zero-hash.\r\n\r\nHowever, this would require a client seeking to gain a guarantee on the chain's integrity to download not just the beacon chain but also the shard chains, which adds a significant amount of data: up to 1/16 the data of all shards in the entire chain! It would also make fraud proof enforcement harder, as the beacon chain would not have access to any state roots in between the crosslinks. A better approach would have `shard_block_hash` (and therefore the custody bit) include the block bodies and also the headers.\r\n\r\nFor the proposals, we rename `shard_block_hash` to `custody_commitment_data`.\r\n\r\n#### A philosophical note\r\n\r\nWe can consider the crosslinks being included into the beacon chain as being the \"real\" shard blocks' headers. So all \"real shard block headers\" get included into the beacon chain. The shard blocks that appear in the intermediate stages are merely a coordination device to assist the proposal committee on coming together to agree what block to propose, and in such a way that transaction senders can get assurance within one slot that their block will (likely) get included. From this point of view, we want to be able to fully verify state transitions inside of these \"real shard blocks\" and fully verify that the coordination game was actually followed, so we should include shard headers in the data to be committed.\r\n\r\n#### Proposal 1: two sub-trees\r\n\r\nLet `custody_commitment_data = hash(header_root, body_root)`, where `body_root` is a Merkle root of all block data, and `header_root` is a Merkle root of all header data, zero-padded to 16 KB (for skipped slots, block data is fully zero, and header data is some placeholder containing the most recent block header root and `state_root`). We can add a state transition validity fraud proof by asking for a Merkle branch for the header and a Merkle branch in the corresponding block root in the body data, and checking that the latter does not match the `data_root` in the former.\r\n\r\n#### Proposal 2: interlacing\r\n\r\nFor each block, have 32 kilobytes of data, where the first 16 kilobytes are the header (zero-padded to 16 KB) and the second 16 kilobytes are the data (for skipped slots, block data is fully zero, and header data is some placeholder containing the most recent block header root and `state_root`). We can add a state transition validity fraud proof with a Merkle branch for the header and for the body data as in proposal 1, also checking that the latter does not match the `data_root` in the former. However, the fraud proof will be shorter, because most of the two Merkle branches are shared because the header and body are beside each other in the tree.\r\n\r\n#### Proposal 3: optimizing interlacing\r\n\r\nFor each block, have 32 kilobytes of data, where the first 2 kilobytes are the header (zero-padded to 2 KB) and the remaining 30 kilobytes are the data (for skipped slots, block data is fully zero, and header data is some placeholder containing the most recent block header root and `state_root`). A block header now contains four data roots for the 2+4+8+16 kilobytes of the data respectively. We would add a fraud proof type for each of the four roots and parts of the block data.\r\n\r\nProposal 3 is more efficient than proposal 2 when we want to add data availability proofs because it does not add the ~80% overhead from hashing many zero bytes, but it also adds some extra complexity. We could mitigate the 80% overhead by simply using the space for other purposes. Possible ways to use the space include:\r\n\r\n* Putting in STARKs of validity\r\n* Putting in erasure coded values for the other data\r\n* Putting in random Merkle branches from the state\r\n\r\nThese ideas would be easier to implement if there was a large contiguous pool of data, which is an advantage of proposal 1 over proposal 2.",
  "closed_by": {
    "login": "djrtwo",
    "id": 1433595,
    "node_id": "MDQ6VXNlcjE0MzM1OTU=",
    "avatar_url": "https://avatars.githubusercontent.com/u/1433595?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/djrtwo",
    "html_url": "https://github.com/djrtwo",
    "followers_url": "https://api.github.com/users/djrtwo/followers",
    "following_url": "https://api.github.com/users/djrtwo/following{/other_user}",
    "gists_url": "https://api.github.com/users/djrtwo/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/djrtwo/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/djrtwo/subscriptions",
    "organizations_url": "https://api.github.com/users/djrtwo/orgs",
    "repos_url": "https://api.github.com/users/djrtwo/repos",
    "events_url": "https://api.github.com/users/djrtwo/events{/privacy}",
    "received_events_url": "https://api.github.com/users/djrtwo/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/529/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/529/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/484291876",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/529#issuecomment-484291876",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/529",
    "id": 484291876,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ4NDI5MTg3Ng==",
    "user": {
      "login": "djrtwo",
      "id": 1433595,
      "node_id": "MDQ6VXNlcjE0MzM1OTU=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1433595?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/djrtwo",
      "html_url": "https://github.com/djrtwo",
      "followers_url": "https://api.github.com/users/djrtwo/followers",
      "following_url": "https://api.github.com/users/djrtwo/following{/other_user}",
      "gists_url": "https://api.github.com/users/djrtwo/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/djrtwo/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/djrtwo/subscriptions",
      "organizations_url": "https://api.github.com/users/djrtwo/orgs",
      "repos_url": "https://api.github.com/users/djrtwo/repos",
      "events_url": "https://api.github.com/users/djrtwo/events{/privacy}",
      "received_events_url": "https://api.github.com/users/djrtwo/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2019-04-17T22:56:46Z",
    "updated_at": "2019-04-17T22:56:46Z",
    "author_association": "MEMBER",
    "body": "We went with proposal 1\r\nhttps://github.com/ethereum/eth2.0-specs/blob/dev/specs/core/1_shard-data-chains.md#compute_crosslink_data_root",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/484291876/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
