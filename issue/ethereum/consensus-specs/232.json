{
  "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232",
  "repository_url": "https://api.github.com/repos/ethereum/consensus-specs",
  "labels_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232/labels{/name}",
  "comments_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232/comments",
  "events_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232/events",
  "html_url": "https://github.com/ethereum/consensus-specs/issues/232",
  "id": 387443667,
  "node_id": "MDU6SXNzdWUzODc0NDM2Njc=",
  "number": 232,
  "title": "SSZ question: clarification on the homogeneity of list elements",
  "user": {
    "login": "cleishm",
    "id": 79651,
    "node_id": "MDQ6VXNlcjc5NjUx",
    "avatar_url": "https://avatars.githubusercontent.com/u/79651?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/cleishm",
    "html_url": "https://github.com/cleishm",
    "followers_url": "https://api.github.com/users/cleishm/followers",
    "following_url": "https://api.github.com/users/cleishm/following{/other_user}",
    "gists_url": "https://api.github.com/users/cleishm/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/cleishm/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/cleishm/subscriptions",
    "organizations_url": "https://api.github.com/users/cleishm/orgs",
    "repos_url": "https://api.github.com/users/cleishm/repos",
    "events_url": "https://api.github.com/users/cleishm/events{/privacy}",
    "received_events_url": "https://api.github.com/users/cleishm/received_events",
    "type": "User",
    "site_admin": false
  },
  "labels": [
    {
      "id": 1063043872,
      "node_id": "MDU6TGFiZWwxMDYzMDQzODcy",
      "url": "https://api.github.com/repos/ethereum/consensus-specs/labels/general:question",
      "name": "general:question",
      "color": "FAD689",
      "default": false,
      "description": "Further information is requested"
    },
    {
      "id": 1170174610,
      "node_id": "MDU6TGFiZWwxMTcwMTc0NjEw",
      "url": "https://api.github.com/repos/ethereum/consensus-specs/labels/scope:SSZ",
      "name": "scope:SSZ",
      "color": "77428D",
      "default": false,
      "description": "Simple Serialize"
    }
  ],
  "state": "closed",
  "locked": false,
  "assignee": null,
  "assignees": [

  ],
  "milestone": null,
  "comments": 8,
  "created_at": "2018-12-04T19:27:43Z",
  "updated_at": "2019-01-28T09:57:28Z",
  "closed_at": "2019-01-28T09:57:28Z",
  "author_association": "CONTRIBUTOR",
  "active_lock_reason": null,
  "body": "In the current [SSZ specification](https://github.com/ethereum/eth2.0-specs/blob/ff2551e754028260a619c1b538ac194568f1eff2/specs/simple-serialize.md#listvectors), lists are defined as \"a collection of elements of the same homogeneous **type**\".\r\n\r\nBy this definition, a list of byte arrays, a list of other lists, or a list of collections, are all homogeneous by *type* yet contain elements that may vary in serialized size.\r\n\r\nThe example implementations sum each elements serialized length to find the raw length, however the specification says the raw length is defined as `len(list) * sizeof(element)`, implying they all have the same serialized size. Additionally, the Tree Hash definition only uses the size of the first element in a list to calculate `items_per_chunk` (`SSZ_CHUNK_SIZE // len(lst[0])`).\r\n\r\nThe question is: should the specification define that lists contain elements of homogeneous type **and size**, or should we update the specification of raw length (e.g. to `sum(sizeof(elem) for elem in list)`) and the Tree Hash algorithm according?",
  "closed_by": {
    "login": "hwwhww",
    "id": 9263930,
    "node_id": "MDQ6VXNlcjkyNjM5MzA=",
    "avatar_url": "https://avatars.githubusercontent.com/u/9263930?v=4",
    "gravatar_id": "",
    "url": "https://api.github.com/users/hwwhww",
    "html_url": "https://github.com/hwwhww",
    "followers_url": "https://api.github.com/users/hwwhww/followers",
    "following_url": "https://api.github.com/users/hwwhww/following{/other_user}",
    "gists_url": "https://api.github.com/users/hwwhww/gists{/gist_id}",
    "starred_url": "https://api.github.com/users/hwwhww/starred{/owner}{/repo}",
    "subscriptions_url": "https://api.github.com/users/hwwhww/subscriptions",
    "organizations_url": "https://api.github.com/users/hwwhww/orgs",
    "repos_url": "https://api.github.com/users/hwwhww/repos",
    "events_url": "https://api.github.com/users/hwwhww/events{/privacy}",
    "received_events_url": "https://api.github.com/users/hwwhww/received_events",
    "type": "User",
    "site_admin": false
  },
  "reactions": {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232/reactions",
    "total_count": 0,
    "+1": 0,
    "-1": 0,
    "laugh": 0,
    "hooray": 0,
    "confused": 0,
    "heart": 0,
    "rocket": 0,
    "eyes": 0
  },
  "timeline_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232/timeline",
  "performed_via_github_app": null,
  "state_reason": "completed"
}
[
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/445480216",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/232#issuecomment-445480216",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232",
    "id": 445480216,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NTQ4MDIxNg==",
    "user": {
      "login": "cleishm",
      "id": 79651,
      "node_id": "MDQ6VXNlcjc5NjUx",
      "avatar_url": "https://avatars.githubusercontent.com/u/79651?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cleishm",
      "html_url": "https://github.com/cleishm",
      "followers_url": "https://api.github.com/users/cleishm/followers",
      "following_url": "https://api.github.com/users/cleishm/following{/other_user}",
      "gists_url": "https://api.github.com/users/cleishm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cleishm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cleishm/subscriptions",
      "organizations_url": "https://api.github.com/users/cleishm/orgs",
      "repos_url": "https://api.github.com/users/cleishm/repos",
      "events_url": "https://api.github.com/users/cleishm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cleishm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-08T18:35:02Z",
    "updated_at": "2018-12-08T18:35:02Z",
    "author_association": "CONTRIBUTOR",
    "body": "I also wonder if an \"easier\" way to resolve this would be to change the list length prefix to _only_ `len(list)` (nElements), and not the raw length of the entire list encoding. This would simplify serialization, sacrificing only the ability to skip over a complete value when decoding, which is not a common use case afaik.\r\n\r\nThoughts?",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/445480216/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/445545275",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/232#issuecomment-445545275",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232",
    "id": 445545275,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NTU0NTI3NQ==",
    "user": {
      "login": "jannikluhn",
      "id": 29854669,
      "node_id": "MDQ6VXNlcjI5ODU0NjY5",
      "avatar_url": "https://avatars.githubusercontent.com/u/29854669?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/jannikluhn",
      "html_url": "https://github.com/jannikluhn",
      "followers_url": "https://api.github.com/users/jannikluhn/followers",
      "following_url": "https://api.github.com/users/jannikluhn/following{/other_user}",
      "gists_url": "https://api.github.com/users/jannikluhn/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/jannikluhn/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/jannikluhn/subscriptions",
      "organizations_url": "https://api.github.com/users/jannikluhn/orgs",
      "repos_url": "https://api.github.com/users/jannikluhn/repos",
      "events_url": "https://api.github.com/users/jannikluhn/events{/privacy}",
      "received_events_url": "https://api.github.com/users/jannikluhn/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-09T15:07:14Z",
    "updated_at": "2018-12-09T15:07:14Z",
    "author_association": "MEMBER",
    "body": "I _think_ the spec is wrong and the example implementation is right. Otherwise lists of containers containing lists would not be possible, but those seem to be used in the phase 0 spec (e.g. `BeaconBlockBody.attestations`).",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/445545275/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/445550443",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/232#issuecomment-445550443",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232",
    "id": 445550443,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NTU1MDQ0Mw==",
    "user": {
      "login": "cleishm",
      "id": 79651,
      "node_id": "MDQ6VXNlcjc5NjUx",
      "avatar_url": "https://avatars.githubusercontent.com/u/79651?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cleishm",
      "html_url": "https://github.com/cleishm",
      "followers_url": "https://api.github.com/users/cleishm/followers",
      "following_url": "https://api.github.com/users/cleishm/following{/other_user}",
      "gists_url": "https://api.github.com/users/cleishm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cleishm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cleishm/subscriptions",
      "organizations_url": "https://api.github.com/users/cleishm/orgs",
      "repos_url": "https://api.github.com/users/cleishm/repos",
      "events_url": "https://api.github.com/users/cleishm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cleishm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-09T16:18:30Z",
    "updated_at": "2018-12-09T16:18:30Z",
    "author_association": "CONTRIBUTOR",
    "body": "Yeah, I agree. Though that means the Tree Hash algorithm is wrong too.\r\n\r\nWdyt about just using the element count?",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/445550443/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/445748545",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/232#issuecomment-445748545",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232",
    "id": 445748545,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NTc0ODU0NQ==",
    "user": {
      "login": "mkalinin",
      "id": 1892772,
      "node_id": "MDQ6VXNlcjE4OTI3NzI=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1892772?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mkalinin",
      "html_url": "https://github.com/mkalinin",
      "followers_url": "https://api.github.com/users/mkalinin/followers",
      "following_url": "https://api.github.com/users/mkalinin/following{/other_user}",
      "gists_url": "https://api.github.com/users/mkalinin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mkalinin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mkalinin/subscriptions",
      "organizations_url": "https://api.github.com/users/mkalinin/orgs",
      "repos_url": "https://api.github.com/users/mkalinin/repos",
      "events_url": "https://api.github.com/users/mkalinin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mkalinin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-10T09:31:15Z",
    "updated_at": "2018-12-10T09:31:15Z",
    "author_association": "MEMBER",
    "body": "> Wdyt about just using the element count?\r\n\r\nWhen there is a need of decoding an object that have come from network it's good to know _whole size_ of encoded object. Otherwise, you have to pull list items in sequential fashion and calculate the size to mitigate overflows.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/445748545/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/445847989",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/232#issuecomment-445847989",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232",
    "id": 445847989,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NTg0Nzk4OQ==",
    "user": {
      "login": "cleishm",
      "id": 79651,
      "node_id": "MDQ6VXNlcjc5NjUx",
      "avatar_url": "https://avatars.githubusercontent.com/u/79651?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cleishm",
      "html_url": "https://github.com/cleishm",
      "followers_url": "https://api.github.com/users/cleishm/followers",
      "following_url": "https://api.github.com/users/cleishm/following{/other_user}",
      "gists_url": "https://api.github.com/users/cleishm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cleishm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cleishm/subscriptions",
      "organizations_url": "https://api.github.com/users/cleishm/orgs",
      "repos_url": "https://api.github.com/users/cleishm/repos",
      "events_url": "https://api.github.com/users/cleishm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cleishm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-10T15:07:37Z",
    "updated_at": "2018-12-10T15:07:37Z",
    "author_association": "CONTRIBUTOR",
    "body": "> you have to pull list items in sequential fashion and calculate the size to mitigate overflows\r\n\r\nYou’re going to do that anyway though, right? Unless you’re pulling the value and _not_ decoding it, which I can’t think of a use-case for, then you’ll be iterating and decoding the length of each part. And currently you have to iterate until you find the value whose end aligns with the overall raw length (or exceeds it, which would signal an encoding error).",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/445847989/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/446096705",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/232#issuecomment-446096705",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232",
    "id": 446096705,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NjA5NjcwNQ==",
    "user": {
      "login": "mkalinin",
      "id": 1892772,
      "node_id": "MDQ6VXNlcjE4OTI3NzI=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1892772?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mkalinin",
      "html_url": "https://github.com/mkalinin",
      "followers_url": "https://api.github.com/users/mkalinin/followers",
      "following_url": "https://api.github.com/users/mkalinin/following{/other_user}",
      "gists_url": "https://api.github.com/users/mkalinin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mkalinin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mkalinin/subscriptions",
      "organizations_url": "https://api.github.com/users/mkalinin/orgs",
      "repos_url": "https://api.github.com/users/mkalinin/repos",
      "events_url": "https://api.github.com/users/mkalinin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mkalinin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-11T07:14:13Z",
    "updated_at": "2018-12-11T07:14:13Z",
    "author_association": "MEMBER",
    "body": "IMO, it's preferable to know the length of the message before processing it. It would allow reading a certain number of bytes from socket and closing it instantly. Actually, the way message is read from the socket is implementation specific, but to have alternatives here requires length prefixes in bytes.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/446096705/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/446260033",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/232#issuecomment-446260033",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232",
    "id": 446260033,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NjI2MDAzMw==",
    "user": {
      "login": "cleishm",
      "id": 79651,
      "node_id": "MDQ6VXNlcjc5NjUx",
      "avatar_url": "https://avatars.githubusercontent.com/u/79651?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/cleishm",
      "html_url": "https://github.com/cleishm",
      "followers_url": "https://api.github.com/users/cleishm/followers",
      "following_url": "https://api.github.com/users/cleishm/following{/other_user}",
      "gists_url": "https://api.github.com/users/cleishm/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/cleishm/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/cleishm/subscriptions",
      "organizations_url": "https://api.github.com/users/cleishm/orgs",
      "repos_url": "https://api.github.com/users/cleishm/repos",
      "events_url": "https://api.github.com/users/cleishm/events{/privacy}",
      "received_events_url": "https://api.github.com/users/cleishm/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-11T16:11:01Z",
    "updated_at": "2018-12-12T08:34:05Z",
    "author_association": "CONTRIBUTOR",
    "body": "@mkalinin: in almost all cases, won't socket reads be buffered anyway? I've rarely seen a need to read only a specific number of bytes from a socket before closing it.\r\n\r\nOnly encoding the length elements actually has positive benefits for sending data - you don't have to buffer the entire list content first. One can output the number of elements to the socket, then encode and immediately output each element. If the entire raw length has to be calculated, then the entire raw list encoding has to be buffered first.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/446260033/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  },
  {
    "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/446492570",
    "html_url": "https://github.com/ethereum/consensus-specs/issues/232#issuecomment-446492570",
    "issue_url": "https://api.github.com/repos/ethereum/consensus-specs/issues/232",
    "id": 446492570,
    "node_id": "MDEyOklzc3VlQ29tbWVudDQ0NjQ5MjU3MA==",
    "user": {
      "login": "mkalinin",
      "id": 1892772,
      "node_id": "MDQ6VXNlcjE4OTI3NzI=",
      "avatar_url": "https://avatars.githubusercontent.com/u/1892772?v=4",
      "gravatar_id": "",
      "url": "https://api.github.com/users/mkalinin",
      "html_url": "https://github.com/mkalinin",
      "followers_url": "https://api.github.com/users/mkalinin/followers",
      "following_url": "https://api.github.com/users/mkalinin/following{/other_user}",
      "gists_url": "https://api.github.com/users/mkalinin/gists{/gist_id}",
      "starred_url": "https://api.github.com/users/mkalinin/starred{/owner}{/repo}",
      "subscriptions_url": "https://api.github.com/users/mkalinin/subscriptions",
      "organizations_url": "https://api.github.com/users/mkalinin/orgs",
      "repos_url": "https://api.github.com/users/mkalinin/repos",
      "events_url": "https://api.github.com/users/mkalinin/events{/privacy}",
      "received_events_url": "https://api.github.com/users/mkalinin/received_events",
      "type": "User",
      "site_admin": false
    },
    "created_at": "2018-12-12T07:43:56Z",
    "updated_at": "2018-12-12T07:43:56Z",
    "author_association": "MEMBER",
    "body": "> has positive benefits for sending data\r\n\r\nAnd it, also, has drawbacks for receiving them.\r\n\r\nIn case when number of elements is sent instead of length first received bytes tells almost nothing about entire message, it's just a number of elements that have an unpredictable size. Receiver starts to read these elements and calculate cumulative size. In the middle of it receiver understands that the message is too big and with high probability malformed or malicious. Then it cancels the receiving, and amount of data that have to be processed to understand whether message is sane or not is unknown before reading this message.\r\n\r\nAnother thing is that having a number of elements as a length of list does nothing with a length of container that carries some list. It should be calculated in bytes and that requires calculation of list size in bytes as well.\r\n\r\nAnother feasible way of streaming SSZ messages is to have `SSZSize(obj)` function that just calculates the size of the object in bytes. Of course, it's much less efficient than `len(list) * sizeof(element)` but that is something that could work.",
    "reactions": {
      "url": "https://api.github.com/repos/ethereum/consensus-specs/issues/comments/446492570/reactions",
      "total_count": 0,
      "+1": 0,
      "-1": 0,
      "laugh": 0,
      "hooray": 0,
      "confused": 0,
      "heart": 0,
      "rocket": 0,
      "eyes": 0
    },
    "performed_via_github_app": null
  }
]
